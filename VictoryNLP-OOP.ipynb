{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining\n",
    "In diesem Notebook werden die von der Gruppe 1 bereitstellten Dokumenten aufbereitet und ein Text Mining Verfahren wird ausgeführt, sodass die Informationen dieser Dokumente in der Form einer Knowledge-Graph-Datenbank zur Gruppe 3 bereitgestellt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import der Bibliotheken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basis-Bibliotheken für Datenbearbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotheken für NLP und Textbearbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # RegEx (Regular Expressions für Python für Textbearbeitung)\n",
    "import spacy # Spacy für NLP\n",
    "from spacy import displacy # Graphisches Werkzeug für die Visualisierung der Dependencies (DEP) und Parts of Speach (POS)\n",
    "from spacy.matcher import Matcher # Spacy Objekt, um Muster im Text zu finden\n",
    "from spacy.tokens import Span # Spacy Objekt, um Texte aufzuteilen\n",
    "import de_core_news_md # Spacy-Wortschatz auf Deutsch \n",
    "nlp = de_core_news_md.load() # Erstellung ein Spacy NLP objekt auf basis von dem hochgeladenen Spacy-Wortschatz auf Deutsch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unterstützungsbibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi # api für die Verbindung mit der Wikipedia-Website\n",
    "import concurrent.futures # Unterstützungsbibliothek für die Erstellung eines Wikipedia-Scrapers\n",
    "from tqdm import tqdm # Unterstützungsbibliothek für die Erstellung eines Wikipedia-Scrapers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisierungswerkzeuge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # Basis-Visualisierungstool für Python\n",
    "import networkx as nx # Visualisirungsbibliothek für Beziehungsdarstellung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Search api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers # Import von Elastic Search Objekten für Python\n",
    "import sys, json, os # Unterstützte Datentypen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten Hochladen - Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Größe der importierten Daten: 7617\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Importieren der von Gruppe 1 im Elastic Search bereitgestellten Dokumente.\n",
    "'''\n",
    "\n",
    "es = Elasticsearch([\"http://vala.win.hs-heilbronn.de\"], http_auth=(\"MID\", \"MID202002\"), timeout=600, port=9200)\n",
    "response = es.search(index=\"mid_beispieldaten_v9\", body= {}, size=8000)\n",
    "print('Größe der importierten Daten:', len(response['hits']['hits']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'uoEBxXIB7QWdo8C6vTMN',\n",
       "  '_index': 'mid_beispieldaten_v9',\n",
       "  '_score': 1.0,\n",
       "  '_source': {'Author': None,\n",
       "   'Course': '',\n",
       "   'Course_abbreviation': '',\n",
       "   'Course_location': '',\n",
       "   'Creation-Date': '2019-11-19T12:17:15',\n",
       "   'Last-Modified': '2019-11-19T12:17:15',\n",
       "   'Link': 'www.hs-heilbronn.de/_b/0000000000000024097716bb5dd69a89/4b25a09e1fc943a0b35d33544f9f17b03b696f1a_2578682clip_center_800_600_750b90',\n",
       "   'Text': None,\n",
       "   'Title': None,\n",
       "   'Upload-Date': '2020-06-18T00:42:28.923728Z'},\n",
       "  '_type': '_doc'},\n",
       " {'_id': 'u4EBxXIB7QWdo8C6vTMN',\n",
       "  '_index': 'mid_beispieldaten_v9',\n",
       "  '_score': 1.0,\n",
       "  '_source': {'Author': None,\n",
       "   'Course': '',\n",
       "   'Course_abbreviation': '',\n",
       "   'Course_location': '',\n",
       "   'Creation-Date': None,\n",
       "   'Last-Modified': None,\n",
       "   'Link': 'www.hs-heilbronn.de/21278004/rueckblick-2018-ausblick-2019',\n",
       "   'Text': ' MR-Aktivitäten - Hochschule Heilbronn Skip to navigation Press Enter. Skip to main content Press Enter. home home Login DE EN Suchen Zielgruppen Die Hochschule Forschung Internationales Kooperation Login DE EN Studieninteressierte Studierende Mitarbeitende Lehrende Schulen Alumni Unternehmen Presse Hochschule Heilbronn Standorte Fakultäten Studiengänge für Interessierte Studiengänge für Studierende Heilbronn University Graduate School HUGS Semesterterminplan Grundordnung und Satzungen Öffentliche Bekanntmachungen Gremien und Beauftragte Rektorat Hochschulrat Senat Fakultätsräte Hochschulbeauftragte Personalrat Verfasste Studierendenschaft Zentrale Einrichtungen Bibliothek LIV Career Service Institut für mathematisch-naturwissenschaftliche Grundlagen IfG Rechenzentrum Schulkoordination Stipendienstelle Zentrale Studienberatung Zentrum für Studium und Lehre ZfSL Weiterbildung Berufsbegleitende Studiengänge Heilbronner Institut für Lebenslanges Lernen HILL HHN und Gesellschaft Familiengerechte Hochschule Vielfalt und Gleichstellung Kultur Nachhaltigkeit Verwaltung Intranet Personal Raumbuchung HHN als Arbeitgeber Stellenangebote Rund ums Arbeiten an der HHN Forschung Forschungsförderung Doktorandenkolleg Gründerzentrum STARTKLAR Institute International Office Unsere Partnerhochschulen Kontakt - Sprechzeiten Ins Ausland Studium im Ausland Praktikum im Ausland Sprachen Studieren an der HHN Internationale Vollzeitstudierende Incomings von Partnerhochschulen Heilbronn University of Applied Sciences Informationen zum Studium für Geflüchtete Partner werden Sponsoring Förderkreis Stiftungen Stiftungsprofessuren Angebote für Schulen Talente gewinnen Stipendien Studium mit vertiefter Praxis Firmenkontaktmessen Jobbörse Mechatronik und Robotik - laufende Aktivitäten Machen Sie sich auf dieser Seite gerne ein Bild über die laufenden Aktivitäten des Studiengangs MR und – noch besser – machen Sie mit, nehmen Sie teil und tragen Sie es weiter! ZAFH MikroSens auf der Landesgartenschau in Überlingen vom 22.07. bis 24.07.2020 Den Besuchern wird das \"Virtual Orchestra\" vorgestellt, bei welchem sie das Württembergische Kammerorchester Heilbronn virtuell dirigieren können. Die Dirigierbewegung wird durch Radarsensorik erfasst und als Taktschlag an das Orchester auf dem Monitor weitergegeben. Weicht das Metrum zu stark von der Vorgabe des gewählten Musikstückes ab, so bricht das Orchester das Stück ab. Das Projekt wird von der Hochschule Heilbronn präsentiert und ist in dem Zentrum für angewandte Forschung ZAFH MikroSens Innovative Millimeterwellen-Sensorik für industrielle Anwendungen zusammen mit den Hochschulen Ulm und Pforzheim und der Universität Ulm entstanden. In diesem Forschungsprojekt werden der Radarsensorik über eine neuartige Plattform Applikationsfelder wie beispielsweise Strömungssensorik für fließende Gewässer, Bewegungsanalyse von Bienen, die Erfassung von Kochvorgängen und Automatisierungstechnik erschlossen. pot Bildquelle: Landesgartenschau Überlingen 2020 GmbH Schülerstudium Bildverarbeitung Zehn Schüler des Justinus-Kerner-Gymnasiums Weinsberg nahmen am Schülerstudium Bildverarbeitung teil und waren mit ihrem MWT-Lehrer Herrn Balle zu Gast im Labor für Technische Optik des Studiengangs Mechatronik und Robotik der Hochschule Heilbronn. Die Vorstudenten führten hier mit großem Interesse und Elan Versuche zur Bestimmung der Eigenschaften von LEDs und zur telezentrischen Kameramesstechnik durch und bauten ein einfaches Spektrometer als Aufsatz auf ihre Mobiltelefone, um damit die spektrale Zusammensetzung des Lichts sichtbar zu machen. Kommentar eines Schülers: „Jetzt weiß ich, wofür ich die Mathe in der Schule praktisch gebrauchen kann. Ich dachte gar nicht, dass ein Ingenieurstudium so abwechslungsreich sein kann.“ pot Das Virtual Orchestra wurde auf der BUGA von über 10.000 Besuchern dirigiert; über 1000 haben den Score von 9000 geknackt und an der Verlosung von zwei Freikarten für ein Konzert des Württembergischen Kammerorchesters teilgenommen. Die Dirigierbewegung des Besuchers wurde von einem im Projekt MikroSens entwickelten 122GHz Radarsensor erfasst. Das virtuelle Orchester auf der Leinwand spielte dann im Takt des Dirigenten. Drei Stücke standen zur Auswahl: Die kleine Nachtmusik, Holbergs Suite und die Adaption von Beethovens Ode an die Freude. pot Zweimal Platz 1 beim diesjährigen HHN-Konstruktionswettbewerb Unter dem Motto „Autonomer Lastentransport“ zeigten die Erstis im Studiengang Mechatronik und Robotik was sie draufhaben: 6 Teams konstruierten ein völlig autonom fahrendes Mini-Fahrzeug, das in der Lage ist, eine große Last über eine vorgegebene Strecke zu transportieren. „In diesem Semester waren die Studierenden wirklich exzellent“, sagt Organisator und Professor im Studiengang, Wolfgang Wehl. Field Robot Event auf der BUGA Am diesjährigen Field Robot Event nahmen das Team der Fakultät Mechatronik und Robotik und 14 weitere Teams aus verschiedenen europäischen Ländern teil. Austragungsort war vom 17. - 21. Juni die BUGA in Heilbronn. Auf einem zwölf mal zwölf Meter großen Feld mit ca. 80 cm hohen Maispflanzen traten die Teams in fünf verschiedenen Disziplinen gegeneinander an. In Task 1 sollte jede Reihe des Maisfeldes durchfahren werden. In der nächsten Aufgabe waren es nur bestimmte Reihen. Ziel des 3. Tasks war das Erkennen von Hindernissen und Unkraut, das dann in Task 4 bekämpft werden sollte. Am letzten Tag fand der Freestyle-Task statt, in dem jedes Team unterschiedliche Ideen für die Agrarwirtschaft zeigen konnte, z. B. dass das mobile Robotersystem einer Person folgt. Dies könnte dazu verwendet werden um schwere Dinge zu transportieren. Der Studiengang Mechatronik und Robotik beteiligte sich mit einem Tool am Heilbronner Hackathon Sensor  AI. Den Teilnehmern wurde eine Radarsensorik aus dem Projekt MikroSens vorgestellt, die Geschwindigkeiten und Abstände von Objekten schnell erfassen kann. Mittels dieser Sensordaten können über AI Objekte wie z.B. Gestenbewegungen erkannt werden. Dmitrii Kozlov, wissenschaftlicher Mitarbeiter im Studiengang Mechatronik und Robotik stellte das Tool vor und unterstützte als Coach bezüglich Programmierung und AI. Prof. Hoch aus dem Studiengang war Mitglied der Jury und beurteilte die Ergebnisse der Teilnehmer. pot Die Arbeitsgemeinschaft LED  Beleuchtungstechnik von Photonics BW und des Arbeitskreis LED Technik von optence  bayern photonics tagte am 22. Mai 2019 an der Hochschule Heilbronn. Der Gastgeber Prof. Dr.-Ing. Peter Ott vom Studiengang Mechatronik und Robotik stellte den 30 Gästen aus Industrie und Hochschulen die Forschungs- und Lehraktivitäten seines Labors für Technische Optik vor. Die Fachvorträge aus der Industrie zu aktuellen Themen der LED- und Beleuchtungstechnik und die anschließende rege Diskussion ergaben insgesamt eine sehr gelungenen Veranstaltung. pot Der deutschlandweite Fachbereichstag Mechatronik wurde von der Fakultät für Mechanik und Elektronik an der Hochschule Heilbronn ausgerichtet. Am Donnerstag und Freitag, den 16./17. Mai 2019, trafen sich 35 Dekane und Studiengangsleiter aus ganz Deutschland, um ihre aktuellen Erfahrungen und Entwicklungen in den Studiengängen aus ihren Hochschulen auszutauschen. Der Freitag stand unter dem hochaktuellen Thema Ingenieurausbildung für die Digitale Transformation. Daran schlossen sich Berichte über das breite Band der bereits vorhandenen Aktivitäten in den Studiengängen an. Mit der feierlichen Verleihung des Preises der Deutschen Gesellschaft für Mechatronik e.V. für die besten Bachelor- und Master-Arbeiten aus der Mechatronik an die Absolventen Felix Schneider, Dennis Hotze und Dominik Eickmann ging die Veranstaltung am Freitagnachmittag zu Ende. jwi Das Virtuelle Orchester auf der BUGA Am 17.April wurde die BUGA eröffnet und das Virtuelle Orchester wurde bereits am ersten Wochenende über 800 Mal dirigiert. Die Dirigierbewegung wird von einem im Projekt MikroSens entwickelten 122GHz Radarsensor erfasst. Das Orchester spielt entsprechend im Takt des Dirigenten. Für Grundlagen Digitaltechnik wurde im Sommersemester 2018 ein “inverted classrom” aufgesetzt. Statt der klassischen Vorlesung mit Übung, werden Zahlensysteme, boolesche Algebra und Schaltwerke über Videos und Beispielen darin erklärt. Damit das vermittelte Wissen gefestigt werden kann, sind im Anschluss Aufgaben zu lösen. Die Anwesenheitszeit wird statt für Frontalunterricht, zum Klären der Aufgaben und für Labore genutzt. Die Resonanz ist hoch und die Interaktion zwischen Lernenden und Coach hat sich erhöht. tfi Das ZAFH Projekt MikroSens wurde um zwei Jahre bis Ende 2020 verlängert. Das Projekt befasst sich mit Radarsensorik. Erforscht werden Prinzipien der Künstlichen Intelligenz zur Verarbeitung von Radardaten Deep Learning und Compressed Sensing. Im Labor stehen diverse Radare von 24GHz bis 122GHz für studentische Arbeiten zur Verfügung. 2019 wird das Exponat Virtual Orchestra auf der Bundesgartenschau in Heilbronn gezeigt. Dabei wird die Handbewegung eines Dirigenten mittels Radarsensorik erfasst. Das Orchester passt sich an den dirigierten Takt an. mal ZIM-Projekt: Automatisierte Messung; Selektion und Montage von Lithium-Zellen Die automatisierte Montage von modernen Lithium-Ionen-Akkus für akkubetriebene Antriebssysteme wird aus ökonomischen Gründen nur bei größeren Stückzahlen realisiert, während kleinere Stückzahlen in Handmontage gefertigt werden. Das Ziel dieses Projektes ist die Realisierung einer einfachen und flexiblen Roboterzelle, die die Prozessschritte einer Sortieranlage und der Handmontage kombiniert. Also eine Bestückung von Zellhaltern mit Lithium-Zellen bei gleichzeitiger Spannungsmessung und Umorientierung der einzelnen Zellen. Im Rahmen des öffentlich geförderten Projekts werden zahlreiche studentische Arbeiten, wie zum Beispiel Thesis, Seminararbeit oder Laborarbeit angeboten. thu Praxistage Roboterprogrammierung in der FANUC-Akademie Leinfelden Im siebten Semester geht es bei Robotik und Automation traditionell zu einem der großen Roboterhersteller für den Feinschliff in der Roboterprogrammierung. Nach Stäubli in Bayreuth, Kuka in Augsburg waren wir im Januar erstmals beim größten Roboterhersteller der Welt: Fanuc. Die japanische Firma hat in Leinfelden seine Deutschlandzentrale mit Vertrieb, Schulungszentrum und dem Kompetenzzentrum Automotive. Zwei unserer Absolventen sind dort und schwärmten von den tollen Arbeitsbedingungen aber auch von der optimalen Vorbereitung durch ihr Studium an der HHN. Der abendliche Ausklang in der Nürtinger Altstadt bot Gelegenheit für Gespräche in entspannter Atmosphäre. aho Das interdisziplinäre Projekt sense2cloud wurde 2018 erfolgreich abgeschlossen. Sense2cloud vernetzt fertigungsintegrierte Industriekameras mit skalierbaren Cloudumgebungen zur Bilddatenanalyse. Eine spezielle Systemarchitektur ermöglicht auch die Skalierung großer Analyseressourcen innerhalb des Fertigungstakts, so dass auch neuartige rechenintensive Algorithmen in zeitkritischen Anwendungen eingesetzt werden können. Messageorientierte Datenübertragung ermöglicht eine einfache PlugSense- Fertigungsintegration. Zahlreiche Studierende konnten im Rahmen von Studien- und Abschlussarbeiten Projekterfahrung in anwendungsorientierter Forschung sammeln. pot IHK Forschungstransferpreis 2018 Den IHK-Forschungstransferpreis 2018 in Silber erhielten Dr. Michael Spallek, Rommelag Engineering, Sulzbach Laufen und Prof. Dr. Uwe Gleiter, Hochschule Heilbronn. Sie haben gemeinsam in ihrem Projekt „Bottelpack Easy Empty“ mit Hilfe modernster Simulationstechnik eine neuartige und kostengünstige Infusionsflasche entwickelt, die sich im Gegensatz zu den herkömmlichen Infusionsflaschen auch unbelüftet vollständig entleert, bei hohen Temperaturen sterilisiert werden kann und deutlich weniger Kunststoffmaterial zur Herstellung benötigt. ugl Gastprofessor aus Durham Zur Stärkung einer bestehenden langjährigen internationalen Kooperation auf dem Gebiet der Fluiddynamik kam Herr Prof. Philip H. Gaskell aus dem nordenglischen Durham als Gastprofessor an die Hochschule und bot Studenten aus den Studiengängen MR und MB die Vorlesungen Strömungslehre und Modellbildung und Simulation in englischer Sprache an. Herr Gaskell betreut zudem einen Doktoranden im Studiengang MR. Die Gastprofessur wurde nach Antrag von Prof. Scholle durch den DAAD mit ca. 25.000 € unterstützt. Die Durham University steht im UK-Ranking auf Platz vier hinter Oxford, Cambridge und Imperial College und findet sich im internationalen Ranking unter den Top 100, vergleichbar mit der TU München oder Uni Heidelberg. msc Zurück zu Mechatronik und Robotik - Bachelor - Studierende Home Personensuche Impressum Kontakt © 2020 HHN Hochschule Heilbronn - Max-Planck Str. 39 - 74081 Heilbronn ',\n",
       "   'Title': 'MR-Aktivitäten - Hochschule Heilbronn',\n",
       "   'Upload-Date': '2020-06-18T00:42:06.083993Z'},\n",
       "  '_type': '_doc'},\n",
       " {'_id': 'vIEBxXIB7QWdo8C6vTMN',\n",
       "  '_index': 'mid_beispieldaten_v9',\n",
       "  '_score': 1.0,\n",
       "  '_source': {'Author': None,\n",
       "   'Course': '',\n",
       "   'Course_abbreviation': '',\n",
       "   'Course_location': '',\n",
       "   'Creation-Date': None,\n",
       "   'Last-Modified': None,\n",
       "   'Link': 'www.hs-heilbronn.de/1074136/partner-universities',\n",
       "   'Text': \" Partner Universities - Hochschule Heilbronn Skip to navigation Press Enter. Skip to main content Press Enter. home home Login DE EN Suchen Zielgruppen Die Hochschule Forschung Internationales Kooperation Login DE EN Studieninteressierte Studierende Mitarbeitende Lehrende Schulen Alumni Unternehmen Presse Hochschule Heilbronn Standorte Fakultäten Studiengänge für Interessierte Studiengänge für Studierende Heilbronn University Graduate School HUGS Semesterterminplan Grundordnung und Satzungen Öffentliche Bekanntmachungen Gremien und Beauftragte Rektorat Hochschulrat Senat Fakultätsräte Hochschulbeauftragte Personalrat Verfasste Studierendenschaft Zentrale Einrichtungen Bibliothek LIV Career Service Institut für mathematisch-naturwissenschaftliche Grundlagen IfG Rechenzentrum Schulkoordination Stipendienstelle Zentrale Studienberatung Zentrum für Studium und Lehre ZfSL Weiterbildung Berufsbegleitende Studiengänge Heilbronner Institut für Lebenslanges Lernen HILL HHN und Gesellschaft Familiengerechte Hochschule Vielfalt und Gleichstellung Kultur Nachhaltigkeit Verwaltung Intranet Personal Raumbuchung HHN als Arbeitgeber Stellenangebote Rund ums Arbeiten an der HHN Forschung Forschungsförderung Doktorandenkolleg Gründerzentrum STARTKLAR Institute International Office Unsere Partnerhochschulen Kontakt - Sprechzeiten Ins Ausland Studium im Ausland Praktikum im Ausland Sprachen Studieren an der HHN Internationale Vollzeitstudierende Incomings von Partnerhochschulen Heilbronn University of Applied Sciences Informationen zum Studium für Geflüchtete Partner werden Sponsoring Förderkreis Stiftungen Stiftungsprofessuren Angebote für Schulen Talente gewinnen Stipendien Studium mit vertiefter Praxis Firmenkontaktmessen Jobbörse Newsroom Portal Struktur und Organisation Projekte und Aktivitäten Forschung Career Service  Alumni International Activities Exchange Students Going Abroad Partner Universities Erasmus+ Staff Mobility Würth Incoming Scholarship Collaboration Opportunities International Day Schule  Hochschule 30 Jahre Campus Künzelsau Fakultät Technik und Wirtschaft TW Homepage Fakultät TW International Activities Partner Universities Partner Universities Following is the latest list of all the partner universities of Heilbronn University of Applied Sciences. To find a partner university applicable to you, please refer to your faculty the TW column then your Study Programme. HHN Partner Universities Alternatively, please refer to the list below for the faculty's partner universities that have already been extracted for you. To find out more about a particular partner university, please get in touch with the Contact Person for the respective partner university. We are also constantly expanding our international network! Be the first to know of any new partnerships or latest news by following us on facebook. Erasmus+ Partner Universities for the Faculty of Engineering and Business TW Austria FH Kufstein Tirol Study Programme: BK, EM Contact Person: Prof. Dr. Thomas Bezold BK, Prof. Dr.-Ing. Ekkehard Laqua EM Belgium EPEHC Haute École Économique et Technique Study Programme: BM Contact Person: Prof. Dr. Joachim Link HELMo Haute Ecole Libre Mosane Study Programme: BM, MBM Contact Person: Prof. Dr. Joachim Link Howest Study Programme: BK, BM Contact Person: Prof. Dr. Thomas Bezold UCLL Hogeschool Univeristy College Leuven-Limburg Study Programme: BM, BS Contact Person: Prof. Dr. Lothar Nadler BM, Prof. Dr. Elisabeth Schloeder BS Denmark International Business Academy Study Programme: BM Contact Person: Prof. Dr. Joachim Link Finland Haaga-Helia University of Applied Sciences Study Programme: BK, MBK Sports Management Contact Person: Prof. Dr. Thomas Bezold JAMK University of Applied Sciences Study Programme: BK Contact Person: Prof. Dr. Louise Bielzer Kajaani University of Applied Sciences Study Programme: BK, MBK, BS, MBM Contact Person: Prof. Dr. Thomas Bezold Lahti University of Applied Sciences Study Programme: BM, MBM Contact Person: Prof. Dr. Joachim Link Metropolia University of Applied Sciences Study Programme: BK Exchange available only in Summer Semester; arrival by the end of January at the latest. Contact Person: Prof. Dr. Raphaela Henze Satakunta University of Applied Sciences Study Programme: BM, MBM Masters programme is part-time. Contact Person: Prof. Dr. Joachim Link France Université du Littoral Côte d'Opale Study Programme: BM Contact Person: Prof. Dr. Joachim Link Université Paris 13 Study Programme: BM Contact Person: Prof. Dr. Joachim Link Ireland Dundalk Institute of Technology Study Programme: BK Contact Person: Prof. Dr. Thomas Bezold Institute of Technology Carlow Study Programme: BM, EM Exchange available only during Winter Semester. Contact Person: Prof. Dr. Joachim Link BM, Prof. Dr.-Ing. Ekkehard Laqua EM Institute of Technology Tralee Study Programme: EM Contact Person: Prof. Dr.-Ing. Ekkehard Laqua Limerick Institute of Technology Study Programme: EM Contact Person: Prof. Dr.-Ing. Ekkehard Laqua University of Limerick Study Programme: EM Contact Person: Prof. Dr.-Ing. Ekkehard Laqua Italy Università Cattolica del Sacro Cuore Study Programme: BK, MBK, BM, MBM Contact Person: Prof. Dr. Louise Bielzer Università degli Studi di Siena Study Programme: BK, BM Contact Person: Prof. Dr. Axel Birk Latvia University of Latvia Study Programme: BK, MBK, BM, MBM Contact Person: Prof. Dr. Dietmar Högel Liepaja University Study Programme: BK Contact Person: Prof. Dr. Thomas Bezold BA School of Business and Finance Study Programme: BM Contact Person: Prof. Dr. Joachim Link The Netherlands Breda University of Applied Sciences Study Programme: BK, BM Exchange for one year, due to its trimester curriculum. Contact Person: Prof. Dr. Thomas Bezold Fontys University of Applied Sciences Study Programme: BK, BM Contact Person: Prof. Dr. Thomas Bezold BK, Prof. Dr. Joachim Link BM The Hague University of Applied Sciences Study Programme: BM Exchange available only in Summer Semester February-July. Contact Person: Prof. Dr. Joachim Link Hanze University of Applied Sciences Study Programme: BK Sports Management Contact Person: Prof. Dr. Thomas Bezold Rotterdam University of Applied Sciences Study Programme: BM Contact Person: Prof. Dr. Joachim Link NHL Stenden University of Applied Sciences Study Programme: BK Contact Person: Prof. Dr. Thomas Bezold Spain Universidad Europea Valencia Study Programme: BM, MBM Contact Person: Prof. Dr. Joachim Link Universidad del País Vasco Study Programme: EM Contact Person: Dr. Sol Marina Garay Universidad Politécnica de Madrid Study Programme: AE, BM, MBM, ET, EM, MEE, MTM, WI Contact Person: Prof. Dr. Marcus Meyer Universidad Rey Juan Carlos Study Programme: EM Contact Person: Dr. Sol Marina Garay Sweden Karlstads Universitet Study Programme: BM, MBM Contact Person: Prof. Dr. Joachim Link Linnéuniversitetet Study Programme: BK, BM Contact Person: Prof. Dr. Thomas Bezold Mälardalen University Study Programme: BM, MBM Contact Person: Prof. Dr. Joachim Link Örebro Universitet Study Programme: BK, MBK Contact Person: Prof. Dr. Thomas Bezold Turkey Haliç Üniversitesi Study Programme: BK, MBK Contact Person: Prof. Dr. Thomas Bezold Marmara Üniversitesi Study Programme: BK Contact Person: Prof. Dr. Raphaela Henze Yaşar Üniversitesi Study Programme: EM Contact Person: Prof. Dr.-Ing. Mohamed Ibrahim United Kingdom Bournemouth University Study Programme: BK Sports Management Contact Person: Prof. Dr. Thomas Bezold Northumbria University Study Programme: WI Contact Person: Prof. Dr.-Ing. Jürgen Ulm Solent University Study Programme: BK Contact Person: Prof. Dr. Thomas Bezold University of Central Lancashire Study Programme: BK Sports Management Exchange for two semesters. Contact Person: Prof. Dr. Thomas Bezold Global Partner Universities for the Faculty of Engineering and Business TW Brazil Federal University of Pernambuco Study Programme: BM English courses offered only during summer semester. Contact Person: Prof. Dr. Joachim Link China Heilongjiang International University Study Programme: BM Contact Person: Prof. Dr. Joachim Link Shanghai Normal University Study Programme: AE, EM, ET, WI Contact Person: Prof. Dr.-Ing. Andreas Krug Shenzhen Technology University Study Programme: AE, ET, WI Contact Person: Prof. Dr.-Ing. Jürgen Ulm Guatemala Universidad del Istmo Study Programme: BM Contact Person: Prof. Dr. Joachim Link Hong Kong Lingnan University Study Programme: BK Contact Person: Prof. Dr. Louise Bielzer Indonesia University of Tarumanagara Study Programme: BM Contact Person: Prof. Dr. Lothar Nadler Switzerland University of Applied Sciences HTW Chur Study Programme: BK, MBK Contact Person: Prof. Dr. Thomas Bezold Vietnam British University Vietnam Study Programme: BK Contact Person: Prof. Dr. Louise Bielzer Zurück zu Fakultät Technik und Wirtschaft TW Home Personensuche Impressum Kontakt © 2020 HHN Hochschule Heilbronn - Max-Planck Str. 39 - 74081 Heilbronn \",\n",
       "   'Title': 'Partner Universities - Hochschule Heilbronn',\n",
       "   'Upload-Date': '2020-06-18T00:42:39.586380Z'},\n",
       "  '_type': '_doc'},\n",
       " {'_id': 'vYEBxXIB7QWdo8C6vTMN',\n",
       "  '_index': 'mid_beispieldaten_v9',\n",
       "  '_score': 1.0,\n",
       "  '_source': {'Author': None,\n",
       "   'Course': '',\n",
       "   'Course_abbreviation': '',\n",
       "   'Course_location': '',\n",
       "   'Creation-Date': '2016-11-24T20:44:41',\n",
       "   'Last-Modified': '2016-11-24T20:44:41',\n",
       "   'Link': 'www.hs-heilbronn.de/12598639/IMG_8515_JPG.jpg',\n",
       "   'Text': None,\n",
       "   'Title': None,\n",
       "   'Upload-Date': '2020-06-18T00:40:12.871729Z'},\n",
       "  '_type': '_doc'},\n",
       " {'_id': 'voEBxXIB7QWdo8C6vTMN',\n",
       "  '_index': 'mid_beispieldaten_v9',\n",
       "  '_score': 1.0,\n",
       "  '_source': {'Author': None,\n",
       "   'Course': '',\n",
       "   'Course_abbreviation': '',\n",
       "   'Course_location': '',\n",
       "   'Creation-Date': '2014-03-21T14:21:15Z',\n",
       "   'Last-Modified': '2014-05-09T13:02:14Z',\n",
       "   'Link': 'www.hs-heilbronn.de/6352921/Criteria-for-Coasting-on-Highways-for-Passenger-Cars.pdf',\n",
       "   'Text': ' Abstract This study quantifies fuel savings and conditions for the application of coasting phases, i.e. the vehicle rolling without traction force in an automated driving strategy, herein named economic cruise control ECC. Under the presumption of a driver input lead velocity and a limit of acceptable delta speed deviation, fuel savings can achieve values of 5  to just above 10  on highways traveling with a conventional, nonhybridized powertrain, assuming that the ICE is stopped upon coasting. Lower mean speed driving yields relatively higher savings. Reference is constant speed driving at the identical mean velocity, such that an ECC function may obtain somewhat higher savings in real traffic environment. For a first version of driving and powertrain control strategy it could be shown, that the fuel economy of a hybridized powertrain can benefit from coasting, too. For the initiation of the coasting phase, a criterion has been derived by defining a ‘coasting preview length’ CPL function, which can be analytically calculated at each point of the road, if its altitude profile is known. Since downhill coasting seems to be the naturally acceptable case, the CPL function shows a rather sharp increase when approaching the hill summit. The point of inflection of the CPL function was identified as criterion for the earliest reasonable point to start coasting. Introduction Though fuel prices showed certain intermediate decreases in the past due to modern methods of hydrocarbon exploitation and global economic developments, a general tendency to rising fuel costs can be expected for the future. Hence efficiency will remain a crucial requirement for any product of the automotive industry. Furthermore a strong drive to minimize fuel consumption is brought about by legal limitations such as the ‘Corporate Average Fuel Economy’ in the US or the 95 € imposed by the European Union monetarising each g CO2 emissions. Classical approaches such as more efficient powertrain systems and designs for reduced vehicle weight and drag stay promising and receive considerable investments. However, non-conventional measures such as systems assisting drivers to employ more efficient ways of driving become more attractive for industry, consumers and researchers. Often they are referred to as ‘eco-drive’ or similar. The traditional test procedures to measure fuel consumption such as the NEDC in Europe or the US FTP do not capture all relevant driving conditions: For instance, considerable parts of engine loads and vehicle velocities are excluded or only integrated in minor percentages. There is recently a global development towards more realistic or demanding test procedures, either nationally or with the aspect of global standardization, leading to a WLTP. However, these advanced test procedures continue to be defined on flat road profiles. Thus, the considerable percentage of road traffic having uphill and downhill stretches will not be included explicitly. This study should contribute to quantify positive effects on fuel consumption, if the road profile was integrated reasonably into the driving strategy. The basic idea is to apply phases of coasting on downhill parts of the road. Here coasting is understood as the vehicle rolling without any positive =driving or negative traction force. Some recent contributions from automotive industry deal with coasting as a part of future strategy to improve users\\' fuel economy, e. g. [1] and [2]. With conventional, non-hybridized ICE-driven powertrains actually in series, coasting means the ICE idling at low rpm due to the powertrain disengaged either by the clutch or neutral gear. This coasting operation is to separate from overrun conditions with engaged gear and the ICE at higher rpm defined by the total transmission ratio and the vehicle speed. Start-stop-systems are widely common today, which shut off an ICE at or close to zero vehicle speed. And the electrification of auxiliaries is coming up providing many perspectives. Thus conventional powertrain systems which may stop an ICE also Criteria for Coasting on Highways for Passenger Cars 2014-01-1157 Published 04/01/2014 Hermann Koch-Groeber and Jue Wang Heilbronn University ASE CITATION: Koch-Groeber, H. and Wang, J., \"Criteria for Coasting on Highways for Passenger Cars,\" SAE Technical Paper 2014-01-1157, 2014, doi:10.4271/2014-01-1157. Copyright © 2014 SAE International Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM at higher speed are announced for the near future, 2014 [3]. Furthermore, for manual transmission systems dominating some passenger car markets, development is ongoing to establish clutch-by-wire technology [4], which would enable an automated coasting strategy without taking off the established MT handling from the car. On the other hand, widespread automatic transmissions have already realized a disengagement of the powertrain and even ICE stop, introduced in their hybrid versions in today\\'s series [2]. Criteria for Coasting Methodology and Assumptions Modeling calculations in this study are performed either by the commercial software “CRUISE” of AVL List GmbH or by calculation in a personal computer based spreadsheet. A step width of 10 m was applied and regarded sufficient since fuel efficient driving at highway speeds above 70 km/h can be reduced to the use of highest gear and entails rather low longitudinal dynamics, herein commonly below 1 m/s2. Reference Vehicle This research project “ECC” includes on-road vehicle testing as it has been documented in [5]. So the simulation results of this contribution are basing on a virtual car of the same type: Ford of Europe Focus Sedan 5-door with 1, 6 T ecoboost 110 kW 6-speed MT model year 2012. It is equipped with a modern turbo-charged 4 cylinder gasoline DI-engine as moderate downsizing concept. This motorization provides decent power reserves at the regarded traveling speeds of 70 to 130 km/h and road gradients. The reference data of table 1 enters the following simulations. Table 1. Data of reference vehicle Fuel Consumption Map This study is based on a generic map of fuel consumption such that it can be easily adapted to different motorizations. This approach is following studies of Rohde-Brandenburger [7], [8]: Fuel consumption as function of engine rpm and load can be calculated as summation of a zero power part and a second summand for the mere power output increase. This can be depicted as a Willans diagram, shown for the data of this study in figure 1. Figure 1. Willans diagram showing fuel consumption mass flow as composed of zero power part and a gradient with power output: constant initially and slightly curved up close to maximum power Derived from a broad variety of gasoline engines of Volkswagen AG, according [8] the zero power output fuel consumption VdotzeroP,1l in l/h, normalized on 1 liter engine displacement, follows with little tolerance a polynomial of 2nd order in rpm in min−1. 1 The absolute term has been increased for this study from 1,29·10−1 l/h in order to fit the data taken from the reference vehicle. This value VdotzeroP is essential to understand why coasting may save fuel even when the engine is idling: For this engine operating at 3000 rpm, already 2,1 liter of fuel is consumed just to keep the engine at its speed, without yielding any mechanical output power. Hence, lowering the engine speed to an ordinary low idling just below 800 rpm reduces this part of fuel consumption to 0,57 l/h, such that the effect of fuel cut-off by overrun operation is often over-estimated, while overrun constantly draws energy out of the running vehicle. This expresses the well-known fact, that any ICE tends to operate with diminishing efficiency at high rpm and low loads. Following [8], many gasoline engines show a fixed value of 0,27 l/h per kW for the fuel consumption just for the increase of power output, shown as the constant gradient curves in the Willans line diagram. Since Rohde-Brandenburger focused on NEDC operation at low engine loads, he limited his analysis to this linear characteristics. This study, however, requires engine operation also at higher loads. So it has been chosen an additional third order approach leading to 2 Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM This equation leads to the SFC values as shown in the isoline diagram in figure 2 for the relevant rpm area. Key values are given in table 2. Figure 2. Map isolines for specific fuel consumption in the relevant range of ICE operation Table 2. Key values of specific fuel consumption SFC map These characteristics may underestimate the SFC increases under maximum engine load operation due to fuel enrichment, especially for downsized turbo-charged engines. For the purpose of a fuel efficient driving strategy this operation area has to be avoided anyway. According to previous studies with varying SFC mappings [6] the best fuel consumptions are achieved with accelerations around 60 of maximum engine loads i.e. effective torques, which has been chosen as the standard value for vehicle accelerations within this study. Reference Road Profiles The use of navigation data, especially altitude profiles, for improving fuel efficiency has been dealt with previously, e. g. [9]. This study aims at a quantification of the effect of coasting on downhill road passages under defined circumstances. Hence two profiles have been chosen as references, displayed in figure 3. One hill is named “flat” with maximum slopes of 2,5  and a total altitude difference of 27,2 m over a length of 4 km. The top of this hill is exactly at half the total length. The other “steep” hill reaches gradients up to 6,2  with an altitude difference of 41,4 m. This hill profile is complete at its starting altitude after 2330 m. In this study the reference track named “steep hill” is extended by a flat track to the equal total length of 4 km. Figure 3. Road profiles of two reference hills, as one side selected from German motorway A81 and completed by mirroring Both reference hills were composed symmetrically by mirroring a real profile from hilly German motorway A81 between exits Heilbronn-Untergruppenbach and Pleidelsheim north of Stuttgart, basing on data from the LGL office for geoinformation of the state of Baden-Württemberg. This three lane motorway had been completely rebuilt in the 1980s, such that its profile may be taken as a sample applying modern highway tracing. This selection should enable the deduction of general principles for the use of downhill coasting phases to save fuel: roads with steeper gradients exist, especially in mountainous areas. They would require additional braking to limit driving speeds to safe values, thus going beyond the scope of this work. Many international multi-lane long distance freeways tend to limit their maximum gradients to these values around 6  with few exceptions. The “flat” hill shows potentials for coasting at typical road profiles for hilly areas. Assumptions for the Validation of Driving with Coasting Scope of this study is the field of long distance driving with passenger cars or light duty vehicles. Therefore two reference velocities are chosen: 120 km/h 74,6 mph should represent travelling on a multi-lane freeway type road, whereas 90 km/h 55,9 mph stands for overland driving on single lane highways under limited speed conditions. In order to derive conclusions for the pure effect of integrating coasting phases into the driving strategy, this study relies on this quite ideal environment. Real circumstances such as occasions of necessary decelerations due to speed limits, road curvature or traffic situations will pose additional conditions. However, if a coasting strategy were once integrated in the general driving strategy it can be deduced that coasting can as well contribute to fuel efficiency at situations of externally required decelerations. This consideration is valid for the slower traffic in congested urban areas, too, especially if communications car-to-infrastructure or car-to-car were taken into account. The quantification of coasting benefits under these conditions goes beyond this study, too. The higher average travelled distances for those vehicles of the population, which are dominantly used in freeway and overland riding, render an improved fuel efficiency to contribute considerably to the integrative progress of slowing down Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM depletion of resources and emission of greenhouse gases. Furthermore, an efficient use of coasting may benefit the fuel efficiency of hybrid vehicles especially in highway conditions, where their advantage today shows to be less impressive than in urban driving. Lee [10] showed perspectives in this field, though he did not take the road gradient profiles into account. On a vehicle with manual transmission such as the reference car of this project, coasting with the engine idling can be realized by shifting to neutral in many circumstances without endangering the traffic environment. Some cars in series production with conventional powertrains, e. g. VW Passat blue motion technology with dual clutch gearbox, offer coasting features such that the engine does not go to overrun when the driver releases the acceleration pedal completely but disengages the powertrain and make the car coast [11]. Also on widespread torque converter type automatic gearboxes coasting functions may be integrated, being reality in their hybridized vehicle applications, e. g. Daimler\\'s S350 hybrid [2]. Beyond the driver dependent initiation of coasting the main focus of this project is to investigate possibilities of an automated driving strategy, herein named ECC for Economic Cruise Control. This work should contribute by establishing criteria when and how to realize this ECC idea for maximum benefit. One main assumption is related to the aspect of velocity variation. Unlike classical cruise control CC known for decades, any reasonable ECC function will have to include a certain variation of its actual speed. Nowadays this is state of the art because ACC functions with radar based distance sensing are common which automatically decelerate and accelerate the car, too. The basic idea for an ECC function still starts with a setpoint value for vehicle speed, either manually set by the driver or imposed by autonomous sensing systems such as traffic sign identification, distance radar, navigation or even car-to-car or cloud data. Additionally the straightforward approach for any ECC functionality appears to set maximum delta values for the speed variation. One central argument is the acceptance of such a function: if the driver set the command velocity to 100 km/h, it may be assumed that a speed variation between e. g. 103 km/h and 95 km/h would be accepted in most cases. Presumption thereby is the low dynamics of acceleration in top gear and deceleration by coasting. A car varying autonomously its speed between 60 km/h and 130 km/h when the setpoint speed was 100 km/h, unless forced to by traffic circumstances, will presumably not gain positive reactions by owners. Hence, the values of speed deviation seem to be a crucial parameter for ECC function development. As shown in the preliminary studies within this research project [5], [6] and by other authors, e. g. [1] fuel savings by coasting are around 5  in many cases. Savings can reach values above 10  under favorable circumstances. These values appear limited or even marginal. Comparing to the efforts of reducing energy losses or weight of vehicle components, the expenditures to realize an ECC functionality seem to be still well worth considering. These limited values of realistic fuel saving by coasting lead to the conviction that this study as engineering/physical quantification of fuel savings must be based on constant mean velocity cases, since saving fuel by driving less fast is a trivial fact. Table 3 quantifies this dependency for the reference cases of this study: Around 90 km/h, 5  deviation in mean velocity gives almost 5  change in fuel consumption, while the same relative change from the mean velocity even alters fuel consumption by more than 6 . Values for the hill type “steep” differ very little from the values shown here. So fuel savings of some percent may only be proven if it is certain that the mean speed remains constant. Table 3. fuel consumptions upon constant speed driving no coasting On the other hand it should not be precluded as second order effect that any eco-drive function such as ECC might entail a certain slowing down as additional contribution to the perceived fuel savings, being crucial for the acceptance and economic success of such a function. This question, however, goes well beyond the engineering focus of this study to questioning aspects of traffic psychology. Scenarios of Coasting Starting Point Optimization for Coasting without Prior Boost Acceleration The first criterion to be identified is the point of starting the coasting phase. Figure 4 shows possible velocity profiles on the flat reference hill for a mean velocity of 90 km/h, varying from starting well ahead of the summit at 2000 m to points already on the downhill stretch of the hill profile. Outside the coasting phase the vehicle speed has been maintained constant. The value has been taken as degree of freedom in order to fulfill the requirement of identical mean velocity. Hence, for the shorter coasting phase at the earliest starting point 1800 m this constant speed is somewhat lower. Figure 5 displays the effect on fuel consumption in two curves: the higher one gives the values if the ICE was kept idling in the coasting phase. The minimum FC of 4,28 l/100km is equivalent to a fuel saving of 3,8 . The lower red curve shows fuel consumption with the assumption of an engine start-stopsystem including 400 μl fuel needed to restart the warm engine. Its minimum reaches 4,09 l/100km, meaning 8,0  of fuel saving compared to the fuel consumption at constant speed of 4,44 l/100km. Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM Figure 4. Velocity profiles for coasting on reference hill “flat” at mean velocity of 90 km/h Figure 5. Fuel consumption, relative coasting time and velocity split for coasting on reference hill “flat” at mean velocity of 90 km/h Interestingly these savings do hardly depend on the point where the coasting phase was initiated. The minimum in fuel consumption has a very flat characteristic. Only if coasting is started too early, here at 1800 m, the fuel economy is significantly worse. This mostly quite plane curve enables to apply an automated ECC driving strategy such that the initiation of coasting may be taken as a certain degree of freedom, for instance letting it depend on traffic circumstances, without trading in much of the saving benefit. This statement remains unchanged, regarding driving a lot faster over the “steep” reference hill with otherwise identical circumstances, given in figure 6. The minimum fuel consumption follows once again has a very low curvature, so any automation may profit of this degree of freedom. Only in case the coasting starts too early, the fuel consumptions show a step characteristic trading in all saving potentials. In figures 5 and 6, values of the relative length of the coasting phase are depicted, too. For the flat hill in figure 5, the length of coasting phase yields a good correlation to the fuel consumption: the longer the car is coasting at low idle or engine stop, the less fuel is consumed by the part needed to keep the ICE at the higher rpm without creating power output. For the steep hill, shown in figure 6, this tendency prevails only for the late starting point of coasting. If it was initiated to early, the fuel consumption slightly increases although the coasting phase reaches the highest values. Figure 6. Fuel consumption, relative coasting time and velocity split for coasting on reference hill “steep” at mean velocity of 120 km/h Figure 7 is showing the velocity profiles of the case of figure 6. It gives an explanation for this effect: the long coasting phases starting early curve for 1020 m require a significantly increased constant speed value for the other parts of the model hill, depicted as higher velocity split values in figure 6, too. Once again this higher speed level is derived from the requirement to drive the 4 km stretch at constant mean velocity. Hence, these increased speed parts lead to more than proportional increased driving resistances due to the velocity squared dependency of the drag. Figure 7. Velocity profiles for coasting on reference hill “steep” at the mean velocity of 120 km/h Figures 6 and 7 depict a special feature of the steep hill drive: For the starting points at 970 m and before, the coasting phase ends even before the steepest downhill parts are reached, where the rolling car gets accelerate just by gravity. With this short coasting phase, the controlled constant speed outside the coasting phase remains lower. However, shown in figure 6, the fuel saving effect is drastically reduced. These findings strengthen the general tendency that an extension of coasting phases to its maximum benefits the fuel saving potential. Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM Coasting Preview Length CPL as Criterion to Initiate Coasting Phases From the previous paragraph it was learned that there is a rather determined point before which a coasting phase should not be initiated. For an application of an automated ECC function under the condition of a known road profile, a general ‘rule’ to identify this point would be a key criterion. A further demand will be that such a rule would not require much of the calculation resources in any ECU, since they are still limited in spite of tremendous power enhancements because of broadened functionalities, e. g. for OBD purposes. A simplified energy balance of the vehicle rolling without tractions force may be taken as basis for such a rule: 3 With the driving resistances 4 and the kinetic Energy mλ stands for the mass increased by the factor λ accounting for the rotating masses 5 It leads to a differential equation 6 which is solved by stepwise numerical integration to yield 7 Coasting preview length CPL is determined at each point s0 under the boundary conditions of known velocity vs0 and altitude function hs and limited by a given maximum value of Δv. [11] In praxis this maximum speed deviation Δv is determined as a minimum speed value: As shown in the previous paragraph, longer coasting phases support fuel savings, whereas the lowest speed where to finish the coasting phase appears to be crucial parameter for the acceptance of driving strategy with coasting. Figure 8 shows the CPL as function of s0 in the relevant area over the flat reference hill. For a constant speed of 90 km/h when starting to coast, different graphs depict the influence of allowed minimum speeds. Evidently the coasting phase becomes longer with decreasing minimum speed. And there is a maximum in coasting lengths slightly advancing from points behind the top of the hill. Figure 8. CPL Coasting Preview Length for different minimum speed for a mean velocity of 90 km/h - zoomed around the summit of flat hill Most helpful, however, appears to be the sharp rise in CPL values before its maximum. This coincides with the drastically increasing coasting lengths in the velocity profiles of figure 4 and the relative coasting times shown in figure 5, providing the earliest starting point for the coasting phase to yield good fuel savings. Regarding the comparable CPL curve for a minimum speed value of 80 km/h in figure 8, the optimum point to trigger the coasting appears to be the point of inflection of the CPL function. The change of gradient in stepwise on-board calculation of CPL is judged as easily being identified. Figure 9 gives the CPL curves for the higher average velocity of 120 km/h, with adapted minimum speed values. The global characteristics prevail: The maxima of CPL increase and move forward for increasing velocity deltas. Once again, for each assumed minimum speed there is a well identifiable point of deflection in the CPL curve, with good coincidence to the earliest starting point where a coasting phase would pay off. Figure 9. CPL Coasting Preview Length for different minimum speed for a mean velocity of 120 km/h Figure 10 displays the case of fast driving over the steep hill, where the characteristic is somewhat strengthened, showing sharp rises of the CPL curves. Their deflection point coincides with the point of early starting the coasting phase, as discussed the values around 1000 m at figure 7. Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM Figure 10. CPL Coasting Preview Length for different minimum speed over the steep hill for a mean velocity of 120 km/h Besides the starting point the CPL function seems to yield a criterion whether it would be worth to start coasting at all: if the downhill stretch was short and with little road gradient, the first derivative dCPL/ds would stay small such that a limit on its value may serve as borderline, in order not to stress vehicle components or drivers with too many short coasting phases. Velocity Delta Dependency In the first paragraph varying the starting point of the coasting phase already different velocity deltas were observed due to the prerequisite that the mean velocity must be kept constant. However, the minimum speed was not changed. In figure 11 the velocity profiles are depicted depending on this parameter: lower minimum speeds entail longer parts coasting at rather low velocities. To maintain the mean speed this has to be balanced by considerable increased constant speeds beyond the coasting phase, reaching a value above 100 km/h already for 70 km/h as minimum speed. Figure 11. Velocity profiles for coasting on reference hill “flat” at mean velocity of 90 km/h with different minimum speed values Figure 12 shows a clear effect: the lower the minimum speed reached in the coasting phase the higher the fuel efficiency becomes, unless a minimum was not exceeded. At minimum speed values of 73 km/h and 70 km/h the fuel savings attain more than 10 . But their speed deltas of close to or even above 30 km/h are considered to be unacceptable for many drivers and traffic situations. Thus it appears that an ECC driving strategy will have to equilibrate fuel savings and velocity variations. Figure 12. Fuel consumption, relative coasting time and velocity split for coasting on reference hill “flat” at mean velocity of 90 km/h A further point must be discussed about figure 11: the assumed constant speed values outside the coasting area may be contradicting drivers\\' expectance as well: for a mean velocity object of 90 km/h, referring to the classical cruise control function, it will not be convincing to be forced to travel outside the costing phase with significantly higher speed. Though this deviation would be lower if the considered distance was extended to more than 4 km, it seems reasonable to compensate in the direct environment of the coasting phase for the parts of coasting at speeds below the mean value. This leads to the point whether it would be useful to accelerate just before initiating a coasting phase. This approach is referred to as ‘boosting’ within this study. Benefits of Boost Accelerations Before Coasting In figure 13 different realizations of a boost before coasting is displayed, identified by their minimum velocities, whereas figure 14 gives their fuel consumption results. First of all it is found that with the help of boosting the constant speed entering and leaving the hill drive can be set to the desired mean speed and still the coasting reduces the fuel consumption noticeably: for a limited velocity delta, taking 80 km/h as minimum speed, the fuel consumption is reduced by 8,7 . Figure 13. Velocity profiles for coasting preceded by boosting with different minimum speed values Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM Figure 14. Fuel consumption, relative coasting time for coasting with preceding boosting As it has been observed before with no boosting, lowering the velocity split by increasing the minimum speed, the fuel economy deteriorates. Even the additional idea of a subsequent second boosting and coasting phase does not seem completely convincing. Though the fuel savings improve, as the coasting part riding with low idling or zero rpm increases, a higher frequency of changing coasting and boosting must be seen critical: will drivers accept this behavior, even though the zigzag characteristics of the speed do not mean uncomfortable and shaky driving because of the low dynamics of deceleration and acceleration in the top gear at 60  engine load, which is comparable to established accelerations in automated cruise control systems? Besides the aspect on the passenger cars, vehicle subsystems such as starter motors and exhaust gas treatment would profit not only in lifetime, if they were started and shut down less often. At the opposite side regarding large delta speed, figures 13 and 14 show rather little effect by varying the point of boosting start: The values for the minimum speed of 71, 9 km/h and 72, 5 km/h, respectively, do not mean significant differences in fuel savings, although the later starts boosting already at 1720 m, 270 m earlier than the standard starting point. Hybridization Modeling and Simulation Results The objective of the hybrid vehicle simulation study presented in this section is to give a first outline for additional benefits considering coasting at hybrids. The downhill potential energy can be either used to charge the battery by an electric machine, e.g. the operation strategy BMW ActiveHybrid 5 [13], or directly used to overcome the driving resistance by coasting [12] which is supposed to be more efficient due to the higher efficiency in the powertrain. For that case a preliminary coasting strategy is simulated herein. Hybridization Modeling The reference vehicle Ford Focus is virtually hybridized by adding the electrical drive axle on the vehicle rear axle. Figure 15 shows the configuration of this hybridization. An additional clutch connects the ICE and one electric machine “Generator”, which enables the battery charging by ICE. The other electric machine “E-Motor” is directly connected with the rear axle, which can either deliver the traction power or charge the battery by braking energy recuperation. Figure 15. Hybridized reference vehicle powertrain configuration The characteristics of the main additional powertrain components are given in Table 4. The two electric machines share the same specification. Table 4. Characteristics of the additional hybrid components Simulation Method The “steep” hill profile is simulated in AVL Cruise for two average driving velocities, 120 km/h and 90 km/h. The road profile is divided into three sections: section 1 uphill, section 2 downhill and section 3 flat. As shown in Figure 16, 10 cases are simulated, which consider different hybrid operation modes in the three sections. Case 1 is a simulation of the conventional Ford Focus. Case 2 is pure electric vehicle driving simulation. In Case 3 to 8 the vehicle power is delivered either only from ICE or from E-Motor in one complete section. In section 3 of case 9 the ICE mode is involved for the battery SOC balance. And the coasting is considered in case 10. The Case 1 to 9 are constant velocity driving. In case 10 there is velocity variation due to the coasting. The hybrid vehicle operation modes and corresponding ICE and electric machines ON/OFF states are shown in Table 5. The operation point shifting strategy is applied in the ICE mode. If the desired ICE load is less than the optimal load at current rotational speed, the operation point is shifted to the optimal operating line with the same rotational speed. This is also called “load point increase”. In this case, the ICE output torque is increasing. The ICE takes over all the propulsion power and deliver additional power to charge the battery via the Generator. Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM Figure 16. Simulation cases Table 5. Hybrid vehicle modes Simulation Results The simulation results of the hybridized Ford Focus are summarized in Table 6, which lists the fuel consumption FC, battery electrical energy consumption EC and equivalent fuel consumption eq. FC of each case. The equivalent fuel consumption is calculated by the sum of actual ICE fuel consumption and the converted ICE fuel consumption for battery charging to cover the electrical energy consumption. Equation 8 shows this fuel consumption conversion. 8 Where ηG is the efficiency of the Generator, ηB is the efficiency of the battery, SFCopt is the engine optimal specific consumption, ρf is the fuel density 0,76 kg/L for gasoline, and D is the distance 4km. The average velocities 120 km/h and 90 km/h do not have influence on the actual fuel consumption, which is indicated by case 3 to 8. Due to the relative low desired torque during constant driving, the ICE is working under the operation point shifting strategy most of time. Table 6. Steep hill simulation results The battery will be charged to high SOC level or even overcharged if the vehicle was powered by ICE more than one section, see case 4, 6, and 7. Due to the less energy requirement of velocity 90 km/h comparing with 120 km/h, the battery is also at relative high SOC level by ICE operating in the longest section 3, see case 8. However, only one section ICE powering causes an amount of battery discharging energy, see case 2, 3, and 5. In that case, the vehicle is set to the ICE mode for section 1 and part of section 3 to balance the battery SOC, see case 9 and 10.The fuel consumption improvements comparing with conventional vehicle Case 1 are shown in Figure 17.The remarkable improvement is given by Case 6. Comparing with the ICE, the E-Motor has higher efficiency in downhill section due to the low desired traction torque. Furthermore, in order to balance the battery SOC, the reduced ICE mode operating time is applied in Case 9, which has relative high fuel consumption improvement. As it was shown in the first paragraphs of this study, the conventional vehicle fuel consumption benefits from downhill coasting. Case 10 involves a coasting mode in the downhill section, which shows more fuel consumption improving potential also for the hybrid vehicle. The simulation detailed results of case 9 and case10 with average velocity 120 km/h are taken to be the example. The velocity variation and the torque maps of engine and two electric machines are shown in Figure 18. Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM Figure 17. Fuel consumption improvement In Case 10, the constant acceleration in section 1 is required to achieve the average velocity 120 km/h, because the downhill coasting causes vehicle velocity decreasing about 5 km/h. This acceleration required more energy from ICE, so that the Generator delivers less power to charge the battery while the ICE mode. This can be indicated by the Generator torque in Case 10, which is lower than in Case 9. The E-Motor in Case 9 recuperates parts of potential energy with relative low torque in Section 2. During the downhill coasting, the potential energy is totally used to overcome the driving resistances. At the beginning of Section 3 in Case 10, the vehicle required higher traction torque from ICE to reach the desired velocity 120 km/h. Figure 18. a Velocity map of Case 9 and Case 10; bTorque delivered by ICE, Generator and E-Motor for Case 9 and Case 10 with average velocity 120 km/h As it is shown in Table 6 and Figure 17, for 120 km/h average velocity the coasting improved the fuel consumption up to 6,49, which is 3  more than for constant driving Case 9. And the improvement for lower average velocity 90 km/h driving is as high as 10,52 . From the hybrid simulation result the following conclusions: • Traction by the E-Motor during high torque demand causes high equivalent fuel consumption due to the low efficiency of the energy path, which from ICE to battery and then further to electric machine. • The potential energy of the downhill road offers the benefit to fuel consumption improvement of the hybrid vehicle. It is more efficient to use this potential energy by coasting than by energy recuperation. • Comparing with the 120km/h, the lower average velocity 90km/h can benefit more from the downhill coasting. Conclusions 1. By coasting on highways passenger cars can achieve fuel savings up to 10  at a constant mean velocity of 90 km/h. 2. ECC, name of the driving strategy in this study, use downhill parts of the road for coasting in order to achieve drivers\\' acceptance and fuel savings. 3. With higher mean velocity, the relative savings decrease. So coasting tends to be most beneficial at overland travelling with medium speeds in hilly area. 4. The point to initiate the coasting phase yields a rather flat minimum of fuel consumption, leading to a considerable degree of freedom enabling to make the start point depend on traffic circumstances without spending the fuel saving potential significantly. 5. From a simplified energy balance of the rolling vehicle, a CPL function coasting preview length can be calculated, setting a maximum admissible delta velocity with respect to the actual speed. This CPL function shows a sharp increase and well defined deflection point when approaching the hill summit, which can be taken as criterion to initiate a coasting phase. 6. Increasing velocity deltas, allowing the vehicle to cruise down to relatively low minimum speeds, benefits the fuel savings up to a certain limit. This approach, however, has to be balanced to denial of acceptance for instantaneous vehicle velocities too much off the desired speed. 7. The introduction of a boosting phase just prior to the coasting period enables to limit the area of deviations from the desired speed. The benefits in fuel economy do mainly prevail, such that boosting seems to be a proper approach for an acceptable realization of an ECC strategy. 8. The downhill coasting offers a benefit to fuel consumption also for a hybrid vehicle. This improvement can amount to 2  to 3 with respect to a hybrid vehicle at constant velocity driving and 6,5  to 10,5  compared to a conventional vehicle. Coasting on the downhill section appears to be more efficient than energy recuperation via the electrified drivetrain. 9. Future work needs to cover further optimization, especially for the multidimensional hybrid load distribution. Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM References 1. Müller N., Strauss S., Tumback S., Christ A. Bosch: “Segeln-Start/Stopp-Systeme der nächsten Generation” MTZ 09/2011, 644ff 2. Weber T. Daimler AG, “Auto Mobility of the Future: Where does the Journey Lead”, 33rd Intl\\' Vienna Motor Symposium, 2012 3. Bohr B. Robert Bosch GmbH: Interview in “Stuttgarter Zeitung”, 12. April 2013 4. www.bosch-presse.de; “eClutch saves fuel and makes driving easier”, 12th Aug 2013 5. Koch-Groeber H., “Coasting on Highways - Potentials and Realization”; 13th Stuttgart Symposium 2013 6. Koch-Groeber H., Niermann H., Spoerer S., Vogelmann D., Wittemann E., „“ECC Economic Cruise Control”, VPC Virtual Powertrain Creation Conference, Esslingen, 2012 7. Rohde-Brandenburger K.: “Verfahren zur einfachen und sicheren Abschätzung von Kraftstoffverbrauchspotentialen”, HdT Haus der Technik Essen, 1996 8. Rohde-Brandenburger K.: “Was bringen 100 kg Gewichtsreduzierung im Verbrauch? Eine physikalische Berechnung”, ATZ 07-08/2013, 584-591 9. Varnhagen, R. and Korthaus, C., “Reduction of Fuel Consumption with Intelligent Use of Navigation Data,” SAE Technical Paper 2010-01-2004, 2010, doi:10.4271/201001-2004. 10. Lee J., “Vehicle Inertia Impact on Fuel Consumption of Conventional and Hybrid Electric Vehicles Using Acceleration and Coast Driving Strategy”, Dissertation, 2009, Virginia Polytechnical Institute 11. Lutz B., Willig J., “ECC Smartphone APP”, Master Project Report at Hochschule Heilbronn; 2014 12. Henn M., Loesche-ter Horst T., Schulze F., Bartsch P. et al. VW: “Energy efficient vehicle operation by intelligent longitudinal control and route planning”, 12th Stuttgart Symposium 2012 13. Griebel C., Rabenstein F., Klüting M., Kessler F., Kretschmer J., Hockgeiger E.: “The Full-Hybrid Powertrain of the new BMW ActiveHybrid 5”, 20. Aachen Colloquium Automobile and Engine Technology 2011 Contact Information Koch-groeber@hs-heilbronn.de Jue.wang@hs-heilbronn.de Mr. Hermann Koch-Groeber, Prof. Dr.-Ing. Mrs. Jue Wang, M. Sc. ASE Automotive Systems Engineering Faculty of Mechanics and Electronics Heilbronn University Max-Planck-Str. 39 74081 Heilbronn, Germany Acknowledgments The author thanks for the funding of this research project “ECC - economic cruise control” in the program “IngenieurNachwuchs 2010” young engineering talents of BMBF German Federal Ministry of Education and Research and for the support by the project partners: • GETRAG Getriebe- und Zahnradfabrik Hermann Hagenmeyer GmbH  Cie KG, D-74199 Untergruppenbach • IPEK - Institut für Produktentwicklung o. Prof. Dr.-Ing. Dr. h.c. A. Albers at Karlsruhe Institute of Technology KIT • IPETRONIK GmbH  Co. KG, D-76532 Baden-Baden • RA Consulting GmbH, D-76646 Bruchsal Definitions/Abbreviations ACC - Adaptive Cruise Control CPL - Coasting preview length ECC - Economic Cruise Control, as title of this research project acronym for the optimized driving strategy applying cruising phases ECU - Electronic Control Unit FC - Fuel Consumption ICE - Internal combustion engine NEDC - New European Driving Cycle according RL 70/220/ EWG MT - Manual Transmission OBD - On-Board Diagnosis PC - Passenger Car SFC - Specific Fuel Consumption WLTP - Worldwide harmonized Light vehicles Test Procedures The Engineering Meetings Board has approved this paper for publication. It has successfully completed SAE’s peer review process under the supervision of the session organizer. The process requires a minimum of three 3 reviews by industry experts. All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior written permission of SAE International. Positions and opinions advanced in this paper are those of the authors and not necessarily those of SAE International. The author is solely responsible for the content of the paper. ISSN 0148-7191 http://papers.sae.org/2014-01-1157 Downloaded from SAE International by Hermann Koch-Groeber, Wednesday, April 23, 2014 04:26:06 AM http://www.bosch-presse.de http://www.sae.org/technical/papers/2010-01-2004 http://dx.doi.org/10.4271/2010-01-2004 http://dx.doi.org/10.4271/2010-01-2004 http://papers.sae.org/2014-01-1157 ',\n",
       "   'Title': None,\n",
       "   'Upload-Date': '2020-06-18T00:41:59.349752Z'},\n",
       "  '_type': '_doc'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['hits']['hits'][:5] # Ansicht der ersten 5 Dokumenten zwckecks Plausibilisierung des Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generierung von einem Datensatz mit allen Infomationen\n",
    "#### **1** - Alle einzigartigen Features herausfinden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title', 'Creation-Date', 'Text', 'Link', 'Course_location', 'Author', 'Upload-Date', 'Course', 'Course_abbreviation', 'Last-Modified'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Auf Basis von den bereitgestellten und hochgeladenen Dokumenten werden alle einzigartige Features \n",
    "(inkl. Daten und Metadaten) erkannt und gespeichert. Diese werden nachher bei der Erstellung eines Pandas-Dataframes verwendet.\n",
    "'''\n",
    "\n",
    "features_alone = []\n",
    "all_features_list = [list(d['_source'].keys()) for d in response['hits']['hits']]\n",
    "for features in all_features_list:\n",
    "    for feature in features:\n",
    "        features_alone.append(feature)\n",
    "unique_features = set(features_alone)\n",
    "print(unique_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2** - Alle Nötige Infomation aus Elastic Search in einem Dataframe speichern - Hauptdatensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y4HqxHIB7QWdo8C6sjBU', 'aoHqxHIB7QWdo8C6sjBU', 'WoGYxHIB7QWdo8C6DCP5', 'woGhxHIB7QWdo8C6PCSS', 'u4EGxXIB7QWdo8C6XDQt', 'moEYxXIB7QWdo8C6vDfA', '-4HvxHIB7QWdo8C6WTBi', '3oFUxXIB7QWdo8C6ZEBN'] \n",
      "\n",
      "Fehleranzahl:  8 \n",
      "Fehlerquote:  0.10513865159679327 %\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Das Dataframe \"df\" ist das Hauptinput-Dataframe. In diesem Dataframe werden alle Informationen gespeichert, \n",
    "die noch zu bearbeiten sind.\n",
    "'''\n",
    "df = pd.DataFrame()\n",
    "error = []\n",
    "# Alle Informationen, die bearbeitet werden befinden sich unter den Keys ['hits']['hits']\n",
    "for doc in response['hits']['hits']:\n",
    "    # Try and Except als fehlertoleranter Ansatz\n",
    "    try:\n",
    "        # Extrahieren der Metadaten aus der ersten Ebene des Jason-Elements\n",
    "        d = {}\n",
    "        d['ID'] = doc['_id']\n",
    "        d['index'] = doc['_index']\n",
    "        d['score'] = doc['_score']\n",
    "\n",
    "        # Extahieren der Metadaten aus der zweiten Ebene  des Jason-Elements unter dem Key: \"_source\"\n",
    "        for feature in unique_features:\n",
    "            d[feature] = doc['_source'][feature]\n",
    "        df = pd.concat([df, pd.DataFrame(d, index=[len(df)])])\n",
    "    # Die Dokumente, die nicht ins Dataframes gespeichert werden könnten, werden in einer Liste gespeichert und \n",
    "    # können bezüglich der Vollständigkeit des Dokuments über das Key \"_id\" nachgeprüft werden\n",
    "    except:\n",
    "        error.append(doc['_id'])\n",
    "# Die fehlerhaften Dokumenten werden dargestellt\n",
    "print(error, '\\n\\nFehleranzahl: ', len(error), '\\nFehlerquote: ', len(error)/len(df)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Course</th>\n",
       "      <th>Course_abbreviation</th>\n",
       "      <th>Course_location</th>\n",
       "      <th>Creation-Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>Last-Modified</th>\n",
       "      <th>Link</th>\n",
       "      <th>Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>Upload-Date</th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019-11-19T12:17:15</td>\n",
       "      <td>uoEBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>2019-11-19T12:17:15</td>\n",
       "      <td>www.hs-heilbronn.de/_b/0000000000000024097716b...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-06-18T00:42:28.923728Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn Skip to...</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>vIEBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/1074136/partner-universities</td>\n",
       "      <td>Partner Universities - Hochschule Heilbronn S...</td>\n",
       "      <td>Partner Universities - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:39.586380Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2016-11-24T20:44:41</td>\n",
       "      <td>vYEBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>2016-11-24T20:44:41</td>\n",
       "      <td>www.hs-heilbronn.de/12598639/IMG_8515_JPG.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-06-18T00:40:12.871729Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2014-03-21T14:21:15Z</td>\n",
       "      <td>voEBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>2014-05-09T13:02:14Z</td>\n",
       "      <td>www.hs-heilbronn.de/6352921/Criteria-for-Coast...</td>\n",
       "      <td>Abstract This study quantifies fuel savings a...</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-06-18T00:41:59.349752Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Author Course Course_abbreviation Course_location         Creation-Date  \\\n",
       "0   None                                              2019-11-19T12:17:15   \n",
       "1   None                                                             None   \n",
       "2   None                                                             None   \n",
       "3   None                                              2016-11-24T20:44:41   \n",
       "4   None                                             2014-03-21T14:21:15Z   \n",
       "\n",
       "                     ID         Last-Modified  \\\n",
       "0  uoEBxXIB7QWdo8C6vTMN   2019-11-19T12:17:15   \n",
       "1  u4EBxXIB7QWdo8C6vTMN                  None   \n",
       "2  vIEBxXIB7QWdo8C6vTMN                  None   \n",
       "3  vYEBxXIB7QWdo8C6vTMN   2016-11-24T20:44:41   \n",
       "4  voEBxXIB7QWdo8C6vTMN  2014-05-09T13:02:14Z   \n",
       "\n",
       "                                                Link  \\\n",
       "0  www.hs-heilbronn.de/_b/0000000000000024097716b...   \n",
       "1  www.hs-heilbronn.de/21278004/rueckblick-2018-a...   \n",
       "2   www.hs-heilbronn.de/1074136/partner-universities   \n",
       "3      www.hs-heilbronn.de/12598639/IMG_8515_JPG.jpg   \n",
       "4  www.hs-heilbronn.de/6352921/Criteria-for-Coast...   \n",
       "\n",
       "                                                Text  \\\n",
       "0                                               None   \n",
       "1   MR-Aktivitäten - Hochschule Heilbronn Skip to...   \n",
       "2   Partner Universities - Hochschule Heilbronn S...   \n",
       "3                                               None   \n",
       "4   Abstract This study quantifies fuel savings a...   \n",
       "\n",
       "                                         Title                  Upload-Date  \\\n",
       "0                                         None  2020-06-18T00:42:28.923728Z   \n",
       "1        MR-Aktivitäten - Hochschule Heilbronn  2020-06-18T00:42:06.083993Z   \n",
       "2  Partner Universities - Hochschule Heilbronn  2020-06-18T00:42:39.586380Z   \n",
       "3                                         None  2020-06-18T00:40:12.871729Z   \n",
       "4                                         None  2020-06-18T00:41:59.349752Z   \n",
       "\n",
       "                  index  score  \n",
       "0  mid_beispieldaten_v9    1.0  \n",
       "1  mid_beispieldaten_v9    1.0  \n",
       "2  mid_beispieldaten_v9    1.0  \n",
       "3  mid_beispieldaten_v9    1.0  \n",
       "4  mid_beispieldaten_v9    1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Visualisierung des Dataframes zwecks Plausibilisierung.\n",
    "'''\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' MR-Aktivitäten - Hochschule Heilbronn Skip to navigation Press Enter. Skip to main content Press Enter. home home Login DE EN Suchen Zielgruppen Die Hochschule Forschung Internationales Kooperation Login DE EN Studieninteressierte Studierende Mitarbeitende Lehrende Schulen Alumni Unternehmen Presse Hochschule Heilbronn Standorte Fakultäten Studiengänge für Interessierte Studiengänge für Studierende Heilbronn University Graduate School HUGS Semesterterminplan Grundordnung und Satzungen Öffentliche Bekanntmachungen Gremien und Beauftragte Rektorat Hochschulrat Senat Fakultätsräte Hochschulbeauftragte Personalrat Verfasste Studierendenschaft Zentrale Einrichtungen Bibliothek LIV Career Service Institut für mathematisch-naturwissenschaftliche Grundlagen IfG Rechenzentrum Schulkoordination Stipendienstelle Zentrale Studienberatung Zentrum für Studium und Lehre ZfSL Weiterbildung Berufsbegleitende Studiengänge Heilbronner Institut für Lebenslanges Lernen HILL HHN und Gesellschaft Familiengerechte Hochschule Vielfalt und Gleichstellung Kultur Nachhaltigkeit Verwaltung Intranet Personal Raumbuchung HHN als Arbeitgeber Stellenangebote Rund ums Arbeiten an der HHN Forschung Forschungsförderung Doktorandenkolleg Gründerzentrum STARTKLAR Institute International Office Unsere Partnerhochschulen Kontakt - Sprechzeiten Ins Ausland Studium im Ausland Praktikum im Ausland Sprachen Studieren an der HHN Internationale Vollzeitstudierende Incomings von Partnerhochschulen Heilbronn University of Applied Sciences Informationen zum Studium für Geflüchtete Partner werden Sponsoring Förderkreis Stiftungen Stiftungsprofessuren Angebote für Schulen Talente gewinnen Stipendien Studium mit vertiefter Praxis Firmenkontaktmessen Jobbörse Mechatronik und Robotik - laufende Aktivitäten Machen Sie sich auf dieser Seite gerne ein Bild über die laufenden Aktivitäten des Studiengangs MR und – noch besser – machen Sie mit, nehmen Sie teil und tragen Sie es weiter! ZAFH MikroSens auf der Landesgartenschau in Überlingen vom 22.07. bis 24.07.2020 Den Besuchern wird das \"Virtual Orchestra\" vorgestellt, bei welchem sie das Württembergische Kammerorchester Heilbronn virtuell dirigieren können. Die Dirigierbewegung wird durch Radarsensorik erfasst und als Taktschlag an das Orchester auf dem Monitor weitergegeben. Weicht das Metrum zu stark von der Vorgabe des gewählten Musikstückes ab, so bricht das Orchester das Stück ab. Das Projekt wird von der Hochschule Heilbronn präsentiert und ist in dem Zentrum für angewandte Forschung ZAFH MikroSens Innovative Millimeterwellen-Sensorik für industrielle Anwendungen zusammen mit den Hochschulen Ulm und Pforzheim und der Universität Ulm entstanden. In diesem Forschungsprojekt werden der Radarsensorik über eine neuartige Plattform Applikationsfelder wie beispielsweise Strömungssensorik für fließende Gewässer, Bewegungsanalyse von Bienen, die Erfassung von Kochvorgängen und Automatisierungstechnik erschlossen. pot Bildquelle: Landesgartenschau Überlingen 2020 GmbH Schülerstudium Bildverarbeitung Zehn Schüler des Justinus-Kerner-Gymnasiums Weinsberg nahmen am Schülerstudium Bildverarbeitung teil und waren mit ihrem MWT-Lehrer Herrn Balle zu Gast im Labor für Technische Optik des Studiengangs Mechatronik und Robotik der Hochschule Heilbronn. Die Vorstudenten führten hier mit großem Interesse und Elan Versuche zur Bestimmung der Eigenschaften von LEDs und zur telezentrischen Kameramesstechnik durch und bauten ein einfaches Spektrometer als Aufsatz auf ihre Mobiltelefone, um damit die spektrale Zusammensetzung des Lichts sichtbar zu machen. Kommentar eines Schülers: „Jetzt weiß ich, wofür ich die Mathe in der Schule praktisch gebrauchen kann. Ich dachte gar nicht, dass ein Ingenieurstudium so abwechslungsreich sein kann.“ pot Das Virtual Orchestra wurde auf der BUGA von über 10.000 Besuchern dirigiert; über 1000 haben den Score von 9000 geknackt und an der Verlosung von zwei Freikarten für ein Konzert des Württembergischen Kammerorchesters teilgenommen. Die Dirigierbewegung des Besuchers wurde von einem im Projekt MikroSens entwickelten 122GHz Radarsensor erfasst. Das virtuelle Orchester auf der Leinwand spielte dann im Takt des Dirigenten. Drei Stücke standen zur Auswahl: Die kleine Nachtmusik, Holbergs Suite und die Adaption von Beethovens Ode an die Freude. pot Zweimal Platz 1 beim diesjährigen HHN-Konstruktionswettbewerb Unter dem Motto „Autonomer Lastentransport“ zeigten die Erstis im Studiengang Mechatronik und Robotik was sie draufhaben: 6 Teams konstruierten ein völlig autonom fahrendes Mini-Fahrzeug, das in der Lage ist, eine große Last über eine vorgegebene Strecke zu transportieren. „In diesem Semester waren die Studierenden wirklich exzellent“, sagt Organisator und Professor im Studiengang, Wolfgang Wehl. Field Robot Event auf der BUGA Am diesjährigen Field Robot Event nahmen das Team der Fakultät Mechatronik und Robotik und 14 weitere Teams aus verschiedenen europäischen Ländern teil. Austragungsort war vom 17. - 21. Juni die BUGA in Heilbronn. Auf einem zwölf mal zwölf Meter großen Feld mit ca. 80 cm hohen Maispflanzen traten die Teams in fünf verschiedenen Disziplinen gegeneinander an. In Task 1 sollte jede Reihe des Maisfeldes durchfahren werden. In der nächsten Aufgabe waren es nur bestimmte Reihen. Ziel des 3. Tasks war das Erkennen von Hindernissen und Unkraut, das dann in Task 4 bekämpft werden sollte. Am letzten Tag fand der Freestyle-Task statt, in dem jedes Team unterschiedliche Ideen für die Agrarwirtschaft zeigen konnte, z. B. dass das mobile Robotersystem einer Person folgt. Dies könnte dazu verwendet werden um schwere Dinge zu transportieren. Der Studiengang Mechatronik und Robotik beteiligte sich mit einem Tool am Heilbronner Hackathon Sensor  AI. Den Teilnehmern wurde eine Radarsensorik aus dem Projekt MikroSens vorgestellt, die Geschwindigkeiten und Abstände von Objekten schnell erfassen kann. Mittels dieser Sensordaten können über AI Objekte wie z.B. Gestenbewegungen erkannt werden. Dmitrii Kozlov, wissenschaftlicher Mitarbeiter im Studiengang Mechatronik und Robotik stellte das Tool vor und unterstützte als Coach bezüglich Programmierung und AI. Prof. Hoch aus dem Studiengang war Mitglied der Jury und beurteilte die Ergebnisse der Teilnehmer. pot Die Arbeitsgemeinschaft LED  Beleuchtungstechnik von Photonics BW und des Arbeitskreis LED Technik von optence  bayern photonics tagte am 22. Mai 2019 an der Hochschule Heilbronn. Der Gastgeber Prof. Dr.-Ing. Peter Ott vom Studiengang Mechatronik und Robotik stellte den 30 Gästen aus Industrie und Hochschulen die Forschungs- und Lehraktivitäten seines Labors für Technische Optik vor. Die Fachvorträge aus der Industrie zu aktuellen Themen der LED- und Beleuchtungstechnik und die anschließende rege Diskussion ergaben insgesamt eine sehr gelungenen Veranstaltung. pot Der deutschlandweite Fachbereichstag Mechatronik wurde von der Fakultät für Mechanik und Elektronik an der Hochschule Heilbronn ausgerichtet. Am Donnerstag und Freitag, den 16./17. Mai 2019, trafen sich 35 Dekane und Studiengangsleiter aus ganz Deutschland, um ihre aktuellen Erfahrungen und Entwicklungen in den Studiengängen aus ihren Hochschulen auszutauschen. Der Freitag stand unter dem hochaktuellen Thema Ingenieurausbildung für die Digitale Transformation. Daran schlossen sich Berichte über das breite Band der bereits vorhandenen Aktivitäten in den Studiengängen an. Mit der feierlichen Verleihung des Preises der Deutschen Gesellschaft für Mechatronik e.V. für die besten Bachelor- und Master-Arbeiten aus der Mechatronik an die Absolventen Felix Schneider, Dennis Hotze und Dominik Eickmann ging die Veranstaltung am Freitagnachmittag zu Ende. jwi Das Virtuelle Orchester auf der BUGA Am 17.April wurde die BUGA eröffnet und das Virtuelle Orchester wurde bereits am ersten Wochenende über 800 Mal dirigiert. Die Dirigierbewegung wird von einem im Projekt MikroSens entwickelten 122GHz Radarsensor erfasst. Das Orchester spielt entsprechend im Takt des Dirigenten. Für Grundlagen Digitaltechnik wurde im Sommersemester 2018 ein “inverted classrom” aufgesetzt. Statt der klassischen Vorlesung mit Übung, werden Zahlensysteme, boolesche Algebra und Schaltwerke über Videos und Beispielen darin erklärt. Damit das vermittelte Wissen gefestigt werden kann, sind im Anschluss Aufgaben zu lösen. Die Anwesenheitszeit wird statt für Frontalunterricht, zum Klären der Aufgaben und für Labore genutzt. Die Resonanz ist hoch und die Interaktion zwischen Lernenden und Coach hat sich erhöht. tfi Das ZAFH Projekt MikroSens wurde um zwei Jahre bis Ende 2020 verlängert. Das Projekt befasst sich mit Radarsensorik. Erforscht werden Prinzipien der Künstlichen Intelligenz zur Verarbeitung von Radardaten Deep Learning und Compressed Sensing. Im Labor stehen diverse Radare von 24GHz bis 122GHz für studentische Arbeiten zur Verfügung. 2019 wird das Exponat Virtual Orchestra auf der Bundesgartenschau in Heilbronn gezeigt. Dabei wird die Handbewegung eines Dirigenten mittels Radarsensorik erfasst. Das Orchester passt sich an den dirigierten Takt an. mal ZIM-Projekt: Automatisierte Messung; Selektion und Montage von Lithium-Zellen Die automatisierte Montage von modernen Lithium-Ionen-Akkus für akkubetriebene Antriebssysteme wird aus ökonomischen Gründen nur bei größeren Stückzahlen realisiert, während kleinere Stückzahlen in Handmontage gefertigt werden. Das Ziel dieses Projektes ist die Realisierung einer einfachen und flexiblen Roboterzelle, die die Prozessschritte einer Sortieranlage und der Handmontage kombiniert. Also eine Bestückung von Zellhaltern mit Lithium-Zellen bei gleichzeitiger Spannungsmessung und Umorientierung der einzelnen Zellen. Im Rahmen des öffentlich geförderten Projekts werden zahlreiche studentische Arbeiten, wie zum Beispiel Thesis, Seminararbeit oder Laborarbeit angeboten. thu Praxistage Roboterprogrammierung in der FANUC-Akademie Leinfelden Im siebten Semester geht es bei Robotik und Automation traditionell zu einem der großen Roboterhersteller für den Feinschliff in der Roboterprogrammierung. Nach Stäubli in Bayreuth, Kuka in Augsburg waren wir im Januar erstmals beim größten Roboterhersteller der Welt: Fanuc. Die japanische Firma hat in Leinfelden seine Deutschlandzentrale mit Vertrieb, Schulungszentrum und dem Kompetenzzentrum Automotive. Zwei unserer Absolventen sind dort und schwärmten von den tollen Arbeitsbedingungen aber auch von der optimalen Vorbereitung durch ihr Studium an der HHN. Der abendliche Ausklang in der Nürtinger Altstadt bot Gelegenheit für Gespräche in entspannter Atmosphäre. aho Das interdisziplinäre Projekt sense2cloud wurde 2018 erfolgreich abgeschlossen. Sense2cloud vernetzt fertigungsintegrierte Industriekameras mit skalierbaren Cloudumgebungen zur Bilddatenanalyse. Eine spezielle Systemarchitektur ermöglicht auch die Skalierung großer Analyseressourcen innerhalb des Fertigungstakts, so dass auch neuartige rechenintensive Algorithmen in zeitkritischen Anwendungen eingesetzt werden können. Messageorientierte Datenübertragung ermöglicht eine einfache PlugSense- Fertigungsintegration. Zahlreiche Studierende konnten im Rahmen von Studien- und Abschlussarbeiten Projekterfahrung in anwendungsorientierter Forschung sammeln. pot IHK Forschungstransferpreis 2018 Den IHK-Forschungstransferpreis 2018 in Silber erhielten Dr. Michael Spallek, Rommelag Engineering, Sulzbach Laufen und Prof. Dr. Uwe Gleiter, Hochschule Heilbronn. Sie haben gemeinsam in ihrem Projekt „Bottelpack Easy Empty“ mit Hilfe modernster Simulationstechnik eine neuartige und kostengünstige Infusionsflasche entwickelt, die sich im Gegensatz zu den herkömmlichen Infusionsflaschen auch unbelüftet vollständig entleert, bei hohen Temperaturen sterilisiert werden kann und deutlich weniger Kunststoffmaterial zur Herstellung benötigt. ugl Gastprofessor aus Durham Zur Stärkung einer bestehenden langjährigen internationalen Kooperation auf dem Gebiet der Fluiddynamik kam Herr Prof. Philip H. Gaskell aus dem nordenglischen Durham als Gastprofessor an die Hochschule und bot Studenten aus den Studiengängen MR und MB die Vorlesungen Strömungslehre und Modellbildung und Simulation in englischer Sprache an. Herr Gaskell betreut zudem einen Doktoranden im Studiengang MR. Die Gastprofessur wurde nach Antrag von Prof. Scholle durch den DAAD mit ca. 25.000 € unterstützt. Die Durham University steht im UK-Ranking auf Platz vier hinter Oxford, Cambridge und Imperial College und findet sich im internationalen Ranking unter den Top 100, vergleichbar mit der TU München oder Uni Heidelberg. msc Zurück zu Mechatronik und Robotik - Bachelor - Studierende Home Personensuche Impressum Kontakt © 2020 HHN Hochschule Heilbronn - Max-Planck Str. 39 - 74081 Heilbronn '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Beispieldarstellung eines Texts, der vom NLP-Verfahren bearbeitet wird.\n",
    "'''\n",
    "text = df['Text'][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP-Verfahren\n",
    "### Erforschung von Spacy - Entwicklung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"7d59e09e6f5540ee8ee96125e779c7ff-0\" class=\"displacy\" width=\"3200\" height=\"749.5\" direction=\"ltr\" style=\"max-width: none; height: 749.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">das</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">interessante</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Buch</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">wird</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">nicht</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">von</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Victor</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">heute</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">am</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">schönen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">Strand</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">gelesen,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">sondern</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">CONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">fährt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">er</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">das</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">schnelle</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">Auto</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-0\" stroke-width=\"2px\" d=\"M70,614.5 C70,439.5 375.0,439.5 375.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,616.5 L62,604.5 78,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-1\" stroke-width=\"2px\" d=\"M245,614.5 C245,527.0 370.0,527.0 370.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,616.5 L237,604.5 253,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-2\" stroke-width=\"2px\" d=\"M420,614.5 C420,527.0 545.0,527.0 545.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,616.5 L412,604.5 428,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-3\" stroke-width=\"2px\" d=\"M770,614.5 C770,439.5 1075.0,439.5 1075.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ng</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,616.5 L762,604.5 778,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-4\" stroke-width=\"2px\" d=\"M945,614.5 C945,177.0 1965.0,177.0 1965.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sbp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,616.5 L937,604.5 953,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-5\" stroke-width=\"2px\" d=\"M945,614.5 C945,527.0 1070.0,527.0 1070.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1070.0,616.5 L1078.0,604.5 1062.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-6\" stroke-width=\"2px\" d=\"M1295,614.5 C1295,264.5 1960.0,264.5 1960.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,616.5 L1287,604.5 1303,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-7\" stroke-width=\"2px\" d=\"M1470,614.5 C1470,352.0 1955.0,352.0 1955.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,616.5 L1462,604.5 1478,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-8\" stroke-width=\"2px\" d=\"M1645,614.5 C1645,527.0 1770.0,527.0 1770.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,616.5 L1637,604.5 1653,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-9\" stroke-width=\"2px\" d=\"M1470,614.5 C1470,439.5 1775.0,439.5 1775.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1775.0,616.5 L1783.0,604.5 1767.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-10\" stroke-width=\"2px\" d=\"M595,614.5 C595,89.5 1970.0,89.5 1970.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1970.0,616.5 L1978.0,604.5 1962.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-11\" stroke-width=\"2px\" d=\"M595,614.5 C595,2.0 2150.0,2.0 2150.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cd</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2150.0,616.5 L2158.0,604.5 2142.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-12\" stroke-width=\"2px\" d=\"M2170,614.5 C2170,527.0 2295.0,527.0 2295.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2295.0,616.5 L2303.0,604.5 2287.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-13\" stroke-width=\"2px\" d=\"M2345,614.5 C2345,527.0 2470.0,527.0 2470.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2470.0,616.5 L2478.0,604.5 2462.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-14\" stroke-width=\"2px\" d=\"M2695,614.5 C2695,439.5 3000.0,439.5 3000.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2695,616.5 L2687,604.5 2703,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-15\" stroke-width=\"2px\" d=\"M2870,614.5 C2870,527.0 2995.0,527.0 2995.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2870,616.5 L2862,604.5 2878,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-16\" stroke-width=\"2px\" d=\"M2345,614.5 C2345,264.5 3010.0,264.5 3010.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-7d59e09e6f5540ee8ee96125e779c7ff-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oa</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3010.0,616.5 L3018.0,604.5 3002.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "das nk DET Buch [] [Buch, wird]\n",
      "interessante nk ADJ Buch [] [Buch, wird]\n",
      "Buch sb NOUN wird [das, interessante] [wird]\n",
      "wird ROOT AUX wird [Buch, gelesen, ,, sondern] []\n",
      "nicht ng PART Victor [] [Victor, von, gelesen, wird]\n",
      "von sbp ADP gelesen [Victor] [gelesen, wird]\n",
      "Victor nk NOUN von [nicht] [von, gelesen, wird]\n",
      "heute mo ADV gelesen [] [gelesen, wird]\n",
      "am mo ADP gelesen [Strand] [gelesen, wird]\n",
      "schönen nk ADJ Strand [] [Strand, am, gelesen, wird]\n",
      "Strand nk NOUN am [schönen] [am, gelesen, wird]\n",
      "gelesen oc VERB wird [von, heute, am] [wird]\n",
      ", punct PUNCT wird [] [wird]\n",
      "sondern cd CONJ wird [fährt] [wird]\n",
      "fährt cj VERB sondern [er, Auto] [sondern, wird]\n",
      "er sb PRON fährt [] [fährt, sondern, wird]\n",
      "das nk DET Auto [] [Auto, fährt, sondern, wird]\n",
      "schnelle nk ADJ Auto [] [Auto, fährt, sondern, wird]\n",
      "Auto oa NOUN fährt [das, schnelle] [fährt, sondern, wird]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Visualisierung der NLP-Objekte (Dependencies und Parts-of-Speach) auf Basis von Spacy.\n",
    "'''\n",
    "txt = \"das interessante Buch wird nicht von Victor heute am schönen Strand gelesen, sondern fährt er das schnelle Auto\"\n",
    "# text = 'Der Text hätte von dem Mann geschrieben werden können' # zu bearbeitetem Text\n",
    "doc = nlp(txt) # aus einem String hin zu einem Spacy Doc (Textformat mit den analysierten NLP-Objekte)\n",
    "displacy.render(doc,style='dep', jupyter=True,) # Darstellung des Satzes\n",
    "for token in doc: # Informationen aus jedem Token\n",
    "    print(token.text, token.dep_, token.pos_, token.head, [child for child in token.children], [ante for ante in token.ancestors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cj is equal: conjunct\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Spacy-Methode, um die Spacy-Bezwichnungen bspw. von \"Dependencies\"(DEP) und \"Parts-of-Speach\"(POS) erklären zu lassen.\n",
    "'''\n",
    "name = 'cj'\n",
    "print(name, \"is equal:\",spacy.explain(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung einer NLP-Klasse mit den Objekten und Methoden\n",
    "Dieser Punkt ist der Kernpunkt des ganzen Projektes. Hier wird das Text Mining und NLP durchgeführt. Diese Klasse ist auf der Open Source Python-Bibliothek Spacy aufgebaut und besteht aus vielfältige Methoden, um die NLP an die deutsche Sprache anzupassen und die Informationen am besten zu extrahieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VictoryNLP():\n",
    "    \n",
    "    def __init__(self, name, nlp):\n",
    "        '''\n",
    "        Initialisierungsfunktion:\n",
    "        Das Spacy-NLP-Objekt wird importiert um in der Klasse intialisiert.\n",
    "        Der Name des Objekts wird in der Klasse importiert und gespeichert.\n",
    "        '''\n",
    "        self.name = name # Initialisierung vom Objektname\n",
    "        self.nlp = nlp # Initialisierung des Spacy-NLP-Objekts\n",
    "    \n",
    "    def is_question(self,sent):\n",
    "        '''\n",
    "        Prüft, ob der analysierte Satz eine Frage ist.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        sent --> Satz, der analysiert wird\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        True/False --> Boolean, ob der Satz eine Frage ist.\n",
    "        '''\n",
    "        return '?' in sent.text # Prüft, ob \"?\" in dem Satz zu finden ist\n",
    "    \n",
    "    def is_question_words_without_obj(self,token):\n",
    "        '''\n",
    "        Prüft ob der Token ein W-Fragewort ist, bei dem das Objekt oder Subjekt direkt die W-Fragewort ist.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        sent --> Satz, der analysiert wird\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        True/False --> Boolean, ob der Token ein von den W-Fragewörtern ist.\n",
    "    \n",
    "        '''\n",
    "        question_words_without_obj = ['was', 'wo', 'wer', 'wen', 'wem', 'wohin', 'woher'] # W-Fragewörter, , bei denen das Objekt oder Subjekt direkt die W-Fragewort ist\n",
    "        return token.text.lower() in question_words_without_obj # Return Boolean, ob der Token ein von den W-Fragewörtern ist.\n",
    "    \n",
    "    def get_multiple_elements(self,objs):\n",
    "        '''\n",
    "        Bei dieser Methode werden vielfältige Objekte oder Subjekte gesucht. Nicht immer sind die Objekte oder Subjekte direkt\n",
    "        zu erkennen. Manchmal besteht das Objekt oder das Subjekt aus mehrere Wörter, die nicht sofort von Spacy erkennbar sind.\n",
    "        Aus diesem Grund, liest die Methode den Satzt wieder durch und verknüpft die vielfältigen Objekte und Subjekte.\n",
    "        Da das Verfahren gleich für Subjekte und Objekte ist, wird in den Komentare nur über Objekte gesprochen.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        objs --> Liste mit den erkannten Objekten\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        objs --> Bearbeitete Liste von den vielfältigen Objekten\n",
    "    \n",
    "        '''\n",
    "        # Typen von Wörtern, die nicht als Objekte erwünscht sind\n",
    "        unwanted_tokens = (\n",
    "        'AUX', # auxiliar verb\n",
    "        'ADJ', # adjective\n",
    "        'ADV', # adverb\n",
    "        'VERB', # verb\n",
    "        'PART',  # particle\n",
    "        'DET',  # determiner\n",
    "        'SCONJ',  # subordinating conjunction\n",
    "        'PUNCT',  # punctuation\n",
    "        'SYM',  # symbol\n",
    "        'X',  # other\n",
    "        )\n",
    "        \n",
    "        # Diese Typen werden nachher gefiltert, weil viele Verknüpfungen zwischen Objekten über diese Typen zu erkennen sind,\n",
    "        # jedoch werden diese Typen am Ende als Objekte nicht erwünscht, daher werden sie gefiltert.\n",
    "        obj_filter = (\n",
    "        'CONJ', # conjunction\n",
    "        'ADP', # adposition\n",
    "        )\n",
    "        \n",
    "        # Schleife über die Objekte\n",
    "        for obj in objs:\n",
    "            # Schleife über die Kinder des Objkets\n",
    "            for child in obj.children:\n",
    "                # Voraussetzungen:\n",
    "                # --> Wenn das POS des Kinds nicht in des Tuples \"unwanted_tokens\" sich befindet\n",
    "                # --> Und wenn das Kind kein Interpunktionszeichen ist\n",
    "                # --> Und wenn das Kind noch nicht in der Objektliste ist\n",
    "                if child.pos_ not in unwanted_tokens and child.is_punct==False and child not in objs:\n",
    "                    # Fügt das Kind zu der Objektliste ein\n",
    "                    objs.append(child)\n",
    "\n",
    "        # Filtert die Subjekte und Objekte auf basis des Tuples \"obj_filter\" \n",
    "        objs = [obj for obj in objs if obj.pos_ not in obj_filter]\n",
    "        \n",
    "        # Rückgabe der vielfältigen Objekte\n",
    "        return objs\n",
    "    \n",
    "    def substitute_pronoun(self,token):\n",
    "        '''\n",
    "        Für einen guten Lesefluss werden oft Pronomen angewendet. Durch die Anwendung von Pronomen im Text wird \n",
    "        verzichtet, mehrmals die Subjekte oder Objekte zu wiederholen, ohne dass Informationen verloren gehen. \n",
    "        Die Beziehung zwischen Pronomen und den Wörtern, auf denen die Pronomen sich beziehen, werden nicht von \n",
    "        Spacy erkannt und, um diese Informationen nicht zu verlieren und um herauszufinden, woraus das Pronomen \n",
    "        sich bezieht, wurde diese Methode geschrieben.              \n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        token --> Wort aus dem Satz, der analysiert wird\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        Wenn das Wort, auf dem das Pronomen sich bezieht, erkannt wird:\n",
    "        obj  --> Wenn das Pronomen in einem Relativsatz sich befindet und das Wort, auf dem das Pronomen sich \n",
    "                 bezieht, in einem Hauptsatz zu finden ist.\n",
    "        subj --> Wenn das Pronomen in einem Konjunktivsatz  ist, wird das Subjekt des Hauptsatzes gewählt, um \n",
    "                 das Pronomen zu ersetzen\n",
    "        case --> 1 bedeutet Charakteristiken aus der Aktivform und 2 bedeutet Charakteristiken aus der Passivform\n",
    "        \n",
    "        Sonst:\n",
    "        token --> Rückgabe desselben Wortes\n",
    "        '''\n",
    "        case=1\n",
    "        \n",
    "        # Wenn die Abhängigkeit der Wurzel des Wortes ein Relativsatz ist und das Wort ein Pronomen ist\n",
    "        if token.head.dep_ == 'rc' and token.pos_ == 'PRON':\n",
    "            # Wird versucht die Wurzel der Wurzel zu speichern (zweite Wurzel)\n",
    "            try:\n",
    "                obj = token.head.head\n",
    "                # Wenn es klappt wird das Pronomen von seiner zweiten Wurzel ersetzt\n",
    "                # Rückgabe von case 1 (Aktivform)\n",
    "                return obj, case\n",
    "            except:\n",
    "                None\n",
    "                \n",
    "        # Wenn die Abhängigkeit der Wurzel des Wortes eine Konjunktion ist und das Wort ein Pronomen ist aber davor befindet sich eine Konjunktion  \n",
    "        elif token.head.head.head.dep_ == 'cd' and token.pos_ == 'PRON':\n",
    "\n",
    "            # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen, wenn der Satz in der Aktivform steht\n",
    "            try:\n",
    "                # Holt das Subjekt des anderen Satzs\n",
    "                subj = [subj for subj in token.head.head.head.head.children if subj.dep_=='sb'][0] \n",
    "                # Prüft, ob das Hauptsatz in der Passivform steht\n",
    "                if subj.head.lemma_ == 'werden':\n",
    "                    # Findet das Hauptverb\n",
    "                    oc_verb = [oc for oc in subj.head.children if oc.dep_=='oc'][0]\n",
    "                    case = 2\n",
    "                    # Sucht nach den Objekten\n",
    "                    for i in range(3):\n",
    "                        try:\n",
    "                            # Sucht nach einem Objekt Akkusativ\n",
    "                            obj = [obj for obj in oc_verb.children if obj.dep_=='oa'][0]\n",
    "                            return obj, case\n",
    "                        except:\n",
    "                            # Sucht nach einem Subjekt in der Passivform\n",
    "                            try:\n",
    "                                obj = [obj for obj in oc_verb.children if obj.dep_=='sbp'][0]\n",
    "                                obj = [obj for obj in obj.children if obj.dep_=='nk'][0]\n",
    "                                return obj, case\n",
    "                            except:\n",
    "                                # Sucht nach einem Predikat\n",
    "                                try:\n",
    "                                    obj = [obj for obj in oc_verb.children if obj.dep_=='pd'][0]\n",
    "                                    return obj, case\n",
    "                                except:\n",
    "                                    # Prüft, ob die Ebene des Hauptverbs noch nicht erreicht wurde\n",
    "                                    try:\n",
    "                                        oc_verb = [oc for oc in oc_verb.children if obj.dep_=='oc'][0]\n",
    "                                    except:\n",
    "                                        None\n",
    "                        \n",
    "                # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen        \n",
    "                else:\n",
    "                    # Rückgabe von case 1 (Aktivform)\n",
    "                    return subj, case\n",
    "            except:\n",
    "                None\n",
    "        \n",
    "        # Wenn die Abhängigkeit der Wurzel des Wortes eine Konjunktion ist und das Wort ein Pronomen ist aber davor befindet sich eine Konjunktion  \n",
    "        elif token.head.head.dep_ == 'cd' and token.pos_ == 'PRON':\n",
    "\n",
    "            # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen, wenn der Satz in der Aktivform steht\n",
    "            try:\n",
    "                # Holt das Subjekt des anderen Satzs\n",
    "                subj = [subj for subj in token.head.head.head.children if subj.dep_=='sb'][0] \n",
    "                # Prüft, ob das Hauptsatz in der Passivform steht\n",
    "                if subj.head.lemma_ == 'werden':\n",
    "                    # Findet das Hauptverb\n",
    "                    oc_verb = [oc for oc in subj.head.children if oc.dep_=='oc'][0]\n",
    "                    case = 2\n",
    "                    # Sucht nach den Objekten\n",
    "                    for i in range(3):\n",
    "                        # Sucht nach einem Objekt Akkusativ\n",
    "                        try:\n",
    "                            obj = [obj for obj in oc_verb.children if obj.dep_=='oa'][0]\n",
    "                            return obj, case\n",
    "                        except:\n",
    "                            # Sucht nach einem Subjekt in der Passivform\n",
    "                            try:\n",
    "                                obj = [obj for obj in oc_verb.children if obj.dep_=='sbp'][0]\n",
    "                                obj = [obj for obj in obj.children if obj.dep_=='nk'][0]\n",
    "                                return obj, case\n",
    "                            except:\n",
    "                                # Sucht nach einem Predikat\n",
    "                                try:\n",
    "                                    obj = [obj for obj in oc_verb.children if obj.dep_=='pd'][0]\n",
    "                                    return obj, case\n",
    "                                except:\n",
    "                                    # Prüft, ob die Ebene des Hauptverbs noch nicht erreicht wurde\n",
    "                                    try:\n",
    "                                        oc_verb = [oc for oc in oc_verb.children if obj.dep_=='oc'][0]\n",
    "                                    except:\n",
    "                                        None\n",
    "                        \n",
    "                # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen        \n",
    "                else:\n",
    "                    # Rückgabe von case 1 (Aktivform)\n",
    "                    return subj, case\n",
    "            except:\n",
    "                None\n",
    "        \n",
    "        # Wenn die Abhängigkeit der Wurzel des Wortes eine Konjunktion ist und das Wort ein Pronomen ist\n",
    "        elif token.head.dep_ == 'cj' and token.pos_ == 'PRON':\n",
    "            \n",
    "            # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen, wenn der Satz in der Aktivform steht\n",
    "            try:\n",
    "                # Holt das Subjekt des anderen Satzs\n",
    "                subj = [subj for subj in token.head.head.children if subj.dep_=='sb'][0] \n",
    "                # Prüft, ob das Hauptsatz in der Passivform steht\n",
    "                if subj.head.lemma_ == 'werden':\n",
    "                    # Findet das Hauptverb\n",
    "                    oc_verb = [oc for oc in subj.head.children if oc.dep_=='oc'][0]\n",
    "                    case = 2\n",
    "                    # Sucht nach den Objekten\n",
    "                    for i in range(3):\n",
    "                        # Sucht nach einem Objekt Akkusativ\n",
    "                        try:\n",
    "                            obj = [obj for obj in oc_verb.children if obj.dep_=='oa'][0]\n",
    "                            return obj, case\n",
    "                        except:\n",
    "                            # Sucht nach einem Subjekt in der Passivform\n",
    "                            try:\n",
    "                                obj = [obj for obj in oc_verb.children if obj.dep_=='sbp'][0]\n",
    "                                obj = [obj for obj in obj.children if obj.dep_=='nk'][0]\n",
    "                                return obj, case\n",
    "                            except:\n",
    "                                # Sucht nach einem Predikat\n",
    "                                try:\n",
    "                                    obj = [obj for obj in oc_verb.children if obj.dep_=='pd'][0]\n",
    "                                    return obj, case\n",
    "                                except:\n",
    "                                    # Prüft, ob die Ebene des Hauptverbs noch nicht erreicht wurde\n",
    "                                    try:\n",
    "                                        oc_verb = [oc for oc in oc_verb.children if obj.dep_=='oc'][0]\n",
    "                                    except:\n",
    "                                        None\n",
    "                # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen        \n",
    "                else:\n",
    "                    # Rückgabe von case 1 (Aktivform)\n",
    "                    return subj, case\n",
    "            except:\n",
    "                None\n",
    "        else:\n",
    "            # Wenn die beiden Fälle nicht zugetroffen werden, bleibt das Pronomen\n",
    "            return token, case\n",
    "    \n",
    "    def get_chunks(self,subjs, sent):\n",
    "        '''\n",
    "        Die Methode \"get_chunks\" findet in dem Satz, wo das Subjekt sich befindet, für jedes vorher gefundenen\n",
    "        Objekt sein entsprechendes sogenanntes \"Noun Chunk\". Das ist die Kombination von Wörter die, das Objekt \n",
    "        oder Subjekt beschreiben. Nehmen wir zum Beispiel der Satz \"Peter will heute das schnelle rote Auto \n",
    "        fahren.\". In diesem Fall ist das Substantiv \"Auto\" das Objekt und \"das schnelle rote Auto\" das \n",
    "        entsprechende \"Noun Chunk\".\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        subjs --> Liste mit den vorher erkannten Subjekte oder Objekte\n",
    "        sent  --> Satz, der analysiert wird\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        chunks --> Liste mit den entsprechenden Noun Chunks auf Basis des Inputs \"subjs\"\n",
    "        '''\n",
    "        # Nutzt die Spacy-Generator \".noun_chunks\", um alle gefundenen Noun Chunks in dem Satz in einer Liste zu speichern.\n",
    "        chunks_raw = [chunk for chunk in sent.noun_chunks]\n",
    "        \n",
    "        # Leere Liste, in der die gefundenen Noun Chunks \n",
    "        chunks = []\n",
    "        \n",
    "        # Schleife über die Subjekte\n",
    "        for subj in subjs:\n",
    "            # Schleife über alle Noun Chunks von dem Satz\n",
    "            for chunk in chunks_raw:\n",
    "                # Wenn das Subjekt in dem entsprechenden Chunk sich befindet, wird es zu der Outputliste hinzugefügt.\n",
    "                if subj in chunk:\n",
    "                    chunks.append(chunk)\n",
    "                    \n",
    "        # Stellt sicher, dass die Output-Noun-Chunks einzigartig sind\n",
    "        chunks = list(set(chunks))\n",
    "        \n",
    "        # Rückgabe der Noun Chunks\n",
    "        return chunks\n",
    "    \n",
    "    def get_root(self,element):\n",
    "        '''\n",
    "        Bei jedem Satz wird eine Wurzel definiert. Als Wurzel eines Satzes werden Verben oder Hilfsverben angenommen.\n",
    "        Diese Wurzel sind die Basis für die Relationen zwischen Subjekte und Objekte. Diese Methode findet die Wurzeln\n",
    "        des Satzes heraus.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        element --> Token, das analysiert wird. Aus dem Token wird die Wurzel gefunden.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        root --> Gefundene Wurzel von dem Satz auf Basis von dem Input \"element\"\n",
    "        '''\n",
    "        # Erlaubte Parts-Of-Speach von den Wurzeln\n",
    "        root_pos = (\n",
    "        'VERB', # Verben\n",
    "        'AUX')  # Hilfsverben\n",
    "        \n",
    "        # Anwendung der Spacy-Methode \".head\" um die Wurzel eines Worts zu finden\n",
    "        root = element.head\n",
    "        \n",
    "        # Schleife, die von Wort zu Wort geht, um die Wurzel in Form von Verben oder Hilfsverben zu finden.\n",
    "        while root.pos_ not in root_pos and root != root.head:\n",
    "            root = root.head\n",
    "        \n",
    "        # Rückgabe der Wurzel\n",
    "        return root\n",
    "    \n",
    "    def get_modal_verb(self,sent, roots):\n",
    "        '''\n",
    "        Modalverben, wie können, wollen, sollen, möchten, werden von Spacy als eine separte Kategorie erkannt.\n",
    "        Die Modalverben ergeben nur Sinn, wenn sie Zusammen mit den Hauptverben als Relation erkannt werden. Aus\n",
    "        diesem Grund wird durch diese Methode das Modalverb erkannt und zu der Roots-Liste (Wurzeln) hinzugefügt.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        sent  --> Satz, der analysiert wird\n",
    "        roots --> Roots-Liste oder erkannte Wurzeln des Satzes\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        roots --> Roots-Liste mit der Ergänzung von den Modalverben\n",
    "        '''\n",
    "        # Schleife über die Wörter des Satzes\n",
    "        for oc in sent:\n",
    "            # Wenn das Wort ein Modalverb ist, wird es zu der Roots-Liste hinzugefügt\n",
    "            if oc.dep_=='oc':\n",
    "                roots.append(oc)   \n",
    "        # Rückgabe der ergänzten Wurzeln         \n",
    "        return roots  \n",
    "    \n",
    "    def get_clause(self,token):\n",
    "        '''\n",
    "        Bei einem Nebensatz kommt es of vor, dass das Objekt des Hauptsatzes  das Subjekt des Nebensatzes ist.\n",
    "        Diese Methode erkennt diese Fälle und prüft, ob das Objekt das Subjekt eines Nebensatzes ist.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        token  --> Token, das geprüft wird, ob ein Nebensatz zu ihm verbunden ist\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        check_clause --> Kind des geprüften Tokens, zu dem ein Nebensatz verbunden ist\n",
    "        '''\n",
    "        # \"Parts-Of-Speach\", die erwünscht sind, um den Nebensatz zu charakterisieren\n",
    "        clause_link = ('VERB', 'AUX') # Verben oder Hilfsverben\n",
    "        \n",
    "        # Aus der Spacy-Generator werden die Kinder vom Token gesammelt, die als \"Part-Of-Speach Verben oder Hilfsverben enthalten\"\n",
    "        check_clause = [child for child in token.children if child.pos_ in clause_link]\n",
    "        # Falls die Liste \"check_clause\" größer als null ist wird diese Liste zurückgegeben\n",
    "        if len(check_clause)>0:\n",
    "            # Rückgabe der Liste \"check_clause\"\n",
    "            return check_clause\n",
    "        else:\n",
    "            # Rückgabe einer leeren Liste\n",
    "            return []\n",
    "        \n",
    "    def activate_passive(self,case, relation, obj, subj, obj_chunk, subj_chunk, obj_type, subj_type):\n",
    "        '''\n",
    "        Diese Methode wandelt die Sätze in der Passivform in die Aktivform um. Falls der Satz in der passiven \n",
    "        Form ist, wird das Subjekt von dem Objekt ersetzt und umgekehrt, sodass das Ergebnis immer einheitlich in \n",
    "        der aktiven Form steht. Die Inputs und Outputs sind gleich und nur die Relation wird in dieser Methode transformiert.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        relation --> Relationen, die sie Subjekte und die Objekte verbinden\n",
    "        obj --> Erkannte Objekte\n",
    "        subj --> Erkannte Subjekte\n",
    "        obj_chunk --> Erkannte Noun Chunks aus den Objekten\n",
    "        subj_chunk --> Erkannte Noun Chunks aus den Subjekten\n",
    "        obj_type --> Objekttyp aus den Objekten, ergeben von der Spacy-Methode \".ent_type_\"\n",
    "        subj_type --> Subjekttyp aus den Subjekten, ergeben von der Spacy-Methode \".ent_type_\"\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        relation --> Relationen, die sie Subjekte und die Objekte verbinden\n",
    "        obj --> Erkannte Objekte\n",
    "        subj --> Erkannte Subjekte\n",
    "        obj_chunk --> Erkannte Noun Chunks aus den Objekten\n",
    "        subj_chunk --> Erkannte Noun Chunks aus den Subjekten\n",
    "        obj_type --> Objekttyp aus den Objekten, ergeben von der Spacy-Methode \".ent_type_\"\n",
    "        subj_type --> Subjekttyp aus den Subjekten, ergeben von der Spacy-Methode \".ent_type_\"\n",
    "        \n",
    "        '''\n",
    "        # Wandelt den String zu einem Spacy-Doc um\n",
    "        doc = nlp(relation)\n",
    "        # Leere Liste, für die Stammform des Verbs\n",
    "        lemma_form = []\n",
    "        # Variable zu bestätigen, ob der Satz ist Passiv, oder nicht\n",
    "        counter = 0\n",
    "        \n",
    "        # Schleife über die Tokens des transformierten Relation\n",
    "        for token in doc:\n",
    "            # Falls die Passivform nicht erkannt wird\n",
    "            if token.lemma_ != 'werden':\n",
    "                # Das Verb wird in der Stammform gespeichert\n",
    "                lemma_form.append(token.lemma_)\n",
    "            # Charakterisierung der Passivform: Wenn das Hilfsverb werden angewendet wird\n",
    "            else: # token.lemma_ == 'werden':\n",
    "                # Counter zählt hoch\n",
    "                counter += 1\n",
    "        \n",
    "        # Alle Relations werden zu einem String umgewandelt\n",
    "        relation = ' '.join(map(str, lemma_form))\n",
    "        \n",
    "        # Wenn die Passivworm erkannt wurde\n",
    "        if counter >0 and case == 1:\n",
    "            # Rückgabe der Relationen Objekte und Subjekte in der umgekehrten Reinfolge \n",
    "            return relation, subj, obj, subj_chunk, obj_chunk, subj_type, obj_type\n",
    "        # Wenn die Passivform nicht erkannt wurde\n",
    "        else:\n",
    "            # Rückgabe der Relationen Objekte und Subjekte in der direkten Reinfolge \n",
    "            return relation, obj, subj, obj_chunk, subj_chunk, obj_type, subj_type\n",
    "    \n",
    "    def get_relations(self,roots):\n",
    "        '''\n",
    "        Diese Methode ist dafür verantwörtlich, die Beziehungen bzw. Relationen zwischen Objekte und Subjekte\n",
    "        herauszufinden. Bei dieser Funktion Spielen viele sprachlische Eigenschaften der deutschen Sprache eine\n",
    "        Rolle. Herausforderungen sind bspw. die Modalverben und Hauptverben zu verbinden, oder die Relationen aus\n",
    "        Nebensätzen und mit den Hauptsätzen zu verknüpfen. \n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        roots --> Die Wurzeln die in dem Satz erkannt wurden\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        relation_full --> Die Relationen mit den zusätzlichen Informationen, wie die verbalen Konjunktionen\n",
    "        '''\n",
    "        # Leere Liste für die Relationen\n",
    "        relations=[]\n",
    "        # Leere liste für die Konjunktionen\n",
    "        conj_verb = []\n",
    "        \n",
    "        # Schleife über die Wurzeln, um die verbalen Konjunktionen herauszufinden\n",
    "        for root in roots:\n",
    "            # Placeholder für die erstellung der Relationen\n",
    "            pm = ''\n",
    "            ng = ''\n",
    "            svp = ''\n",
    "            head1 = ''\n",
    "            head2 = ''\n",
    "            head3 = ''\n",
    "            # Schleife über die Kinder der gefundenen Wurzel\n",
    "            for child in root.children:\n",
    "                \n",
    "                # Prüfen, ob ein morphologisches Partikel vorhanden ist\n",
    "                if child.dep_ == 'pm':\n",
    "                    pm = child.text + ' '\n",
    "                    \n",
    "                # Prüfen, ob ein negatives Element vorhanden ist\n",
    "                if child.dep_ == 'ng':\n",
    "                    ng = child.text + ' '\n",
    "                    \n",
    "            # Prüfen, ob die Relationen vielfältige verbale Konjunktionen enthalten\n",
    "            # Erste Ebene: Für die Relationen, die aus zwei Verben oder Hilfsverben besteht\n",
    "            if (root.head.pos_=='VERB' or root.head.pos_=='AUX') and \\\n",
    "            root.head!=root and root.dep_!='cj':\n",
    "                head1 = root.head.text + ' '\n",
    "                \n",
    "                # Zweite Ebene: Für die Relationen, die aus drei Verben oder Hilfsverben besteht\n",
    "                if (root.head.head.pos_=='VERB' or root.head.head.pos_=='AUX') and \\\n",
    "                root.head.head!=root.head and root.head.dep_!='cj':\n",
    "                    head2 = root.head.head.text + ' '\n",
    "                    \n",
    "                    # Zweite Ebene: Für die Relationen, die aus vier Verben oder Hilfsverben besteht\n",
    "                    if (root.head.head.head.pos_=='VERB' or root.head.head.head.pos_=='AUX') and \\\n",
    "                    root.head.head.head!=root.head.head and root.head.head.dep_!='cj':\n",
    "                        head3 = root.head.head.head.text + ' '\n",
    "                \n",
    "                # Zusammenfügung von allen verbalen Konjunktionen als ein einziges Text\n",
    "                conj_verb.append(\"{}{}{}{}{}{}\".format(head1, head3, head2, ng, pm, root.text ))\n",
    "        \n",
    "        # Schleife über die gefundenen Wurzeln für die Erstellung der Relationen\n",
    "        for root in roots:\n",
    "            \n",
    "            # Prüfen, ob die Wurzeln bei den verbalen Konjunktionen bereits gespeichert wurden\n",
    "            test = [root.text in element for element in conj_verb]\n",
    "            \n",
    "            # Die Relationen herausfinden und in eine Liste speichern\n",
    "            if sum(test) == 0 and (root.pos_=='VERB' or (root.pos_=='AUX' and root.lemma_=='haben')):\n",
    "                # Placeholder für die Nachbereitung der Relationen\n",
    "                pm = ''\n",
    "                ng = ''\n",
    "                svp = ''\n",
    "                \n",
    "                # Schleife über die Kinder der gefundenen Wurzel\n",
    "                for child in root.children:\n",
    "                    # Prüfen ob das Kind ein trennbares Verb ist\n",
    "                    if child.dep_ == 'svp':\n",
    "                        svp = child.text\n",
    "                    # Prüfen ob das Kind ein morphologisches Partikel ist\n",
    "                    if child.dep_ == 'pm':\n",
    "                        pm = child.text + ' '\n",
    "                    # check if there is a negative element\n",
    "                    if child.dep_ == 'ng':\n",
    "                        ng = child.text + ' '\n",
    "                        \n",
    "                # Zusammenfügung von allen verben als ein einziges Text\n",
    "                relations.append(\"{}{}{}{}\".format(ng, pm, svp, root.text))\n",
    "\n",
    "        # Erstellung einer Liste aus den Relationen mit einzigartigen Relationen\n",
    "        relations = list(set(relations))\n",
    "        # Erstellung einer Liste aus den verbalen Konjunktionen mit einzigartigen Konjunktionen\n",
    "        conj_verb = list(set(conj_verb))\n",
    "        \n",
    "        # Erstellung der finalen Relationen aus der Zusammenfügung von den Verben (Relationen) und verbalen Konjunktionen\n",
    "        relations_full = relations + conj_verb\n",
    "        \n",
    "        # Rückgabe der vollständigen Relationen\n",
    "        return relations_full\n",
    "    \n",
    "    def linking_relations(self,subjs, objs, roots, sub_chunks, obj_chunks, relations):\n",
    "        '''\n",
    "        Aus der Analyse des Satzes mittels NLP werden die Objekte, Objekt Chunks, Subjekte, Subjekt Chunks und die\n",
    "        Relationen gefunden, extrahiert und zugeordnet. In dieser Methode werden alle diese gefundene Informationen\n",
    "        miteinander verbunden. Die Subjekte werden zu den Relationen verbunden und diese Verbindung zu den jeweiligen\n",
    "        Objekten. Am Ende werden die Subjekte, Objekte und Relationen in einem Dataframe eingefügt.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        subjs --> Gefundene Subjekte\n",
    "        objs --> Gefundente Objekte\n",
    "        roots --> Die Gefundene Wurzeln aus dem Satz\n",
    "        relations --> Die bearbeitete Relationen aus dem Satz\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        df_subjs --> Dataframe mit den wesentlichen Informationen bzgl. der Subjekte (Features: root, subj, subj_chunk, subj_type\n",
    "        df_objs --> Dataframe mit den wesentlichen Informationen bzgl. der Objekten (Features: obj, obj_chunk, obj_type, root)\n",
    "        df_relations --> Dataframe mit den wesentlichen Informationen bzgl. der Relationen (Features: relation, root)\n",
    "        df_info --> Dataframe mit den Verbindungen zwischen Objekte, Subjekte und Relationen, \n",
    "                    Ergebnis aus der Analyse jedes Satzes\n",
    "        '''\n",
    "        # Erstellung der 3 Zuordnungstabellen\n",
    "        # 1 - Zuordnungstabelle von den Subjekten\n",
    "        df_subjs = pd.DataFrame(columns = ['subj', 'subj_chunk', 'subj_type', 'root'])\n",
    "\n",
    "        # Ausfüllen der Zuordnungstabelle von den Subjekten\n",
    "        # Schleife über die Subjekte\n",
    "        for subj in subjs:\n",
    "            # Schleife über die Noun Chunks\n",
    "            for chunk in sub_chunks:\n",
    "                # Prüfen ob das Subjekt im Noun Chunk zu finden ist\n",
    "                if subj in chunk:\n",
    "                    # Zeile in das Dataframe einfügen\n",
    "                    add_row = pd.DataFrame({'subj':subj, 'subj_chunk':chunk.text, 'subj_type':subj.ent_type_, 'root':self.get_root(subj)}, \n",
    "                                           index=[len(df_subjs)])\n",
    "                    # Zusammenfügung von der erstellten Zeile in die Zuordnungstabelle von den Subjekten\n",
    "                    df_subjs = pd.concat([df_subjs,add_row])\n",
    "\n",
    "        # 2 - Zuordnungstabelle von den Objekten\n",
    "        df_objs = pd.DataFrame(columns = ['obj', 'obj_chunk', 'obj_type', 'root'])\n",
    "        \n",
    "        # Ausfüllen der Zuordnungstabelle von den Objekten\n",
    "        # Schleife über die Objekte\n",
    "        for obj in objs:\n",
    "            # Schleife über die Noun Chunks\n",
    "            for chunk in obj_chunks:\n",
    "                # Prüfen ob das Objekt im Noun Chunk zu finden ist\n",
    "                if obj in chunk:\n",
    "                    # Zeile in das Dataframe einfügen\n",
    "                    add_row = pd.DataFrame({'obj':obj, 'obj_chunk':chunk.text, 'obj_type':obj.ent_type_, 'root':self.get_root(obj)}, \n",
    "                                           index=[len(df_objs)])\n",
    "                    # Zusammenfügung von der erstellten Zeile in die bestehende Zuordnungstabelle von den Objekten\n",
    "                    df_objs = pd.concat([df_objs,add_row])\n",
    "\n",
    "        # 3 - Zuordnungstabelle von den Relationen\n",
    "        df_relations = pd.DataFrame(columns = ['root', 'relation'])\n",
    "        \n",
    "        # Ausfüllen der Zuordnungstabelle von den Relationen\n",
    "        \n",
    "        # Schleife über die Wurzeln\n",
    "        for root in roots:\n",
    "            \n",
    "            # Schleife über die Relationen\n",
    "            for relation in relations:\n",
    "                \n",
    "                # Prüfen ob die Wurzel in der Relation zu finden ist\n",
    "                if root.text in relation:\n",
    "                    # Zeile in das Dataframe einfügen\n",
    "                    add_row = pd.DataFrame({'root':root, 'relation':relation}, index=[len(df_relations)])\n",
    "                    \n",
    "                    # Zusammenfügung von der erstellten Zeile in die bestehende Zuordnungstabelle von den Relationen\n",
    "                    df_relations = pd.concat([df_relations,add_row])\n",
    "\n",
    "        # Speichern von Entitäten (Subjekte und Objekte) und Beziehungen in einem DataFrame \n",
    "        df_info = pd.DataFrame(columns=['Subjects', 'Subjects_raw', 'Subject_Type', 'Relations', 'Objects_raw', 'Objects', 'Object_Type'], )\n",
    "       \n",
    "        # Schleife über die Subjekte\n",
    "        for i in range(len(df_subjs)):\n",
    "            # Fehlertoleranter Ansatz, um Abbrüche aufgrund außergewöhnlicher Textstrukturen zu vermeiden\n",
    "            try:\n",
    "                # Auswahl des zu analysierenden Subjektes\n",
    "                subj = df_subjs['subj'].iloc[i]\n",
    "\n",
    "                # Auf Basis des Objektes wird die Clause_Relation geholt um die Wurzel des Subjekts zu entdecken\n",
    "                clause_relation = self.get_clause(subj)\n",
    "                # Falls mehrere Wurzeln in dem Satz zu finden sind\n",
    "                if len(clause_relation)>0:\n",
    "                    # erhält den Satz-Wurzel (nur eine Satzrelation pro Subjekt ist erlaubt)\n",
    "                    root1 = clause_relation[0]\n",
    "                # Falls nur eine Wurzel zu finden ist\n",
    "                else:\n",
    "                    # Wurzel wird geholt\n",
    "                    root1 = df_subjs['root'].iloc[i]\n",
    "                # findet die Relation basierend auf der Wurzel\n",
    "                relation1 = df_relations['relation'][df_relations['root'] == root1].values[0]\n",
    "\n",
    "                # Schleife über die Objekte\n",
    "                for j in range(len(df_objs)):\n",
    "                    # Wurzel wird geholt\n",
    "                    root2 = df_objs['root'].iloc[j]\n",
    "                    # findet die Beziehung basierend auf der Wurzel\n",
    "                    relation2 = df_relations['relation'][df_relations['root'] == root2].values[0]\n",
    "                    \n",
    "                    # Verbindungsphase zwischen Subjekte und Objekte\n",
    "                    \n",
    "                    # Falls die gefundene Relation aus dem Subjekt und aus dem Objekt gleich sind\n",
    "                    if relation1 == relation2:\n",
    "                        \n",
    "                        # Auswahl des zu analysierenden Objektes\n",
    "                        obj = df_objs['obj'].iloc[j] \n",
    "                        \n",
    "                        # Objekt ersetzen, wenn es ein Pronomen ist (Relativsatz und Nebensätze)\n",
    "                        obj, case = self.substitute_pronoun(obj)\n",
    "\n",
    "                        # Auf Basis des Objektes wird das Noun Chunk und Objekt-Typ geholt\n",
    "                        obj_chunk = df_objs['obj_chunk'][df_objs['obj'] == obj].values[0]\n",
    "                        obj_type = df_objs['obj_type'].iloc[j]\n",
    "                        \n",
    "                        # Subjekt ersetzen, wenn es ein Pronomen ist (Relativsatz und Nebensätze)\n",
    "                        subj, case = self.substitute_pronoun(subj)\n",
    "                        \n",
    "                        # Wenn das Pronomen auf einem Satz in der Aktivform sich bezieht\n",
    "                        if case == 1:\n",
    "                            # Auf Basis des Subjektes wird versucht, das Noun Chunk und Objekt-Typ zu holen\n",
    "                            try:\n",
    "                                subj_chunk = df_subjs['subj_chunk'][df_subjs['subj'] == subj].values[0]\n",
    "                                subj_type = df_subjs['subj_type'][df_subjs['subj'] == subj].values[0]\n",
    "                            # Falls die Aktiveform nicht erkannt wird, soll das Noun Chunk und Objekt-Typ auf Basis der Passivform geholt werden\n",
    "                            except:\n",
    "                                case = 2\n",
    "                                subj_chunk = df_objs['obj_chunk'][df_objs['obj'] == subj].values[0]\n",
    "                                subj_type = df_objs['obj_chunk'][df_objs['obj'] == subj].values[0]\n",
    "                                \n",
    "                        # Wenn das Pronomen aus einem Satz in der Passivform sich bezieht\n",
    "                        else:\n",
    "                            # Auf Basis des Subjektes wird versucht, das Noun Chunk und Objekt-Typ zu holen\n",
    "                            try:\n",
    "                                subj_chunk = df_objs['obj_chunk'][df_objs['obj'] == subj].values[0]\n",
    "                                subj_type = df_objs['obj_chunk'][df_objs['obj'] == subj].values[0]\n",
    "                            # Falls die Passivform nicht erkannt wird, soll das Noun Chunk und Objekt-Typ auf Basis der Aktivform geholt werden\n",
    "                            except:\n",
    "                                case = 1\n",
    "                                subj_chunk = df_subjs['subj_chunk'][df_subjs['subj'] == subj].values[0]\n",
    "                                subj_type = df_subjs['subj_type'][df_subjs['subj'] == subj].values[0]\n",
    "                        \n",
    "                        # Methode zur Aktivierung der Passivform wird ausgeführt\n",
    "                        relation, obj, subj, obj_chunk, subj_chunk, obj_type, subj_type = self.activate_passive(case, relation1, obj, subj, obj_chunk, subj_chunk, obj_type, subj_type)\n",
    "                        \n",
    "                        # Erstellung eines Dictionarys mit den Informationen, die exportiert werden\n",
    "                        d = {'Subjects_raw':subj, \n",
    "                             'Subjects':subj_chunk,\n",
    "                             'Subject_Type':subj_type,\n",
    "                             'Relations':relation,\n",
    "                             'Objects':obj_chunk, \n",
    "                             'Objects_raw':obj,\n",
    "                             'Object_Type':obj_type}\n",
    "\n",
    "                        # achten Sie darauf, Pronomen nicht als Paare zu speichern (Pronomen sind nicht aussagekräftig)\n",
    "                        # Wenn sowohl das Objekt als auch das Subjekt kein Pronomen sind, werden die Informationen in das Dataframe \"df_info\" eingefügt\n",
    "                        if (self.is_question_words_without_obj(obj) or self.is_question_words_without_obj(subj)) and \\\n",
    "                            obj != subj and subj_chunk != obj_chunk:\n",
    "                            add_row = pd.DataFrame(d,index=[len(df_info)])\n",
    "                            df_info = pd.concat([df_info,add_row])\n",
    "                        elif obj.pos_ != 'PRON' and subj.pos_ != 'PRON' and obj != subj and subj_chunk != obj_chunk:\n",
    "                            add_row = pd.DataFrame(d,index=[len(df_info)])\n",
    "                            df_info = pd.concat([df_info,add_row])\n",
    "            \n",
    "            # Falls die Bearbeitung der Relationen zwischen Subjekte und Objete fehlerhaft sind, wird sie ignoriert und das Programm läuft weiter\n",
    "            except:\n",
    "                None\n",
    "        \n",
    "        # Duplikate werden entfernt\n",
    "        df_info.drop_duplicates(inplace=True)\n",
    "        \n",
    "        # Rückgabe von den Subjekten, Objekten, Relationen und die Zusammenfügung von ihnen.\n",
    "        return df_subjs, df_objs, df_relations, df_info\n",
    "    \n",
    "    def text_prep(self,text):\n",
    "        '''\n",
    "        Diese Methode wird für die Textaufbereitung erstellt. Die Form des Textes beeiflusst dierekt die Performance des\n",
    "        Algorithmus. Wenn Sonderzeichen oder mehrere Textumbruche oder Leerzeichen im Text vorkommen, kann das Algorithmus\n",
    "        schlechter bspw. die Sätze erkennen, oder den Zusammenhang der Wörter im Kontext des Satzes. Aufgrund dessen\n",
    "        wird durch diese Methode den Text vor der Bearbeitung bereinigt, um effizient bearbeitet zu werden.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        text --> Text, der bearbeitet wird\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        text --> Aufbereiteter und bereinigter Text\n",
    "        '''\n",
    "        # Zeilenumbrüche innerhalb des Wortes werden gelöscht\n",
    "        text = re.sub(r'-\\n+', '', text)\n",
    "        # Mehrere Zeilenumbrüche, Tabs  werden zu einem Leerzeichen ersetzt\n",
    "        text = re.sub(r'\\n+', ' ', text)\n",
    "        text = re.sub('\\n ','',text)\n",
    "        text = re.sub('\\n',' ',text)\n",
    "        # removing new line characters\n",
    "        text = re.sub('\\n ','',text)\n",
    "        text = re.sub('\\n',' ',text)\n",
    "        # Ersetzen alle Whitespace-Zeichen zu normalem Leerzeichen\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'\\t+', ' ', text)\n",
    "        # Entfernen von Unterstrich gefolgt von einem Leerzeichen\n",
    "        text = re.sub(\"— \",'',text)\n",
    "        # Entfernen jeglicher Verweise auf externen Text\n",
    "        text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "        # E-Mailadresse wird zu dem Wort E-Mail ersetzt\n",
    "        text = re.sub(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", 'E-Mail', text)\n",
    "        # Klammen werden duch Komma ersetzt\n",
    "        text = re.sub(r'([()[]{}])', ',', text)\n",
    "        # Leerzeichen werden gelöscht, aber die Interpunktion wird beibehalten\n",
    "        text = re.sub(r\"[^<>{}\\\"/|~@#$%^=&*\\\\]\\\\\\\\()\\\\[¿§«»ω⊙¤°℃℉€¥£¢¡®©0-9_+]\", '', text)\n",
    "\n",
    "        # Rückgabe des bereinigten und aufbereiteten Texts\n",
    "        return text\n",
    "        \n",
    "    def information_extraction(self,text,all_info=False):\n",
    "        '''\n",
    "        Diese ist die Hauptmethode der Klasse und über diese Methode werden die andere ausgeführt und gesteuert.\n",
    "        Diese Methode soll extern ausgeführt werden, um das VictoryNLP-Verfahren zu nutzen. Der Bereich \"all_info\" \n",
    "        bezeichnet das Format des Ergebnisses:\n",
    "        --> wenn all_info=False: Rückgabe von den aus dem Dokument extrahierten Informationen\n",
    "        --> wenn all_info=True: Rückgabe von den aus dem Dokument extrahierten Informationen und einzelnen Dataframes: \n",
    "                                Subjekte, Objekte und Relationen\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        text --> Text, der bearbeitet wird\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        Wenn all_infos = False:\n",
    "            df_info_full --> Datensatz mit allen Wissensfragmente (Subjekte, Objekte und Relationen)\n",
    "        Wenn all_infos = True:\n",
    "            df_info_full --> Datensatz mit allen Wissensfragmente (Subjekte, Objekte und Relationen)\n",
    "            df_subjs --> Datensatz mit allen erkannten Subjekten und ihren wesentlichen Informationen\n",
    "            df_objs --> Datensatz mit allen erkannten Objekten und ihren wesentlichen Informationen\n",
    "            df_relations --> Datensatz mit allen Relationen (Beziehungen) zwischen den Subjekten und Objekten\n",
    "            \n",
    "        '''\n",
    "        # Bearbeitung des Textes, um das NLP-Verfahren mit RegEx zu erleichtern\n",
    "        text = self.text_prep(text)\n",
    "        # Erstellung eines Spacy-Objektes\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Erstellung eines Dataframes für die Subjekte\n",
    "        subjs = pd.DataFrame(columns=['subj', 'root'])\n",
    "        \n",
    "        # Erstellung eines Dataframes für die Objekte\n",
    "        objs = pd.DataFrame(columns=['obj', 'root'])\n",
    "        \n",
    "        # Erstellung eines Dataframes für die Relationen\n",
    "        relations = pd.DataFrame(columns=['relation', 'root'])\n",
    "        \n",
    "        # Erstellung eines leeren Dataframes für die Zusammenfügung der Informationen\n",
    "        df_info_full = pd.DataFrame()\n",
    "\n",
    "        # Aufteilung des Textes in Sätzen in Form einer Liste mit den Sätzen im Textformat\n",
    "        sentences = [sent.string.strip() for sent in doc.sents]\n",
    "\n",
    "        # Schleife über die Sätze\n",
    "        for sent in sentences:\n",
    "            \n",
    "            # Weiter Nachbereitung von dem Text, dieses Mal in der Form eines Satzes\n",
    "            sent = self.text_prep(sent)\n",
    "            \n",
    "            # Erstellung eines Spacy-Objektes für das NLP\n",
    "            sent = nlp(sent)\n",
    "\n",
    "            # Erstellung von Placeholders für die Subjekte, Objekte und Wurzeln\n",
    "            subjs = []\n",
    "            objs  = []\n",
    "            roots = []\n",
    "            \n",
    "            # Data Exploration für die Bearbeitung von Fragen\n",
    "            # Erstellung von einer Liste mit den Subjekten (Dependency = 'sb')\n",
    "            s = [word for word in sent if word.dep_ == 'sb']\n",
    "            # Erstellung von einer Liste mit den Objekten (Dependency = 'oa' Objekt Akkusativ)\n",
    "            o = [word for word in sent if word.dep_ == 'oa']\n",
    "            \n",
    "            # Schleife über die Sätze\n",
    "            for token in sent:\n",
    "                # Findet die Subjekte heraus, wenn die Dependency = 'sb', Nominativ\n",
    "                if token.dep_ == 'sb':\n",
    "                    # Fügt den Token in die Subjekt-Liste ein\n",
    "                    subjs.append(token)\n",
    "                    \n",
    "                    # Findet die anderen möglichen Subjekte heraus, falls vielfältige Subjekte vorhanden sind\n",
    "                    subjs = self.get_multiple_elements(subjs)\n",
    "                    \n",
    "                    # Speichert die Wurzeln\n",
    "                    roots.append(token.head)\n",
    "                    # Modalverben werden auch als Wurzel berücksichtigt\n",
    "                    roots = self.get_modal_verb(sent, roots)\n",
    "\n",
    "                # Findet die Objekte heraus. Erlaubte Dependencies:\n",
    "                # 'oa' --> Objekt Akkusativ\n",
    "                # 'da' --> Objekt Dativ\n",
    "                # 'pd' --> Predikat\n",
    "                # 'sbp' --> Subjekt in der Passivform\n",
    "                # 'mo' --> Modifier (z.B.: Präpositionen)\n",
    "                elif token.dep_ == 'oa' or token.dep_ == 'da' or token.dep_ == 'pd' or token.dep_ == 'sbp' or token.dep_ == 'mo':\n",
    "                    # Fügt den Token in die Objekt-Liste ein\n",
    "                    objs.append(token)\n",
    "                    \n",
    "                    # check clausal phrases\n",
    "                    if len(self.get_clause(token))>0:\n",
    "                        subjs.append(token)\n",
    "                        \n",
    "                    # Findet die anderen möglichen Subjekte heraus, falls vielfältige Objekte vorhanden sind\n",
    "                    objs = self.get_multiple_elements(objs)\n",
    "                    \n",
    "                # Die Objekte überprüfen, wenn der Satz eine Frage ist\n",
    "                elif self.is_question(sent) and self.is_question_words_without_obj(token):\n",
    "                    # Wenn die Frage kein Subjekt enthält\n",
    "                    if len(s)==0:\n",
    "                        subjs.append(token)\n",
    "                    # Wenn die Frage kein Objekt enthält\n",
    "                    if len(o)==0:\n",
    "                        objs.append(token)\n",
    "                else:\n",
    "                    None            \n",
    "\n",
    "            # Die Noun Chunks werden geholt\n",
    "            sub_chunks = self.get_chunks(subjs, sent)\n",
    "            obj_chunks = self.get_chunks(objs, sent)\n",
    "            \n",
    "            # Nur die einzigartigen Wurzeln werden beibehalten\n",
    "            roots = list(set(roots))\n",
    "            # Die Relationen werden herausgefunden auf Basis von den Wurzeln\n",
    "            relations = self.get_relations(roots)\n",
    "\n",
    "            # Verbindung von den Subjekten und Objekten über ihre Relationen\n",
    "            df_subjs, df_objs, df_relations, df_info = self.linking_relations(subjs, objs, roots, sub_chunks, obj_chunks, relations)\n",
    "            # Der Satz wird in das Dataframe hinzugefügt \n",
    "            df_info['Sentence'] = str(sent)\n",
    "            # Update von dem bestehenden Dataframe, mit den neuen Informationen aus dem gerade analysierten Satz\n",
    "            df_info_full = pd.concat([df_info_full, df_info])\n",
    "\n",
    "        # Duplikate werden gelöscht\n",
    "        df_info_full.drop_duplicates(subset= ['Subjects', 'Subjects_raw', 'Subject_Type', 'Relations', 'Objects_raw', 'Objects', 'Object_Type', 'Sentence'],\n",
    "                        inplace=True)\n",
    "        \n",
    "        # Vorbose, damit es bewusst ist, wie viele Paare aus einem Dokument extrahiert wurden\n",
    "        print('Pairs extracted: {}'.format(len(df_info_full)))\n",
    "        \n",
    "        # Entwicklungsmodus\n",
    "        if all_info == True:\n",
    "            # Rückgabe von den aus dem Dokument extrahierten Informationen und einzelnen Dataframes: Subjekte, Objekte und Relationen\n",
    "            return df_info_full, df_subjs, df_objs, df_relations\n",
    "        # Produktionsmodus\n",
    "        else:\n",
    "            # Rückgabe von den aus dem Dokument extrahierten Informationen\n",
    "            return df_info_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellung eines Objektes aus der VictoryNLP-Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "victory = VictoryNLP(\"victory\", nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test vom Algorithmus mit einem Text aus den Echtdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:541: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:576: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:670: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:829: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:667: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs extracted: 405\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Objects</th>\n",
       "      <th>Objects_raw</th>\n",
       "      <th>Relations</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Subject_Type</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Subjects_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Stipendien</td>\n",
       "      <td>Stipendien</td>\n",
       "      <td>gewinnen</td>\n",
       "      <td>Talente gewinnen Stipendien Studium mit vertie...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Talente</td>\n",
       "      <td>Talente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Studium</td>\n",
       "      <td>Studium</td>\n",
       "      <td>gewinnen</td>\n",
       "      <td>Talente gewinnen Stipendien Studium mit vertie...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Talente</td>\n",
       "      <td>Talente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>vertiefter Praxis</td>\n",
       "      <td>Praxis</td>\n",
       "      <td>gewinnen</td>\n",
       "      <td>Talente gewinnen Stipendien Studium mit vertie...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Talente</td>\n",
       "      <td>Talente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Die Dirigierbewegung</td>\n",
       "      <td>Dirigierbewegung</td>\n",
       "      <td>erfasst</td>\n",
       "      <td>Die Dirigierbewegung wird durch Radarsensorik ...</td>\n",
       "      <td></td>\n",
       "      <td>Radarsensorik</td>\n",
       "      <td>Radarsensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>das Stück</td>\n",
       "      <td>Stück</td>\n",
       "      <td>abbrechen</td>\n",
       "      <td>Weicht das Metrum zu stark von der Vorgabe des...</td>\n",
       "      <td></td>\n",
       "      <td>das Orchester</td>\n",
       "      <td>Orchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Das Projekt</td>\n",
       "      <td>Projekt</td>\n",
       "      <td>präsentieren</td>\n",
       "      <td>Das Projekt wird von der Hochschule Heilbronn ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>der Hochschule Heilbronn</td>\n",
       "      <td>Hochschule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Hochschulen</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Universität</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Hochschulen</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LOC</td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Universität</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Hochschulen</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LOC</td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Universität</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>der Radarsensorik</td>\n",
       "      <td>Radarsensorik</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td></td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>eine neuartige Plattform</td>\n",
       "      <td>Plattform</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Applikationsfelder</td>\n",
       "      <td>Applikationsfelder</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Bewegungsanalyse</td>\n",
       "      <td>Bewegungsanalyse</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>fließende Gewässer</td>\n",
       "      <td>Gewässer</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>Bienen</td>\n",
       "      <td>Bienen</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>die Erfassung</td>\n",
       "      <td>Erfassung</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Kochvorgängen</td>\n",
       "      <td>Kochvorgängen</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>Automatisierungstechnik</td>\n",
       "      <td>Automatisierungstechnik</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>dem Gebiet</td>\n",
       "      <td>Gebiet</td>\n",
       "      <td>kommen</td>\n",
       "      <td>Zur Stärkung einer bestehenden langjährigen in...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Prof. Philip H. Gaskell</td>\n",
       "      <td>H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>der Fluiddynamik</td>\n",
       "      <td>Fluiddynamik</td>\n",
       "      <td>kommen</td>\n",
       "      <td>Zur Stärkung einer bestehenden langjährigen in...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Prof. Philip H. Gaskell</td>\n",
       "      <td>H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td>dem nordenglischen Durham</td>\n",
       "      <td>Durham</td>\n",
       "      <td>kommen</td>\n",
       "      <td>Zur Stärkung einer bestehenden langjährigen in...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Prof. Philip H. Gaskell</td>\n",
       "      <td>H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>Gastprofessor</td>\n",
       "      <td>Gastprofessor</td>\n",
       "      <td>kommen</td>\n",
       "      <td>Zur Stärkung einer bestehenden langjährigen in...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Prof. Philip H. Gaskell</td>\n",
       "      <td>H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td></td>\n",
       "      <td>die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>kommen</td>\n",
       "      <td>Zur Stärkung einer bestehenden langjährigen in...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Prof. Philip H. Gaskell</td>\n",
       "      <td>H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>einen Doktoranden</td>\n",
       "      <td>Doktoranden</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td></td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Herr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Studiengang MR</td>\n",
       "      <td>Studiengang</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td></td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Herr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Studiengang MR</td>\n",
       "      <td>MR</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td></td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Herr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>einen Doktoranden</td>\n",
       "      <td>Doktoranden</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Gaskell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Studiengang MR</td>\n",
       "      <td>Studiengang</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Gaskell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>Studiengang MR</td>\n",
       "      <td>MR</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Gaskell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Die Gastprofessur</td>\n",
       "      <td>Gastprofessur</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td></td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Prof. Scholle</td>\n",
       "      <td>Prof.</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG</td>\n",
       "      <td>den DAAD</td>\n",
       "      <td>DAAD</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Prof. Scholle</td>\n",
       "      <td>Scholle</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>ca. 25.000 €</td>\n",
       "      <td>€</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>ca. 25.000 €</td>\n",
       "      <td>25.000</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>ca. 25.000 €</td>\n",
       "      <td>ca.</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>UK-Ranking</td>\n",
       "      <td>UK-Ranking</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Platz</td>\n",
       "      <td>Platz</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Oxford</td>\n",
       "      <td>Oxford</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Imperial College</td>\n",
       "      <td>College</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Imperial College</td>\n",
       "      <td>Imperial</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORG</td>\n",
       "      <td>UK-Ranking</td>\n",
       "      <td>UK-Ranking</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Platz</td>\n",
       "      <td>Platz</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Oxford</td>\n",
       "      <td>Oxford</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Imperial College</td>\n",
       "      <td>College</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Imperial College</td>\n",
       "      <td>Imperial</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Object_Type                    Objects              Objects_raw  \\\n",
       "0                              Stipendien               Stipendien   \n",
       "1                                 Studium                  Studium   \n",
       "2                       vertiefter Praxis                   Praxis   \n",
       "0                    Die Dirigierbewegung         Dirigierbewegung   \n",
       "0                               das Stück                    Stück   \n",
       "0                             Das Projekt                  Projekt   \n",
       "0                     den Hochschulen Ulm              Hochschulen   \n",
       "1          LOC        den Hochschulen Ulm                      Ulm   \n",
       "2          LOC                  Pforzheim                Pforzheim   \n",
       "3          ORG        der Universität Ulm              Universität   \n",
       "4          ORG        der Universität Ulm                      Ulm   \n",
       "5                     den Hochschulen Ulm              Hochschulen   \n",
       "6          LOC        den Hochschulen Ulm                      Ulm   \n",
       "7          LOC                  Pforzheim                Pforzheim   \n",
       "8          ORG        der Universität Ulm              Universität   \n",
       "9          ORG        der Universität Ulm                      Ulm   \n",
       "15                    den Hochschulen Ulm              Hochschulen   \n",
       "16         LOC        den Hochschulen Ulm                      Ulm   \n",
       "17         LOC                  Pforzheim                Pforzheim   \n",
       "18         ORG        der Universität Ulm              Universität   \n",
       "19         ORG        der Universität Ulm                      Ulm   \n",
       "0                       der Radarsensorik            Radarsensorik   \n",
       "1                eine neuartige Plattform                Plattform   \n",
       "2                      Applikationsfelder       Applikationsfelder   \n",
       "3                        Bewegungsanalyse         Bewegungsanalyse   \n",
       "4                      fließende Gewässer                 Gewässer   \n",
       "5                                  Bienen                   Bienen   \n",
       "6                           die Erfassung                Erfassung   \n",
       "7          LOC              Kochvorgängen            Kochvorgängen   \n",
       "8                 Automatisierungstechnik  Automatisierungstechnik   \n",
       "..         ...                        ...                      ...   \n",
       "30                             dem Gebiet                   Gebiet   \n",
       "31                       der Fluiddynamik             Fluiddynamik   \n",
       "32              dem nordenglischen Durham                   Durham   \n",
       "33                          Gastprofessor            Gastprofessor   \n",
       "34                         die Hochschule               Hochschule   \n",
       "0                       einen Doktoranden              Doktoranden   \n",
       "1                          Studiengang MR              Studiengang   \n",
       "2                          Studiengang MR                       MR   \n",
       "3                       einen Doktoranden              Doktoranden   \n",
       "4                          Studiengang MR              Studiengang   \n",
       "5                          Studiengang MR                       MR   \n",
       "0                       Die Gastprofessur            Gastprofessur   \n",
       "1         MISC              Prof. Scholle                    Prof.   \n",
       "2          ORG                   den DAAD                     DAAD   \n",
       "3         MISC              Prof. Scholle                  Scholle   \n",
       "4                            ca. 25.000 €                        €   \n",
       "5                            ca. 25.000 €                   25.000   \n",
       "6                            ca. 25.000 €                      ca.   \n",
       "0          ORG                 UK-Ranking               UK-Ranking   \n",
       "1                                   Platz                    Platz   \n",
       "2          LOC                     Oxford                   Oxford   \n",
       "3          ORG                  Cambridge                Cambridge   \n",
       "4          ORG           Imperial College                  College   \n",
       "5          ORG           Imperial College                 Imperial   \n",
       "6          ORG                 UK-Ranking               UK-Ranking   \n",
       "7                                   Platz                    Platz   \n",
       "8          LOC                     Oxford                   Oxford   \n",
       "9          ORG                  Cambridge                Cambridge   \n",
       "10         ORG           Imperial College                  College   \n",
       "11         ORG           Imperial College                 Imperial   \n",
       "\n",
       "       Relations                                           Sentence  \\\n",
       "0       gewinnen  Talente gewinnen Stipendien Studium mit vertie...   \n",
       "1       gewinnen  Talente gewinnen Stipendien Studium mit vertie...   \n",
       "2       gewinnen  Talente gewinnen Stipendien Studium mit vertie...   \n",
       "0        erfasst  Die Dirigierbewegung wird durch Radarsensorik ...   \n",
       "0      abbrechen  Weicht das Metrum zu stark von der Vorgabe des...   \n",
       "0   präsentieren  Das Projekt wird von der Hochschule Heilbronn ...   \n",
       "0      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "1      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "2      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "3      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "4      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "5      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "6      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "7      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "8      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "9      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "15     entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "16     entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "17     entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "18     entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "19     entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "0    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "1    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "2    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "3    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "4    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "5    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "6    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "7    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "8    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "..           ...                                                ...   \n",
       "30        kommen  Zur Stärkung einer bestehenden langjährigen in...   \n",
       "31        kommen  Zur Stärkung einer bestehenden langjährigen in...   \n",
       "32        kommen  Zur Stärkung einer bestehenden langjährigen in...   \n",
       "33        kommen  Zur Stärkung einer bestehenden langjährigen in...   \n",
       "34        kommen  Zur Stärkung einer bestehenden langjährigen in...   \n",
       "0       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "1       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "2       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "3       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "4       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "5       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "0   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "1   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "2   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "3   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "4   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "5   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "6   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "0         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "1         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "2         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "3         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "4         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "5         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "6         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "7         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "8         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "9         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "10        stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "11        stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "\n",
       "                Subject_Type                                        Subjects  \\\n",
       "0                        PER                                         Talente   \n",
       "1                        PER                                         Talente   \n",
       "2                        PER                                         Talente   \n",
       "0                                                              Radarsensorik   \n",
       "0                                                              das Orchester   \n",
       "0                        ORG                        der Hochschule Heilbronn   \n",
       "0                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "1                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "2                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "3                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "4                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "5                        ORG                                       MikroSens   \n",
       "6                        ORG                                       MikroSens   \n",
       "7                        ORG                                       MikroSens   \n",
       "8                        ORG                                       MikroSens   \n",
       "9                        ORG                                       MikroSens   \n",
       "15                       ORG                        industrielle Anwendungen   \n",
       "16                       ORG                        industrielle Anwendungen   \n",
       "17                       ORG                        industrielle Anwendungen   \n",
       "18                       ORG                        industrielle Anwendungen   \n",
       "19                       ORG                        industrielle Anwendungen   \n",
       "0                                                   diesem Forschungsprojekt   \n",
       "1   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "2   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "3   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "4   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "5   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "6   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "7   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "8   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "..                       ...                                             ...   \n",
       "30                       PER                    Herr Prof. Philip H. Gaskell   \n",
       "31                       PER                    Herr Prof. Philip H. Gaskell   \n",
       "32                       PER                    Herr Prof. Philip H. Gaskell   \n",
       "33                       PER                    Herr Prof. Philip H. Gaskell   \n",
       "34                       PER                    Herr Prof. Philip H. Gaskell   \n",
       "0                                                               Herr Gaskell   \n",
       "1                                                               Herr Gaskell   \n",
       "2                                                               Herr Gaskell   \n",
       "3                        PER                                    Herr Gaskell   \n",
       "4                        PER                                    Herr Gaskell   \n",
       "5                        PER                                    Herr Gaskell   \n",
       "0                                                                     Antrag   \n",
       "1                     Antrag                                          Antrag   \n",
       "2                     Antrag                                          Antrag   \n",
       "3                     Antrag                                          Antrag   \n",
       "4                     Antrag                                          Antrag   \n",
       "5                     Antrag                                          Antrag   \n",
       "6                     Antrag                                          Antrag   \n",
       "0                        ORG                           Die Durham University   \n",
       "1                        ORG                           Die Durham University   \n",
       "2                        ORG                           Die Durham University   \n",
       "3                        ORG                           Die Durham University   \n",
       "4                        ORG                           Die Durham University   \n",
       "5                        ORG                           Die Durham University   \n",
       "6                        ORG                           Die Durham University   \n",
       "7                        ORG                           Die Durham University   \n",
       "8                        ORG                           Die Durham University   \n",
       "9                        ORG                           Die Durham University   \n",
       "10                       ORG                           Die Durham University   \n",
       "11                       ORG                           Die Durham University   \n",
       "\n",
       "                 Subjects_raw  \n",
       "0                     Talente  \n",
       "1                     Talente  \n",
       "2                     Talente  \n",
       "0               Radarsensorik  \n",
       "0                   Orchester  \n",
       "0                  Hochschule  \n",
       "0   Millimeterwellen-Sensorik  \n",
       "1   Millimeterwellen-Sensorik  \n",
       "2   Millimeterwellen-Sensorik  \n",
       "3   Millimeterwellen-Sensorik  \n",
       "4   Millimeterwellen-Sensorik  \n",
       "5                   MikroSens  \n",
       "6                   MikroSens  \n",
       "7                   MikroSens  \n",
       "8                   MikroSens  \n",
       "9                   MikroSens  \n",
       "15                Anwendungen  \n",
       "16                Anwendungen  \n",
       "17                Anwendungen  \n",
       "18                Anwendungen  \n",
       "19                Anwendungen  \n",
       "0           Forschungsprojekt  \n",
       "1           Forschungsprojekt  \n",
       "2           Forschungsprojekt  \n",
       "3           Forschungsprojekt  \n",
       "4           Forschungsprojekt  \n",
       "5           Forschungsprojekt  \n",
       "6           Forschungsprojekt  \n",
       "7           Forschungsprojekt  \n",
       "8           Forschungsprojekt  \n",
       "..                        ...  \n",
       "30                         H.  \n",
       "31                         H.  \n",
       "32                         H.  \n",
       "33                         H.  \n",
       "34                         H.  \n",
       "0                        Herr  \n",
       "1                        Herr  \n",
       "2                        Herr  \n",
       "3                     Gaskell  \n",
       "4                     Gaskell  \n",
       "5                     Gaskell  \n",
       "0                      Antrag  \n",
       "1                      Antrag  \n",
       "2                      Antrag  \n",
       "3                      Antrag  \n",
       "4                      Antrag  \n",
       "5                      Antrag  \n",
       "6                      Antrag  \n",
       "0                  University  \n",
       "1                  University  \n",
       "2                  University  \n",
       "3                  University  \n",
       "4                  University  \n",
       "5                  University  \n",
       "6                      Durham  \n",
       "7                      Durham  \n",
       "8                      Durham  \n",
       "9                      Durham  \n",
       "10                     Durham  \n",
       "11                     Durham  \n",
       "\n",
       "[405 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Test mit dem Text aus dem Zweiten Dokument aus den von Gruppe 1 zur Verfügung gestellten Daten\n",
    "'''\n",
    "text = df['Text'][1]\n",
    "df_info_full = victory.information_extraction(text)\n",
    "df_info_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entwicklungsmodus: Test mit einem selbsterstellten Satz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs extracted: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:541: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:576: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:670: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"das interessante Buch wird von Victor nicht heute am schönen Strand gelesen, sondern fährt er das schnelle Auto\"\n",
    "df_info_full, df_subjs, df_objs, df_relations = victory.information_extraction(text, all_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extrahierten Informationen in Form von Subjekten Objekten und ihren Beziehungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Objects</th>\n",
       "      <th>Objects_raw</th>\n",
       "      <th>Relations</th>\n",
       "      <th>Subject_Type</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Subjects_raw</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>das interessante Buch</td>\n",
       "      <td>Buch</td>\n",
       "      <td>lesen</td>\n",
       "      <td>PER</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>das interessante Buch wird von Victor nicht he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>schönen Strand</td>\n",
       "      <td>Strand</td>\n",
       "      <td>lesen</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>das interessante Buch wird von Victor nicht he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>das schnelle Auto</td>\n",
       "      <td>Auto</td>\n",
       "      <td>fahren</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>das interessante Buch wird von Victor nicht he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Object_Type                Objects Objects_raw Relations Subject_Type  \\\n",
       "0              das interessante Buch        Buch     lesen          PER   \n",
       "1                     schönen Strand      Strand     lesen       Victor   \n",
       "2                  das schnelle Auto        Auto    fahren       Victor   \n",
       "\n",
       "  Subjects Subjects_raw                                           Sentence  \n",
       "0   Victor       Victor  das interessante Buch wird von Victor nicht he...  \n",
       "1   Victor       Victor  das interessante Buch wird von Victor nicht he...  \n",
       "2   Victor       Victor  das interessante Buch wird von Victor nicht he...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Objekte und ihre wesentlichen Informationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj</th>\n",
       "      <th>obj_chunk</th>\n",
       "      <th>obj_type</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>PER</td>\n",
       "      <td>gelesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Strand</td>\n",
       "      <td>schönen Strand</td>\n",
       "      <td></td>\n",
       "      <td>gelesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto</td>\n",
       "      <td>das schnelle Auto</td>\n",
       "      <td></td>\n",
       "      <td>fährt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      obj          obj_chunk obj_type     root\n",
       "0  Victor             Victor      PER  gelesen\n",
       "1  Strand     schönen Strand           gelesen\n",
       "2    Auto  das schnelle Auto             fährt"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subjekte und ihre wesentlichen Informationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root</th>\n",
       "      <th>subj</th>\n",
       "      <th>subj_chunk</th>\n",
       "      <th>subj_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wird</td>\n",
       "      <td>Buch</td>\n",
       "      <td>das interessante Buch</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fährt</td>\n",
       "      <td>er</td>\n",
       "      <td>er</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    root  subj             subj_chunk subj_type\n",
       "0   wird  Buch  das interessante Buch          \n",
       "1  fährt    er                     er          "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relationen und Wurzeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wird gelesen</td>\n",
       "      <td>gelesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wird gelesen</td>\n",
       "      <td>wird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fährt</td>\n",
       "      <td>fährt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       relation     root\n",
       "0  wird gelesen  gelesen\n",
       "1  wird gelesen     wird\n",
       "2         fährt    fährt"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methode für die Ausführung des NLP-Verfahrens über alle Dokumente (Aus dem Hauptdatensazt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 0\n",
      "Error\n",
      "___________________________________________________\n",
      "Document: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:541: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:576: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:670: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:829: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:667: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs extracted: 409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:32: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:35: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________\n",
      "Document: 2\n",
      "Pairs extracted: 3\n",
      "___________________________________________________\n",
      "Document: 3\n",
      "Error\n",
      "___________________________________________________\n",
      "Document: 4\n",
      "Pairs extracted: 257\n",
      "___________________________________________________\n",
      "Document: 5\n",
      "Error\n",
      "___________________________________________________\n",
      "Document: 6\n",
      "Pairs extracted: 3\n",
      "___________________________________________________\n",
      "Document: 7\n",
      "Pairs extracted: 0\n",
      "___________________________________________________\n",
      "Document: 8\n",
      "Pairs extracted: 3\n",
      "___________________________________________________\n",
      "Document: 9\n",
      "Pairs extracted: 131\n",
      "___________________________________________________\n",
      "Document: 10\n",
      "Error\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Metadata aus dem Hauptdatensatz\n",
    "metadata = [col for col in df.columns if col != 'Text']\n",
    "\n",
    "# Features aus dem NLP-Verfahren\n",
    "kg_data_cols = ['Subjects', 'Subjects_raw', 'Subject_Type', 'Relations', 'Objects_raw', 'Objects', 'Object_Type', 'Sentence']\n",
    "\n",
    "# Zusammenfügung von allen Features\n",
    "columns = metadata + kg_data_cols\n",
    "\n",
    "# Erstellung eines leeren Dataframes\n",
    "kg_df = pd.DataFrame(columns=columns)\n",
    "df_error = []\n",
    "\n",
    "# Erstellung eines Objektes aus der VictoryNLP-Klasse\n",
    "victory = VictoryNLP(\"victory\", nlp)\n",
    "\n",
    "# Schleife über den Hauptdatensatz\n",
    "for i, doc in df.iterrows():\n",
    "    \n",
    "    # Erstellung eines Dataframes für alle Extrahierten Informationen aus einem Dokument\n",
    "    doc = pd.DataFrame(doc).T\n",
    "    # Einstellung der Spalten\n",
    "    cache = pd.DataFrame(columns=columns)\n",
    "        \n",
    "    # Wird versucht, die Informationen aus einem Dokument zu extrahieren\n",
    "    try:\n",
    "        print('Document: {}'.format(i))\n",
    "        pairs = victory.information_extraction(doc.iloc[0]['Text'])\n",
    "        cache = pd.concat([cache, pairs])\n",
    "        for feature in metadata:\n",
    "            cache[feature] = cache[feature].apply(lambda row : doc.iloc[0][feature])\n",
    "        kg_df = pd.concat([kg_df,cache])\n",
    "        print('___________________________________________________')\n",
    "        \n",
    "    # Wird angezeigt, dass ein Fehler passiert ist\n",
    "    except:\n",
    "        df_error.append(doc.iloc[0]['ID'])\n",
    "        print('Error')\n",
    "        print('___________________________________________________')\n",
    "        \n",
    "    # Speichert den Datensatz während der Ausführung des NLP-Verfahren (in 100-Schritten)\n",
    "    if i%100==0:\n",
    "        kg_df.to_csv(r'pairs_datensatz_v2.csv')\n",
    "# Speichert am Ende\n",
    "kg_df.to_csv(r'pairs_datensatz_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis der Datenextrahierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Course</th>\n",
       "      <th>Course_abbreviation</th>\n",
       "      <th>Course_location</th>\n",
       "      <th>Creation-Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>Last-Modified</th>\n",
       "      <th>Link</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Objects</th>\n",
       "      <th>Objects_raw</th>\n",
       "      <th>Relations</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Subject_Type</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Subjects_raw</th>\n",
       "      <th>Title</th>\n",
       "      <th>Upload-Date</th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>Stipendien</td>\n",
       "      <td>Stipendien</td>\n",
       "      <td>gewinnen</td>\n",
       "      <td>Talente gewinnen Stipendien Studium mit vertie...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Talente</td>\n",
       "      <td>Talente</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>Studium</td>\n",
       "      <td>Studium</td>\n",
       "      <td>gewinnen</td>\n",
       "      <td>Talente gewinnen Stipendien Studium mit vertie...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Talente</td>\n",
       "      <td>Talente</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>vertiefter Praxis</td>\n",
       "      <td>Praxis</td>\n",
       "      <td>gewinnen</td>\n",
       "      <td>Talente gewinnen Stipendien Studium mit vertie...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Talente</td>\n",
       "      <td>Talente</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>Die Dirigierbewegung</td>\n",
       "      <td>Dirigierbewegung</td>\n",
       "      <td>erfasst</td>\n",
       "      <td>Die Dirigierbewegung wird durch Radarsensorik ...</td>\n",
       "      <td></td>\n",
       "      <td>Radarsensorik</td>\n",
       "      <td>Radarsensorik</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>das Stück</td>\n",
       "      <td>Stück</td>\n",
       "      <td>abbrechen</td>\n",
       "      <td>Weicht das Metrum zu stark von der Vorgabe des...</td>\n",
       "      <td></td>\n",
       "      <td>das Orchester</td>\n",
       "      <td>Orchester</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>Das Projekt</td>\n",
       "      <td>Projekt</td>\n",
       "      <td>präsentieren</td>\n",
       "      <td>Das Projekt wird von der Hochschule Heilbronn ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>der Hochschule Heilbronn</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Hochschulen</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Universität</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Hochschulen</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Universität</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Hochschulen</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Universität</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>der Radarsensorik</td>\n",
       "      <td>Radarsensorik</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td></td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>eine neuartige Plattform</td>\n",
       "      <td>Plattform</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>Applikationsfelder</td>\n",
       "      <td>Applikationsfelder</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>Bewegungsanalyse</td>\n",
       "      <td>Bewegungsanalyse</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>fließende Gewässer</td>\n",
       "      <td>Gewässer</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>Bienen</td>\n",
       "      <td>Bienen</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>die Erfassung</td>\n",
       "      <td>Erfassung</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Kochvorgängen</td>\n",
       "      <td>Kochvorgängen</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>u4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/21278004/rueckblick-2018-a...</td>\n",
       "      <td></td>\n",
       "      <td>Automatisierungstechnik</td>\n",
       "      <td>Automatisierungstechnik</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "      <td>MR-Aktivitäten - Hochschule Heilbronn</td>\n",
       "      <td>2020-06-18T00:42:06.083993Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>der Werks- und Fertigungsplanung</td>\n",
       "      <td>Fertigungsplanung</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>ein Absolvent</td>\n",
       "      <td>Absolvent</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Bosch Rexroth</td>\n",
       "      <td>Rexroth</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>ein Absolvent</td>\n",
       "      <td>Absolvent</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Bosch Rexroth</td>\n",
       "      <td>Bosch</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>ein Absolvent</td>\n",
       "      <td>Absolvent</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>auch Erik Müller</td>\n",
       "      <td>auch</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Studiengangs</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>seine Erfahrungen</td>\n",
       "      <td>Erfahrungen</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Studiengangs</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>Projektleiter</td>\n",
       "      <td>Projektleiter</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Studiengangs</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>der Werks- und Fertigungsplanung</td>\n",
       "      <td>Fertigungsplanung</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Studiengangs</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Bosch Rexroth</td>\n",
       "      <td>Rexroth</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Studiengangs</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Bosch Rexroth</td>\n",
       "      <td>Bosch</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Studiengangs</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>auch Erik Müller</td>\n",
       "      <td>auch</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Wirtschaftsingenieurwesen</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>seine Erfahrungen</td>\n",
       "      <td>Erfahrungen</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Wirtschaftsingenieurwesen</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>Projektleiter</td>\n",
       "      <td>Projektleiter</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Wirtschaftsingenieurwesen</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>der Werks- und Fertigungsplanung</td>\n",
       "      <td>Fertigungsplanung</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Wirtschaftsingenieurwesen</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Bosch Rexroth</td>\n",
       "      <td>Rexroth</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Wirtschaftsingenieurwesen</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Bosch Rexroth</td>\n",
       "      <td>Bosch</td>\n",
       "      <td>können einbringen</td>\n",
       "      <td>In dieser konnte auch Erik Müller, ein Absolve...</td>\n",
       "      <td></td>\n",
       "      <td>des Studiengangs Wirtschaftsingenieurwesen</td>\n",
       "      <td>Wirtschaftsingenieurwesen</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>die Chance</td>\n",
       "      <td>Chance</td>\n",
       "      <td>nutzen</td>\n",
       "      <td>Das Publikum nutzte die Chance und brachte sic...</td>\n",
       "      <td></td>\n",
       "      <td>Das Publikum</td>\n",
       "      <td>Publikum</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>den Bereichen Technik</td>\n",
       "      <td>Bereichen</td>\n",
       "      <td>liegen</td>\n",
       "      <td>Ihr Kompetenz-Schwerpunkt liegt auf den Bereic...</td>\n",
       "      <td></td>\n",
       "      <td>Ihr Kompetenz-Schwerpunkt</td>\n",
       "      <td>Kompetenz-Schwerpunkt</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>den Bereichen Technik</td>\n",
       "      <td>Technik</td>\n",
       "      <td>liegen</td>\n",
       "      <td>Ihr Kompetenz-Schwerpunkt liegt auf den Bereic...</td>\n",
       "      <td></td>\n",
       "      <td>Ihr Kompetenz-Schwerpunkt</td>\n",
       "      <td>Kompetenz-Schwerpunkt</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>Wirtschaft</td>\n",
       "      <td>Wirtschaft</td>\n",
       "      <td>liegen</td>\n",
       "      <td>Ihr Kompetenz-Schwerpunkt liegt auf den Bereic...</td>\n",
       "      <td></td>\n",
       "      <td>Ihr Kompetenz-Schwerpunkt</td>\n",
       "      <td>Kompetenz-Schwerpunkt</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>Informatik</td>\n",
       "      <td>Informatik</td>\n",
       "      <td>liegen</td>\n",
       "      <td>Ihr Kompetenz-Schwerpunkt liegt auf den Bereic...</td>\n",
       "      <td></td>\n",
       "      <td>Ihr Kompetenz-Schwerpunkt</td>\n",
       "      <td>Kompetenz-Schwerpunkt</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>drei Standorten</td>\n",
       "      <td>Standorten</td>\n",
       "      <td>anbieten</td>\n",
       "      <td>An drei Standorten in Heilbronn, Künzelsau und...</td>\n",
       "      <td></td>\n",
       "      <td>die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>drei Standorten</td>\n",
       "      <td>drei</td>\n",
       "      <td>anbieten</td>\n",
       "      <td>An drei Standorten in Heilbronn, Künzelsau und...</td>\n",
       "      <td></td>\n",
       "      <td>die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Heilbronn</td>\n",
       "      <td>Heilbronn</td>\n",
       "      <td>anbieten</td>\n",
       "      <td>An drei Standorten in Heilbronn, Künzelsau und...</td>\n",
       "      <td></td>\n",
       "      <td>die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Künzelsau</td>\n",
       "      <td>Künzelsau</td>\n",
       "      <td>anbieten</td>\n",
       "      <td>An drei Standorten in Heilbronn, Künzelsau und...</td>\n",
       "      <td></td>\n",
       "      <td>die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Schwäbisch Hall</td>\n",
       "      <td>Hall</td>\n",
       "      <td>anbieten</td>\n",
       "      <td>An drei Standorten in Heilbronn, Künzelsau und...</td>\n",
       "      <td></td>\n",
       "      <td>die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Schwäbisch Hall</td>\n",
       "      <td>Schwäbisch</td>\n",
       "      <td>anbieten</td>\n",
       "      <td>An drei Standorten in Heilbronn, Künzelsau und...</td>\n",
       "      <td></td>\n",
       "      <td>die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>mehr als 50 Bachelor- und Masterstudiengänge</td>\n",
       "      <td>Masterstudiengänge</td>\n",
       "      <td>anbieten</td>\n",
       "      <td>An drei Standorten in Heilbronn, Künzelsau und...</td>\n",
       "      <td></td>\n",
       "      <td>die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>enge Kooperationen</td>\n",
       "      <td>Kooperationen</td>\n",
       "      <td>pflegen</td>\n",
       "      <td>Die Hochschule pflegt enge Kooperationen mit U...</td>\n",
       "      <td></td>\n",
       "      <td>Die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>Unternehmen</td>\n",
       "      <td>Unternehmen</td>\n",
       "      <td>pflegen</td>\n",
       "      <td>Die Hochschule pflegt enge Kooperationen mit U...</td>\n",
       "      <td></td>\n",
       "      <td>Die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>w4EBxXIB7QWdo8C6vTMN</td>\n",
       "      <td>None</td>\n",
       "      <td>www.hs-heilbronn.de/19243375/komplexe-entschei...</td>\n",
       "      <td></td>\n",
       "      <td>der Region</td>\n",
       "      <td>Region</td>\n",
       "      <td>pflegen</td>\n",
       "      <td>Die Hochschule pflegt enge Kooperationen mit U...</td>\n",
       "      <td></td>\n",
       "      <td>Die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>Komplexe Entscheidungen mit gesundem Menschenv...</td>\n",
       "      <td>2020-06-18T00:42:37.507850Z</td>\n",
       "      <td>mid_beispieldaten_v9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Author Course Course_abbreviation Course_location Creation-Date  \\\n",
       "0    None                                                     None   \n",
       "1    None                                                     None   \n",
       "2    None                                                     None   \n",
       "0    None                                                     None   \n",
       "0    None                                                     None   \n",
       "0    None                                                     None   \n",
       "0    None                                                     None   \n",
       "1    None                                                     None   \n",
       "2    None                                                     None   \n",
       "3    None                                                     None   \n",
       "4    None                                                     None   \n",
       "5    None                                                     None   \n",
       "6    None                                                     None   \n",
       "7    None                                                     None   \n",
       "8    None                                                     None   \n",
       "9    None                                                     None   \n",
       "15   None                                                     None   \n",
       "16   None                                                     None   \n",
       "17   None                                                     None   \n",
       "18   None                                                     None   \n",
       "19   None                                                     None   \n",
       "0    None                                                     None   \n",
       "1    None                                                     None   \n",
       "2    None                                                     None   \n",
       "3    None                                                     None   \n",
       "4    None                                                     None   \n",
       "5    None                                                     None   \n",
       "6    None                                                     None   \n",
       "7    None                                                     None   \n",
       "8    None                                                     None   \n",
       "..    ...    ...                 ...             ...           ...   \n",
       "13   None                                                     None   \n",
       "14   None                                                     None   \n",
       "15   None                                                     None   \n",
       "16   None                                                     None   \n",
       "17   None                                                     None   \n",
       "18   None                                                     None   \n",
       "19   None                                                     None   \n",
       "20   None                                                     None   \n",
       "21   None                                                     None   \n",
       "22   None                                                     None   \n",
       "23   None                                                     None   \n",
       "24   None                                                     None   \n",
       "25   None                                                     None   \n",
       "26   None                                                     None   \n",
       "27   None                                                     None   \n",
       "0    None                                                     None   \n",
       "0    None                                                     None   \n",
       "1    None                                                     None   \n",
       "2    None                                                     None   \n",
       "3    None                                                     None   \n",
       "0    None                                                     None   \n",
       "1    None                                                     None   \n",
       "2    None                                                     None   \n",
       "3    None                                                     None   \n",
       "4    None                                                     None   \n",
       "5    None                                                     None   \n",
       "6    None                                                     None   \n",
       "0    None                                                     None   \n",
       "1    None                                                     None   \n",
       "2    None                                                     None   \n",
       "\n",
       "                      ID Last-Modified  \\\n",
       "0   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "1   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "2   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "0   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "0   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "0   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "0   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "1   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "2   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "3   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "4   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "5   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "6   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "7   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "8   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "9   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "15  u4EBxXIB7QWdo8C6vTMN          None   \n",
       "16  u4EBxXIB7QWdo8C6vTMN          None   \n",
       "17  u4EBxXIB7QWdo8C6vTMN          None   \n",
       "18  u4EBxXIB7QWdo8C6vTMN          None   \n",
       "19  u4EBxXIB7QWdo8C6vTMN          None   \n",
       "0   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "1   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "2   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "3   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "4   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "5   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "6   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "7   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "8   u4EBxXIB7QWdo8C6vTMN          None   \n",
       "..                   ...           ...   \n",
       "13  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "14  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "15  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "16  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "17  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "18  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "19  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "20  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "21  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "22  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "23  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "24  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "25  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "26  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "27  w4EBxXIB7QWdo8C6vTMN          None   \n",
       "0   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "0   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "1   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "2   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "3   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "0   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "1   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "2   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "3   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "4   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "5   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "6   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "0   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "1   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "2   w4EBxXIB7QWdo8C6vTMN          None   \n",
       "\n",
       "                                                 Link Object_Type  \\\n",
       "0   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "1   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "2   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "0   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "0   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "0   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "0   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "1   www.hs-heilbronn.de/21278004/rueckblick-2018-a...         LOC   \n",
       "2   www.hs-heilbronn.de/21278004/rueckblick-2018-a...         LOC   \n",
       "3   www.hs-heilbronn.de/21278004/rueckblick-2018-a...         ORG   \n",
       "4   www.hs-heilbronn.de/21278004/rueckblick-2018-a...         ORG   \n",
       "5   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "6   www.hs-heilbronn.de/21278004/rueckblick-2018-a...         LOC   \n",
       "7   www.hs-heilbronn.de/21278004/rueckblick-2018-a...         LOC   \n",
       "8   www.hs-heilbronn.de/21278004/rueckblick-2018-a...         ORG   \n",
       "9   www.hs-heilbronn.de/21278004/rueckblick-2018-a...         ORG   \n",
       "15  www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "16  www.hs-heilbronn.de/21278004/rueckblick-2018-a...         LOC   \n",
       "17  www.hs-heilbronn.de/21278004/rueckblick-2018-a...         LOC   \n",
       "18  www.hs-heilbronn.de/21278004/rueckblick-2018-a...         ORG   \n",
       "19  www.hs-heilbronn.de/21278004/rueckblick-2018-a...         ORG   \n",
       "0   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "1   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "2   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "3   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "4   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "5   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "6   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "7   www.hs-heilbronn.de/21278004/rueckblick-2018-a...         LOC   \n",
       "8   www.hs-heilbronn.de/21278004/rueckblick-2018-a...               \n",
       "..                                                ...         ...   \n",
       "13  www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "14  www.hs-heilbronn.de/19243375/komplexe-entschei...         PER   \n",
       "15  www.hs-heilbronn.de/19243375/komplexe-entschei...         PER   \n",
       "16  www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "17  www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "18  www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "19  www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "20  www.hs-heilbronn.de/19243375/komplexe-entschei...         PER   \n",
       "21  www.hs-heilbronn.de/19243375/komplexe-entschei...         PER   \n",
       "22  www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "23  www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "24  www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "25  www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "26  www.hs-heilbronn.de/19243375/komplexe-entschei...         PER   \n",
       "27  www.hs-heilbronn.de/19243375/komplexe-entschei...         PER   \n",
       "0   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "0   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "1   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "2   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "3   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "0   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "1   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "2   www.hs-heilbronn.de/19243375/komplexe-entschei...         LOC   \n",
       "3   www.hs-heilbronn.de/19243375/komplexe-entschei...         LOC   \n",
       "4   www.hs-heilbronn.de/19243375/komplexe-entschei...         LOC   \n",
       "5   www.hs-heilbronn.de/19243375/komplexe-entschei...         LOC   \n",
       "6   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "0   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "1   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "2   www.hs-heilbronn.de/19243375/komplexe-entschei...               \n",
       "\n",
       "                                         Objects              Objects_raw  \\\n",
       "0                                     Stipendien               Stipendien   \n",
       "1                                        Studium                  Studium   \n",
       "2                              vertiefter Praxis                   Praxis   \n",
       "0                           Die Dirigierbewegung         Dirigierbewegung   \n",
       "0                                      das Stück                    Stück   \n",
       "0                                    Das Projekt                  Projekt   \n",
       "0                            den Hochschulen Ulm              Hochschulen   \n",
       "1                            den Hochschulen Ulm                      Ulm   \n",
       "2                                      Pforzheim                Pforzheim   \n",
       "3                            der Universität Ulm              Universität   \n",
       "4                            der Universität Ulm                      Ulm   \n",
       "5                            den Hochschulen Ulm              Hochschulen   \n",
       "6                            den Hochschulen Ulm                      Ulm   \n",
       "7                                      Pforzheim                Pforzheim   \n",
       "8                            der Universität Ulm              Universität   \n",
       "9                            der Universität Ulm                      Ulm   \n",
       "15                           den Hochschulen Ulm              Hochschulen   \n",
       "16                           den Hochschulen Ulm                      Ulm   \n",
       "17                                     Pforzheim                Pforzheim   \n",
       "18                           der Universität Ulm              Universität   \n",
       "19                           der Universität Ulm                      Ulm   \n",
       "0                              der Radarsensorik            Radarsensorik   \n",
       "1                       eine neuartige Plattform                Plattform   \n",
       "2                             Applikationsfelder       Applikationsfelder   \n",
       "3                               Bewegungsanalyse         Bewegungsanalyse   \n",
       "4                             fließende Gewässer                 Gewässer   \n",
       "5                                         Bienen                   Bienen   \n",
       "6                                  die Erfassung                Erfassung   \n",
       "7                                  Kochvorgängen            Kochvorgängen   \n",
       "8                        Automatisierungstechnik  Automatisierungstechnik   \n",
       "..                                           ...                      ...   \n",
       "13              der Werks- und Fertigungsplanung        Fertigungsplanung   \n",
       "14                                 Bosch Rexroth                  Rexroth   \n",
       "15                                 Bosch Rexroth                    Bosch   \n",
       "16                              auch Erik Müller                     auch   \n",
       "17                             seine Erfahrungen              Erfahrungen   \n",
       "18                                 Projektleiter            Projektleiter   \n",
       "19              der Werks- und Fertigungsplanung        Fertigungsplanung   \n",
       "20                                 Bosch Rexroth                  Rexroth   \n",
       "21                                 Bosch Rexroth                    Bosch   \n",
       "22                              auch Erik Müller                     auch   \n",
       "23                             seine Erfahrungen              Erfahrungen   \n",
       "24                                 Projektleiter            Projektleiter   \n",
       "25              der Werks- und Fertigungsplanung        Fertigungsplanung   \n",
       "26                                 Bosch Rexroth                  Rexroth   \n",
       "27                                 Bosch Rexroth                    Bosch   \n",
       "0                                     die Chance                   Chance   \n",
       "0                          den Bereichen Technik                Bereichen   \n",
       "1                          den Bereichen Technik                  Technik   \n",
       "2                                     Wirtschaft               Wirtschaft   \n",
       "3                                     Informatik               Informatik   \n",
       "0                                drei Standorten               Standorten   \n",
       "1                                drei Standorten                     drei   \n",
       "2                                      Heilbronn                Heilbronn   \n",
       "3                                      Künzelsau                Künzelsau   \n",
       "4                                Schwäbisch Hall                     Hall   \n",
       "5                                Schwäbisch Hall               Schwäbisch   \n",
       "6   mehr als 50 Bachelor- und Masterstudiengänge       Masterstudiengänge   \n",
       "0                             enge Kooperationen            Kooperationen   \n",
       "1                                    Unternehmen              Unternehmen   \n",
       "2                                     der Region                   Region   \n",
       "\n",
       "            Relations                                           Sentence  \\\n",
       "0            gewinnen  Talente gewinnen Stipendien Studium mit vertie...   \n",
       "1            gewinnen  Talente gewinnen Stipendien Studium mit vertie...   \n",
       "2            gewinnen  Talente gewinnen Stipendien Studium mit vertie...   \n",
       "0             erfasst  Die Dirigierbewegung wird durch Radarsensorik ...   \n",
       "0           abbrechen  Weicht das Metrum zu stark von der Vorgabe des...   \n",
       "0        präsentieren  Das Projekt wird von der Hochschule Heilbronn ...   \n",
       "0           entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "1           entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "2           entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "3           entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "4           entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "5           entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "6           entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "7           entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "8           entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "9           entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "15          entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "16          entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "17          entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "18          entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "19          entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "0         erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "1         erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "2         erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "3         erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "4         erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "5         erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "6         erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "7         erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "8         erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "..                ...                                                ...   \n",
       "13  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "14  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "15  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "16  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "17  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "18  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "19  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "20  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "21  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "22  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "23  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "24  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "25  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "26  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "27  können einbringen  In dieser konnte auch Erik Müller, ein Absolve...   \n",
       "0              nutzen  Das Publikum nutzte die Chance und brachte sic...   \n",
       "0              liegen  Ihr Kompetenz-Schwerpunkt liegt auf den Bereic...   \n",
       "1              liegen  Ihr Kompetenz-Schwerpunkt liegt auf den Bereic...   \n",
       "2              liegen  Ihr Kompetenz-Schwerpunkt liegt auf den Bereic...   \n",
       "3              liegen  Ihr Kompetenz-Schwerpunkt liegt auf den Bereic...   \n",
       "0            anbieten  An drei Standorten in Heilbronn, Künzelsau und...   \n",
       "1            anbieten  An drei Standorten in Heilbronn, Künzelsau und...   \n",
       "2            anbieten  An drei Standorten in Heilbronn, Künzelsau und...   \n",
       "3            anbieten  An drei Standorten in Heilbronn, Künzelsau und...   \n",
       "4            anbieten  An drei Standorten in Heilbronn, Künzelsau und...   \n",
       "5            anbieten  An drei Standorten in Heilbronn, Künzelsau und...   \n",
       "6            anbieten  An drei Standorten in Heilbronn, Künzelsau und...   \n",
       "0             pflegen  Die Hochschule pflegt enge Kooperationen mit U...   \n",
       "1             pflegen  Die Hochschule pflegt enge Kooperationen mit U...   \n",
       "2             pflegen  Die Hochschule pflegt enge Kooperationen mit U...   \n",
       "\n",
       "                Subject_Type                                        Subjects  \\\n",
       "0                        PER                                         Talente   \n",
       "1                        PER                                         Talente   \n",
       "2                        PER                                         Talente   \n",
       "0                                                              Radarsensorik   \n",
       "0                                                              das Orchester   \n",
       "0                        ORG                        der Hochschule Heilbronn   \n",
       "0                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "1                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "2                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "3                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "4                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "5                        ORG                                       MikroSens   \n",
       "6                        ORG                                       MikroSens   \n",
       "7                        ORG                                       MikroSens   \n",
       "8                        ORG                                       MikroSens   \n",
       "9                        ORG                                       MikroSens   \n",
       "15                       ORG                        industrielle Anwendungen   \n",
       "16                       ORG                        industrielle Anwendungen   \n",
       "17                       ORG                        industrielle Anwendungen   \n",
       "18                       ORG                        industrielle Anwendungen   \n",
       "19                       ORG                        industrielle Anwendungen   \n",
       "0                                                   diesem Forschungsprojekt   \n",
       "1   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "2   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "3   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "4   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "5   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "6   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "7   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "8   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "..                       ...                                             ...   \n",
       "13                                                             ein Absolvent   \n",
       "14                                                             ein Absolvent   \n",
       "15                                                             ein Absolvent   \n",
       "16                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "17                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "18                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "19                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "20                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "21                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "22                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "23                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "24                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "25                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "26                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "27                                des Studiengangs Wirtschaftsingenieurwesen   \n",
       "0                                                               Das Publikum   \n",
       "0                                                  Ihr Kompetenz-Schwerpunkt   \n",
       "1                                                  Ihr Kompetenz-Schwerpunkt   \n",
       "2                                                  Ihr Kompetenz-Schwerpunkt   \n",
       "3                                                  Ihr Kompetenz-Schwerpunkt   \n",
       "0                                                             die Hochschule   \n",
       "1                                                             die Hochschule   \n",
       "2                                                             die Hochschule   \n",
       "3                                                             die Hochschule   \n",
       "4                                                             die Hochschule   \n",
       "5                                                             die Hochschule   \n",
       "6                                                             die Hochschule   \n",
       "0                                                             Die Hochschule   \n",
       "1                                                             Die Hochschule   \n",
       "2                                                             Die Hochschule   \n",
       "\n",
       "                 Subjects_raw  \\\n",
       "0                     Talente   \n",
       "1                     Talente   \n",
       "2                     Talente   \n",
       "0               Radarsensorik   \n",
       "0                   Orchester   \n",
       "0                  Hochschule   \n",
       "0   Millimeterwellen-Sensorik   \n",
       "1   Millimeterwellen-Sensorik   \n",
       "2   Millimeterwellen-Sensorik   \n",
       "3   Millimeterwellen-Sensorik   \n",
       "4   Millimeterwellen-Sensorik   \n",
       "5                   MikroSens   \n",
       "6                   MikroSens   \n",
       "7                   MikroSens   \n",
       "8                   MikroSens   \n",
       "9                   MikroSens   \n",
       "15                Anwendungen   \n",
       "16                Anwendungen   \n",
       "17                Anwendungen   \n",
       "18                Anwendungen   \n",
       "19                Anwendungen   \n",
       "0           Forschungsprojekt   \n",
       "1           Forschungsprojekt   \n",
       "2           Forschungsprojekt   \n",
       "3           Forschungsprojekt   \n",
       "4           Forschungsprojekt   \n",
       "5           Forschungsprojekt   \n",
       "6           Forschungsprojekt   \n",
       "7           Forschungsprojekt   \n",
       "8           Forschungsprojekt   \n",
       "..                        ...   \n",
       "13                  Absolvent   \n",
       "14                  Absolvent   \n",
       "15                  Absolvent   \n",
       "16               Studiengangs   \n",
       "17               Studiengangs   \n",
       "18               Studiengangs   \n",
       "19               Studiengangs   \n",
       "20               Studiengangs   \n",
       "21               Studiengangs   \n",
       "22  Wirtschaftsingenieurwesen   \n",
       "23  Wirtschaftsingenieurwesen   \n",
       "24  Wirtschaftsingenieurwesen   \n",
       "25  Wirtschaftsingenieurwesen   \n",
       "26  Wirtschaftsingenieurwesen   \n",
       "27  Wirtschaftsingenieurwesen   \n",
       "0                    Publikum   \n",
       "0       Kompetenz-Schwerpunkt   \n",
       "1       Kompetenz-Schwerpunkt   \n",
       "2       Kompetenz-Schwerpunkt   \n",
       "3       Kompetenz-Schwerpunkt   \n",
       "0                  Hochschule   \n",
       "1                  Hochschule   \n",
       "2                  Hochschule   \n",
       "3                  Hochschule   \n",
       "4                  Hochschule   \n",
       "5                  Hochschule   \n",
       "6                  Hochschule   \n",
       "0                  Hochschule   \n",
       "1                  Hochschule   \n",
       "2                  Hochschule   \n",
       "\n",
       "                                                Title  \\\n",
       "0               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "1               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "2               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "0               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "0               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "0               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "0               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "1               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "2               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "3               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "4               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "5               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "6               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "7               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "8               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "9               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "15              MR-Aktivitäten - Hochschule Heilbronn   \n",
       "16              MR-Aktivitäten - Hochschule Heilbronn   \n",
       "17              MR-Aktivitäten - Hochschule Heilbronn   \n",
       "18              MR-Aktivitäten - Hochschule Heilbronn   \n",
       "19              MR-Aktivitäten - Hochschule Heilbronn   \n",
       "0               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "1               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "2               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "3               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "4               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "5               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "6               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "7               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "8               MR-Aktivitäten - Hochschule Heilbronn   \n",
       "..                                                ...   \n",
       "13  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "14  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "15  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "16  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "17  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "18  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "19  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "20  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "21  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "22  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "23  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "24  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "25  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "26  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "27  Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "0   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "0   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "1   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "2   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "3   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "0   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "1   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "2   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "3   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "4   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "5   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "6   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "0   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "1   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "2   Komplexe Entscheidungen mit gesundem Menschenv...   \n",
       "\n",
       "                    Upload-Date                 index  score  \n",
       "0   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "1   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "2   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "0   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "0   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "0   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "0   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "1   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "2   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "3   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "4   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "5   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "6   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "7   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "8   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "9   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "15  2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "16  2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "17  2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "18  2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "19  2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "0   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "1   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "2   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "3   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "4   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "5   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "6   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "7   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "8   2020-06-18T00:42:06.083993Z  mid_beispieldaten_v9    1.0  \n",
       "..                          ...                   ...    ...  \n",
       "13  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "14  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "15  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "16  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "17  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "18  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "19  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "20  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "21  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "22  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "23  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "24  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "25  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "26  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "27  2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "0   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "0   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "1   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "2   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "3   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "0   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "1   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "2   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "3   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "4   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "5   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "6   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "0   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "1   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "2   2020-06-18T00:42:37.507850Z  mid_beispieldaten_v9    1.0  \n",
       "\n",
       "[806 rows x 20 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Methoden aus der VictoryNLP-Klasse werden hier auch in Einzelblöcke zur Verfügung gestellt, damit die Auswertung von denen einfacher ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def is_question(sent):\n",
    "        '''\n",
    "        Prüft, ob der analisyste Satz eine Frage ist.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        sent --> Satz, der analysiert wird\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        Boolean, ob \"?\" in dem Satz zu finden ist\n",
    "        '''\n",
    "        return '?' in sent.text # Prüft, ob \"?\" in dem Satz zu finden ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " def is_question_words_without_obj(token):\n",
    "        '''\n",
    "        Prüft ob der Token ein W-Fragewort ist, bei dem das Objekt oder Subjekt direkt die W-Fragewort ist.\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Inputs ###\n",
    "        token --> Wort, das analysiert wird\n",
    "        ____________________________________________________________________________________________________\n",
    "        ### Outputs ###\n",
    "        Boolean --> ob, das Wort in W-Fragewort ist, bei dem das Objekt oder Subjekt direkt die W-Fragewort ist.\n",
    "    \n",
    "        '''\n",
    "        question_words_without_obj = ['was', 'wo', 'wer', 'wen', 'wem', 'wohin', 'woher'] # W-Fragewörter, , bei denen das Objekt oder Subjekt direkt die W-Fragewort ist\n",
    "        return token.text.lower() in question_words_without_obj # Return Boolean, ob der Token ein von den W-Fragewörtern ist.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_elements(objs):\n",
    "    '''\n",
    "    Bei dieser Methode werden vielfältige Objekte oder Subjekte gesucht. Nicht immer sind die Objekte oder Subjekte direkt\n",
    "    zu erkennen. Manchmal besteht das Objekt oder das Subjekt aus mehrere Wörter, die nicht sofort von Spacy erkennbar sind.\n",
    "    Aus diesem Grund, liest die Methode den Satzt wieder durch und verknüpft die vielfältigen Objekte und Subjekte.\n",
    "    Da das Verfahren gleich für Subjekte und Objekte ist, wird in den Komentare nur über Objekte gesprochen.\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    objs --> Liste mit den erkannten Objekten\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    objs --> Bearbeitete Liste von den vielfältigen Objekten\n",
    "\n",
    "    '''\n",
    "    # Typen von Wörtern, die nicht als Objekte erwünscht sind\n",
    "    unwanted_tokens = (\n",
    "    'AUX', # auxiliar verb\n",
    "    'ADJ', # adjective\n",
    "    'ADV', # adverb\n",
    "    'VERB', # verb\n",
    "    'PART',  # particle\n",
    "    'DET',  # determiner\n",
    "    'SCONJ',  # subordinating conjunction\n",
    "    'PUNCT',  # punctuation\n",
    "    'SYM',  # symbol\n",
    "    'X',  # other\n",
    "    )\n",
    "\n",
    "    # Diese Typen werden nachher gefiltert, weil viele Verknüpfungen zwischen Objekten über diese Typen zu erkennen sind,\n",
    "    # jedoch werden diese Typen am Ende als Objekte nicht erwünscht, daher werden sie gefiltert.\n",
    "    obj_filter = (\n",
    "    'CONJ', # conjunction\n",
    "    'ADP', # adposition\n",
    "    )\n",
    "\n",
    "    # Schleife über die Objekte\n",
    "    for obj in objs:\n",
    "        # Schleife über die Kinder des Objkets\n",
    "        for child in obj.children:\n",
    "            # Voraussetzungen:\n",
    "            # --> Wenn das POS des Kinds nicht in des Tuples \"unwanted_tokens\" sich befindet\n",
    "            # --> Und wenn das Kind kein Interpunktionszeichen ist\n",
    "            # --> Und wenn das Kind noch nicht in der Objektliste ist\n",
    "            if child.pos_ not in unwanted_tokens and child.is_punct==False and child not in objs:\n",
    "                # Fügt das Kind zu der Objektliste ein\n",
    "                objs.append(child)\n",
    "\n",
    "    # Filtert die Subjekte und Objekte auf basis des Tuples \"obj_filter\" \n",
    "    objs = [obj for obj in objs if obj.pos_ not in obj_filter]\n",
    "\n",
    "    # Rückgabe der vielfältigen Objekte\n",
    "    return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_pronoun(token):\n",
    "    '''\n",
    "    Für einen guten Lesefluss werden oft Pronomen angewendet. Durch die Anwendung von Pronomen im Text wird\n",
    "    verzichtet, mehrmals die Subjekte oder Objekte zu wiederholen, ohne dass Informationen verloren geht.\n",
    "    Die Beziehung zwischen Pronomen und den Wörtern auf denen die Pronomen sich beziehen werden nicht von \n",
    "    Spacy erkannt und, um diese Informationen nicht zu verlieren und um herauszufinden woraus das Pronomem\n",
    "    sich bezieht wurde diese Methode geschrieben        \n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    token --> Wort aus dem Satz, der analysiert wird\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    Wenn das Wort, auf dem das Pronomen sich bezieht, erkannt wird:\n",
    "    obj  --> Wenn das Pronomen in einem Relativsatz sich befindet und das Wort, auf dem das Pronomen sich \n",
    "             bezieht, in einem Hauptsatz zu finden ist.\n",
    "    subj --> Wenn das Pronomen in einer Konjunktivsatz ist, wird das Subjekt des Hauptsatzes gewählt, um \n",
    "             das Pronomen zu ersetzen\n",
    "    '''\n",
    "    case=1\n",
    "\n",
    "    # Wenn die Abhängigkeit der Wurzel des Wortes ein Relativsatz ist und das Wort ein Pronomen ist\n",
    "    if token.head.dep_ == 'rc' and token.pos_ == 'PRON':\n",
    "        # Wird versucht die Wurzel der Wurzel zu speichern (zweite Wurzel)\n",
    "        try:\n",
    "            obj = token.head.head\n",
    "            # Wenn es klappt wird das Pronomen von seiner zweiten Wurzel ersetzt\n",
    "            # Rückgabe von case 1 (Aktivform)\n",
    "            return obj, case\n",
    "        except:\n",
    "            None\n",
    "\n",
    "    # Wenn die Abhängigkeit der Wurzel des Wortes eine Konjunktion ist und das Wort ein Pronomen ist aber davor befindet sich eine Konjunktion  \n",
    "    elif token.head.head.head.dep_ == 'cd' and token.pos_ == 'PRON':\n",
    "\n",
    "        # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen, wenn der Satz in der Aktivform steht\n",
    "        try:\n",
    "            # Holt das Subjekt des anderen Satzs\n",
    "            subj = [subj for subj in token.head.head.head.head.children if subj.dep_=='sb'][0] \n",
    "            # Prüft, ob das Hauptsatz in der Passivform steht\n",
    "            if subj.head.lemma_ == 'werden':\n",
    "                # Findet das Hauptverb\n",
    "                oc_verb = [oc for oc in subj.head.children if oc.dep_=='oc'][0]\n",
    "                case = 2\n",
    "                # Sucht nach den Objekten\n",
    "                for i in range(3):\n",
    "                    try:\n",
    "                        # Sucht nach einem Objekt Akkusativ\n",
    "                        obj = [obj for obj in oc_verb.children if obj.dep_=='oa'][0]\n",
    "                        return obj, case\n",
    "                    except:\n",
    "                        # Sucht nach einem Subjekt in der Passivform\n",
    "                        try:\n",
    "                            obj = [obj for obj in oc_verb.children if obj.dep_=='sbp'][0]\n",
    "                            obj = [obj for obj in obj.children if obj.dep_=='nk'][0]\n",
    "                            return obj, case\n",
    "                        except:\n",
    "                            # Sucht nach einem Predikat\n",
    "                            try:\n",
    "                                obj = [obj for obj in oc_verb.children if obj.dep_=='pd'][0]\n",
    "                                return obj, case\n",
    "                            except:\n",
    "                                # Prüft, ob die Ebene des Hauptverbs noch nicht erreicht wurde\n",
    "                                try:\n",
    "                                    oc_verb = [oc for oc in oc_verb.children if obj.dep_=='oc'][0]\n",
    "                                except:\n",
    "                                    None\n",
    "\n",
    "            # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen        \n",
    "            else:\n",
    "                # Rückgabe von case 1 (Aktivform)\n",
    "                return subj, case\n",
    "        except:\n",
    "            None\n",
    "\n",
    "    # Wenn die Abhängigkeit der Wurzel des Wortes eine Konjunktion ist und das Wort ein Pronomen ist aber davor befindet sich eine Konjunktion  \n",
    "    elif token.head.head.dep_ == 'cd' and token.pos_ == 'PRON':\n",
    "\n",
    "        # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen, wenn der Satz in der Aktivform steht\n",
    "        try:\n",
    "            # Holt das Subjekt des anderen Satzs\n",
    "            subj = [subj for subj in token.head.head.head.children if subj.dep_=='sb'][0] \n",
    "            # Prüft, ob das Hauptsatz in der Passivform steht\n",
    "            if subj.head.lemma_ == 'werden':\n",
    "                # Findet das Hauptverb\n",
    "                oc_verb = [oc for oc in subj.head.children if oc.dep_=='oc'][0]\n",
    "                case = 2\n",
    "                # Sucht nach den Objekten\n",
    "                for i in range(3):\n",
    "                    # Sucht nach einem Objekt Akkusativ\n",
    "                    try:\n",
    "                        obj = [obj for obj in oc_verb.children if obj.dep_=='oa'][0]\n",
    "                        return obj, case\n",
    "                    except:\n",
    "                        # Sucht nach einem Subjekt in der Passivform\n",
    "                        try:\n",
    "                            obj = [obj for obj in oc_verb.children if obj.dep_=='sbp'][0]\n",
    "                            obj = [obj for obj in obj.children if obj.dep_=='nk'][0]\n",
    "                            return obj, case\n",
    "                        except:\n",
    "                            # Sucht nach einem Predikat\n",
    "                            try:\n",
    "                                obj = [obj for obj in oc_verb.children if obj.dep_=='pd'][0]\n",
    "                                return obj, case\n",
    "                            except:\n",
    "                                # Prüft, ob die Ebene des Hauptverbs noch nicht erreicht wurde\n",
    "                                try:\n",
    "                                    oc_verb = [oc for oc in oc_verb.children if obj.dep_=='oc'][0]\n",
    "                                except:\n",
    "                                    None\n",
    "\n",
    "            # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen        \n",
    "            else:\n",
    "                # Rückgabe von case 1 (Aktivform)\n",
    "                return subj, case\n",
    "        except:\n",
    "            None\n",
    "\n",
    "    # Wenn die Abhängigkeit der Wurzel des Wortes eine Konjunktion ist und das Wort ein Pronomen ist\n",
    "    elif token.head.dep_ == 'cj' and token.pos_ == 'PRON':\n",
    "\n",
    "        # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen, wenn der Satz in der Aktivform steht\n",
    "        try:\n",
    "            # Holt das Subjekt des anderen Satzs\n",
    "            subj = [subj for subj in token.head.head.children if subj.dep_=='sb'][0] \n",
    "            # Prüft, ob das Hauptsatz in der Passivform steht\n",
    "            if subj.head.lemma_ == 'werden':\n",
    "                # Findet das Hauptverb\n",
    "                oc_verb = [oc for oc in subj.head.children if oc.dep_=='oc'][0]\n",
    "                case = 2\n",
    "                # Sucht nach den Objekten\n",
    "                for i in range(3):\n",
    "                    # Sucht nach einem Objekt Akkusativ\n",
    "                    try:\n",
    "                        obj = [obj for obj in oc_verb.children if obj.dep_=='oa'][0]\n",
    "                        return obj, case\n",
    "                    except:\n",
    "                        # Sucht nach einem Subjekt in der Passivform\n",
    "                        try:\n",
    "                            obj = [obj for obj in oc_verb.children if obj.dep_=='sbp'][0]\n",
    "                            obj = [obj for obj in obj.children if obj.dep_=='nk'][0]\n",
    "                            return obj, case\n",
    "                        except:\n",
    "                            # Sucht nach einem Predikat\n",
    "                            try:\n",
    "                                obj = [obj for obj in oc_verb.children if obj.dep_=='pd'][0]\n",
    "                                return obj, case\n",
    "                            except:\n",
    "                                # Prüft, ob die Ebene des Hauptverbs noch nicht erreicht wurde\n",
    "                                try:\n",
    "                                    oc_verb = [oc for oc in oc_verb.children if obj.dep_=='oc'][0]\n",
    "                                except:\n",
    "                                    None\n",
    "            # Wird versucht das Subjekt des früheren Satzes gewählt, um das Pronomen zu ersetzen        \n",
    "            else:\n",
    "                # Rückgabe von case 1 (Aktivform)\n",
    "                return subj, case\n",
    "        except:\n",
    "            None\n",
    "    else:\n",
    "        # Wenn die beiden Fälle nicht zugetroffen werden, bleibt das Pronomen\n",
    "        return token, case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(subjs, sent):\n",
    "    '''\n",
    "    Die Methode \"get_chunks\" findet in dem Satz, wo das Subjekt sich befindet, für jedes vorher gefundenen\n",
    "    Objekt sein entsprechendes sogenanntes \"Noun Chunk\". Das ist die Kombination von Wörter die, das Objekt \n",
    "    oder Subjekt beschreiben. Nehmen wir zum Beispiel der Satz \"Peter will heute das schnelle rote Auto \n",
    "    fahren.\". In diesem Fall ist das Substantiv \"Auto\" das Objekt und \"das schnelle rote Auto\" das \n",
    "    entsprechende \"Noun Chunk\".\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    subjs --> Liste mit den vorher erkannten Subjekte oder Objekte\n",
    "    sent  --> Satz, der analysiert wird\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    chunks --> Liste mit den entsprechenden Noun Chunks auf Basis des Inputs \"subjs\"\n",
    "    '''\n",
    "    # Nutzt die Spacy-Generator \".noun_chunks\", um alle gefundenen Noun Chunks in dem Satz in einer Liste zu speichern.\n",
    "    chunks_raw = [chunk for chunk in sent.noun_chunks]\n",
    "\n",
    "    # Leere Liste, in der die gefundenen Noun Chunks \n",
    "    chunks = []\n",
    "\n",
    "    # Schleife über die Subjekte\n",
    "    for subj in subjs:\n",
    "        # Schleife über alle Noun Chunks von dem Satz\n",
    "        for chunk in chunks_raw:\n",
    "            # Wenn das Subjekt in dem entsprechenden Chunk sich befindet, wird es zu der Outputliste hinzugefügt.\n",
    "            if subj in chunk:\n",
    "                chunks.append(chunk)\n",
    "\n",
    "    # Stellt sicher, dass die Output-Noun-Chunks einzigartig sind\n",
    "    chunks = list(set(chunks))\n",
    "\n",
    "    # Rückgabe der Noun Chunks\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root(element):\n",
    "    '''\n",
    "    Bei jedem Satz wird eine Wurzel definiert. Als Wurzel eines Satzes werden Verben oder Hilfsverben angenommen.\n",
    "    Diese Wurzel sind die Basis für die Relationen zwischen Subjekte und Objekte. Diese Methode findet die Wurzeln\n",
    "    des Satzes heraus.\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    element --> Token, das analysiert wird. Aus dem Token wird die Wurzel gefunden.\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    root --> Gefundene Wurzel von dem Satz auf Basis von dem Input \"element\"\n",
    "    '''\n",
    "    # Erlaubte Parts-Of-Speach von den Wurzeln\n",
    "    root_pos = (\n",
    "    'VERB', # Verben\n",
    "    'AUX')  # Hilfsverben\n",
    "\n",
    "    # Anwendung der Spacy-Methode \".head\" um die Wurzel eines Worts zu finden\n",
    "    root = element.head\n",
    "\n",
    "    # Schleife, die von Wort zu Wort geht, um die Wurzel in Form von Verben oder Hilfsverben zu finden.\n",
    "    while root.pos_ not in root_pos and root != root.head:\n",
    "        root = root.head\n",
    "\n",
    "    # Rückgabe der Wurzel\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modal_verb(sent, roots):\n",
    "    '''\n",
    "    Modalverben, wie können, wollen, sollen, möchten, werden von Spacy als eine separte Kategorie erkannt.\n",
    "    Die Modalverben ergeben nur Sinn, wenn sie Zusammen mit den Hauptverben als Relation erkannt werden. Aus\n",
    "    Diesem Grund wird durch diese Methode das Modalverb erkannt und zu der Roots-Liste (Wurzeln) hinzugefügt.\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    sent  --> Satz, der analysiert wird\n",
    "    roots --> Roots-Liste oder erkannte Wurzeln des Satzes\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    roots --> Roots-Liste mit der Ergänzung von den Modalverben\n",
    "    '''\n",
    "    # Schleife über die Wörter des Satzes\n",
    "    for oc in sent:\n",
    "        # Wenn das Wort ein Modalverb ist, wird es zu der Roots-Liste hinzugefügt\n",
    "        if oc.dep_=='oc':\n",
    "            roots.append(oc)   \n",
    "    # Rückgabe der ergänzten Wurzeln         \n",
    "    return roots   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clause(token):\n",
    "    '''\n",
    "    Bei einem Nebensatz, kommt es of vor, dass das Objekt des Hauptssatzes das Subjekt des Nebensatzes ist.\n",
    "    Diese Methode erkennt diese Fällen und, wenn vorhanden, gibt den Nebensatz zurück. In anderen Wörter\n",
    "    prüft, ob das Objekt das Subjekt eines Nebensatzes ist.\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    token  --> Token, das geprüft wird, ob ein Nebensatz zu ihm verbunden ist\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    check_clause --> Kind des geprüften Tokens, zu dem ein Nebensatz verbunden ist\n",
    "    '''\n",
    "    # \"Parts-Of-Speach\", die erwünscht sind, um den Nebensatz zu charakterisieren\n",
    "    clause_link = ('VERB', 'AUX') # Verben oder Hilfsverben\n",
    "\n",
    "    # Aus der Spacy-Generator werden die Kinder vom Token gesammelt, die als \"Part-Of-Speach Verben oder Hilfsverben enthalten\"\n",
    "    check_clause = [child for child in token.children if child.pos_ in clause_link]\n",
    "    # Falls die Liste \"check_clause\" größer als null ist wird diese Liste zurückgegeben\n",
    "    if len(check_clause)>0:\n",
    "        # Rückgabe der Liste \"check_clause\"\n",
    "        return check_clause\n",
    "    else:\n",
    "        # Rückgabe einer leeren Liste\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_passive(case, relation, obj, subj, obj_chunk, subj_chunk, obj_type, subj_type):\n",
    "    '''\n",
    "    Diese Methode wandelt die Sätze in der passiven Form in die aktive Form um. Falls der Satz in der passiven \n",
    "    Form ist, wird das Subjekt von dem Objekt ersetzt und umgekehrt, sodass das Ergebnis immer einheitlich in \n",
    "    dem aktiven Form steht. Die Inputs und Outputs sind gleich und nur die Relation wird in dieser Methode transformiert\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    relation --> Relationen, die sie Subjekte und die Objekte verbinden\n",
    "    obj --> Erkannte Objekte\n",
    "    subj --> Erkannte Subjekte\n",
    "    obj_chunk --> Erkannte Noun Chunks aus den Objekten\n",
    "    subj_chunk --> Erkannte Noun Chunks aus den Subjekten\n",
    "    obj_type --> Objekttyp aus den Objekten, ergeben von der Spacy-Methode \".ent_type_\"\n",
    "    subj_type --> Subjekttyp aus den Subjekten, ergeben von der Spacy-Methode \".ent_type_\"\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    relation --> Relationen, die sie Subjekte und die Objekte verbinden\n",
    "    obj --> Erkannte Objekte\n",
    "    subj --> Erkannte Subjekte\n",
    "    obj_chunk --> Erkannte Noun Chunks aus den Objekten\n",
    "    subj_chunk --> Erkannte Noun Chunks aus den Subjekten\n",
    "    obj_type --> Objekttyp aus den Objekten, ergeben von der Spacy-Methode \".ent_type_\"\n",
    "    subj_type --> Subjekttyp aus den Subjekten, ergeben von der Spacy-Methode \".ent_type_\"\n",
    "\n",
    "    '''\n",
    "    # Wandelt den String zu einem Spacy-Doc um\n",
    "    doc = nlp(relation)\n",
    "    # Leere Liste, für die Stammform des Verbs\n",
    "    lemma_form = []\n",
    "    # Variable zu bestätigen, ob der Satz ist Passiv, oder nicht\n",
    "    counter = 0\n",
    "\n",
    "    # Schleife über die Tokens des transformierten Relation\n",
    "    for token in doc:\n",
    "        # Falls die Passivform nicht erkannt wird\n",
    "        if token.lemma_ != 'werden':\n",
    "            # Das Verb wird in der Stammform gespeichert\n",
    "            lemma_form.append(token.lemma_)\n",
    "        # Charakterisierung der Passivform: Wenn das Hilfsverb werden angewendet wird\n",
    "        else: # token.lemma_ == 'werden':\n",
    "            # Counter zählt hoch\n",
    "            counter += 1\n",
    "\n",
    "    # Alle Relations werden zu einem String umgewandelt\n",
    "    relation = ' '.join(map(str, lemma_form))\n",
    "\n",
    "    # Wenn die Passivworm erkannt wurde\n",
    "    if counter >0 and case == 1:\n",
    "        # Rückgabe der Relationen Objekte und Subjekte in der umgekehrten Reinfolge \n",
    "        return relation, subj, obj, subj_chunk, obj_chunk, subj_type, obj_type\n",
    "    # Wenn die Passivform nicht erkannt wurde\n",
    "    else:\n",
    "        # Rückgabe der Relationen Objekte und Subjekte in der direkten Reinfolge \n",
    "        return relation, obj, subj, obj_chunk, subj_chunk, obj_type, subj_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations(roots):\n",
    "    '''\n",
    "    Diese Methode ist dafür verantwörtlich, die Beziehungen bzw. Relationen zwischen Objekte und Subjekte\n",
    "    herauszufinden. Bei dieser Funktion Spielen viele sprachlische Eigenschaften der deutschen Sprache eine\n",
    "    Rolle. Herausforderungen sind bspw. die Modalverben und Hauptverben zu verbinden, oder die Relationen aus\n",
    "    Nebensätzen und mit den Hauptsätzen zu verknüpfen. \n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    roots --> Die Wurzeln die in dem Satz erkannt wurden\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    relation_full --> Die Relationen mit den zusätzlichen Informationen, wie die verbalen Konjunktionen\n",
    "    '''\n",
    "    # Leere Liste für die Relationen\n",
    "    relations=[]\n",
    "    # Leere liste für die Konjunktionen\n",
    "    conj_verb = []\n",
    "\n",
    "    # Schleife über die Wurzeln, um die verbalen Konjunktionen herauszufinden\n",
    "    for root in roots:\n",
    "        # Placeholder für die erstellung der Relationen\n",
    "        pm = ''\n",
    "        ng = ''\n",
    "        svp = ''\n",
    "        head1 = ''\n",
    "        head2 = ''\n",
    "        head3 = ''\n",
    "        # Schleife über die Kinder der gefundenen Wurzel\n",
    "        for child in root.children:\n",
    "\n",
    "            # Prüfen, ob ein morphologisches Partikel vorhanden ist\n",
    "            if child.dep_ == 'pm':\n",
    "                pm = child.text + ' '\n",
    "\n",
    "            # Prüfen, ob ein negatives Element vorhanden ist\n",
    "            if child.dep_ == 'ng':\n",
    "                ng = child.text + ' '\n",
    "\n",
    "        # Prüfen, ob die Relationen vielfältige verbale Konjunktionen enthalten\n",
    "        # Erste Ebene: Für die Relationen, die aus zwei Verben oder Hilfsverben besteht\n",
    "        if (root.head.pos_=='VERB' or root.head.pos_=='AUX') and \\\n",
    "        root.head!=root and root.dep_!='cj':\n",
    "            head1 = root.head.text + ' '\n",
    "\n",
    "            # Zweite Ebene: Für die Relationen, die aus drei Verben oder Hilfsverben besteht\n",
    "            if (root.head.head.pos_=='VERB' or root.head.head.pos_=='AUX') and \\\n",
    "            root.head.head!=root.head and root.head.dep_!='cj':\n",
    "                head2 = root.head.head.text + ' '\n",
    "\n",
    "                # Zweite Ebene: Für die Relationen, die aus vier Verben oder Hilfsverben besteht\n",
    "                if (root.head.head.head.pos_=='VERB' or root.head.head.head.pos_=='AUX') and \\\n",
    "                root.head.head.head!=root.head.head and root.head.head.dep_!='cj':\n",
    "                    head3 = root.head.head.head.text + ' '\n",
    "\n",
    "            # Zusammenfügung von allen verbalen Konjunktionen als ein einziges Text\n",
    "            conj_verb.append(\"{}{}{}{}{}{}\".format(head1, head3, head2, ng, pm, root.text ))\n",
    "\n",
    "    # Schleife über die gefundenen Wurzeln für die Erstellung der Relationen\n",
    "    for root in roots:\n",
    "\n",
    "        # Prüfen, ob die Wurzeln bei den verbalen Konjunktionen bereits gespeichert wurden\n",
    "        test = [root.text in element for element in conj_verb]\n",
    "\n",
    "        # Die Relationen herausfinden und in eine Liste speichern\n",
    "        if sum(test) == 0 and (root.pos_=='VERB' or (root.pos_=='AUX' and root.lemma_=='haben')):\n",
    "            # Placeholder für die Nachbereitung der Relationen\n",
    "            pm = ''\n",
    "            ng = ''\n",
    "            svp = ''\n",
    "\n",
    "            # Schleife über die Kinder der gefundenen Wurzel\n",
    "            for child in root.children:\n",
    "                # Prüfen ob das Kind ein trennbares Verb ist\n",
    "                if child.dep_ == 'svp':\n",
    "                    svp = child.text\n",
    "                # Prüfen ob das Kind ein morphologisches Partikel ist\n",
    "                if child.dep_ == 'pm':\n",
    "                    pm = child.text + ' '\n",
    "                # check if there is a negative element\n",
    "                if child.dep_ == 'ng':\n",
    "                    ng = child.text + ' '\n",
    "\n",
    "            # Zusammenfügung von allen verben als ein einziges Text\n",
    "            relations.append(\"{}{}{}{}\".format(ng, pm, svp, root.text))\n",
    "\n",
    "    # Erstellung einer Liste aus den Relationen mit einzigartigen Relationen\n",
    "    relations = list(set(relations))\n",
    "    # Erstellung einer Liste aus den verbalen Konjunktionen mit einzigartigen Konjunktionen\n",
    "    conj_verb = list(set(conj_verb))\n",
    "\n",
    "    # Erstellung der finalen Relationen aus der Zusammenfügung von den Verben (Relationen) und verbalen Konjunktionen\n",
    "    relations_full = relations + conj_verb\n",
    "\n",
    "    # Rückgabe der vollständigen Relationen\n",
    "    return relations_full       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linking_relations(subjs, objs, roots, sub_chunks, obj_chunks, relations):\n",
    "    '''\n",
    "    Aus der Analyse des Satzes mittels NLP werden die Objekte, Objekt Chunks, Subjekte, Subjekt Chunks und die\n",
    "    Relationen gefunden, extrahiert und zugeordnet. In dieser Methode werden alle diese gefundene Informationen\n",
    "    miteinander verbunden. Die Subjekte werden zu den Relationen verbunden und diese Verbindung zu den jeweiligen\n",
    "    Objekten. Am Ende werden die Subjekte, Objekte und Relationen in einem Dataframe eingefügt.\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    subjs --> Gefundene Subjekte\n",
    "    objs --> Gefundente Objekte\n",
    "    roots --> Die Gefundene Wurzeln aus dem Satz\n",
    "    relations --> Die bearbeitete Relationen aus dem Satz\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    df_subjs --> Dataframe mit den wesentlichen Informationen bzgl. der Subjekte (Features: root, subj, subj_chunk, subj_type\n",
    "    df_objs --> Dataframe mit den wesentlichen Informationen bzgl. der Objekten (Features: obj, obj_chunk, obj_type, root)\n",
    "    df_relations --> Dataframe mit den wesentlichen Informationen bzgl. der Relationen (Features: relation, root)\n",
    "    df_info --> Dataframe mit den Verbindungen zwischen Objekte, Subjekte und Relationen, \n",
    "                Ergebnis aus der Analyse jedes Satzes\n",
    "    '''\n",
    "    # Erstellung der 3 Zuordnungstabellen\n",
    "    # 1 - Zuordnungstabelle von den Subjekten\n",
    "    df_subjs = pd.DataFrame(columns = ['subj', 'subj_chunk', 'subj_type', 'root'])\n",
    "\n",
    "    # Ausfüllen der Zuordnungstabelle von den Subjekten\n",
    "    # Schleife über die Subjekte\n",
    "    for subj in subjs:\n",
    "        # Schleife über die Noun Chunks\n",
    "        for chunk in sub_chunks:\n",
    "            # Prüfen ob das Subjekt im Noun Chunk zu finden ist\n",
    "            if subj in chunk:\n",
    "                # Zeile in das Dataframe einfügen\n",
    "                add_row = pd.DataFrame({'subj':subj, 'subj_chunk':chunk.text, 'subj_type':subj.ent_type_, 'root':get_root(subj)}, \n",
    "                                       index=[len(df_subjs)])\n",
    "                # Zusammenfügung von der erstellten Zeile in die Zuordnungstabelle von den Subjekten\n",
    "                df_subjs = pd.concat([df_subjs,add_row])\n",
    "\n",
    "    # 2 - Zuordnungstabelle von den Objekten\n",
    "    df_objs = pd.DataFrame(columns = ['obj', 'obj_chunk', 'obj_type', 'root'])\n",
    "\n",
    "    # Ausfüllen der Zuordnungstabelle von den Objekten\n",
    "    # Schleife über die Objekte\n",
    "    for obj in objs:\n",
    "        # Schleife über die Noun Chunks\n",
    "        for chunk in obj_chunks:\n",
    "            # Prüfen ob das Objekt im Noun Chunk zu finden ist\n",
    "            if obj in chunk:\n",
    "                # Zeile in das Dataframe einfügen\n",
    "                add_row = pd.DataFrame({'obj':obj, 'obj_chunk':chunk.text, 'obj_type':obj.ent_type_, 'root':get_root(obj)}, \n",
    "                                       index=[len(df_objs)])\n",
    "                # Zusammenfügung von der erstellten Zeile in die bestehende Zuordnungstabelle von den Objekten\n",
    "                df_objs = pd.concat([df_objs,add_row])\n",
    "\n",
    "    # 3 - Zuordnungstabelle von den Relationen\n",
    "    df_relations = pd.DataFrame(columns = ['root', 'relation'])\n",
    "\n",
    "    # Ausfüllen der Zuordnungstabelle von den Relationen\n",
    "\n",
    "    # Schleife über die Wurzeln\n",
    "    for root in roots:\n",
    "\n",
    "        # Schleife über die Relationen\n",
    "        for relation in relations:\n",
    "\n",
    "            # Prüfen ob die Wurzel in der Relation zu finden ist\n",
    "            if root.text in relation:\n",
    "                # Zeile in das Dataframe einfügen\n",
    "                add_row = pd.DataFrame({'root':root, 'relation':relation}, index=[len(df_relations)])\n",
    "\n",
    "                # Zusammenfügung von der erstellten Zeile in die bestehende Zuordnungstabelle von den Relationen\n",
    "                df_relations = pd.concat([df_relations,add_row])\n",
    "\n",
    "    # Speichern von Entitäten (Subjekte und Objekte) und Beziehungen in einem DataFrame \n",
    "    df_info = pd.DataFrame(columns=['Subjects', 'Subjects_raw', 'Subject_Type', 'Relations', 'Objects_raw', 'Objects', 'Object_Type'], )\n",
    "\n",
    "    # Schleife über die Subjekte\n",
    "    for i in range(len(df_subjs)):\n",
    "        # Fehlertoleranter Ansatz, um Abbrüche aufgrund außergewöhnlicher Textstrukturen zu vermeiden\n",
    "        try:\n",
    "            # Auswahl des zu analysierenden Subjektes\n",
    "            subj = df_subjs['subj'].iloc[i]\n",
    "\n",
    "            # Auf Basis des Objektes wird die Clause_Relation geholt um die Wurzel des Subjekts zu entdecken\n",
    "            clause_relation = get_clause(subj)\n",
    "            # Falls mehrere Wurzeln in dem Satz zu finden sind\n",
    "            if len(clause_relation)>0:\n",
    "                # erhält den Satz-Wurzel (nur eine Satzrelation pro Subjekt ist erlaubt)\n",
    "                root1 = clause_relation[0]\n",
    "            # Falls nur eine Wurzel zu finden ist\n",
    "            else:\n",
    "                # Wurzel wird geholt\n",
    "                root1 = df_subjs['root'].iloc[i]\n",
    "            # findet die Relation basierend auf der Wurzel\n",
    "            relation1 = df_relations['relation'][df_relations['root'] == root1].values[0]\n",
    "\n",
    "            # Schleife über die Objekte\n",
    "            for j in range(len(df_objs)):\n",
    "                # Wurzel wird geholt\n",
    "                root2 = df_objs['root'].iloc[j]\n",
    "                # findet die Beziehung basierend auf der Wurzel\n",
    "                relation2 = df_relations['relation'][df_relations['root'] == root2].values[0]\n",
    "\n",
    "                # Verbindungsphase zwischen Subjekte und Objekte\n",
    "\n",
    "                # Falls die gefundene Relation aus dem Subjekt und aus dem Objekt gleich sind\n",
    "                if relation1 == relation2:\n",
    "\n",
    "                    # Auswahl des zu analysierenden Objektes\n",
    "                    obj = df_objs['obj'].iloc[j] \n",
    "\n",
    "                    # Objekt ersetzen, wenn es ein Pronomen ist (Relativsatz und Nebensätze)\n",
    "                    obj, case = substitute_pronoun(obj)\n",
    "\n",
    "                    # Auf Basis des Objektes wird das Noun Chunk und Objekt-Typ geholt\n",
    "                    obj_chunk = df_objs['obj_chunk'][df_objs['obj'] == obj].values[0]\n",
    "                    obj_type = df_objs['obj_type'].iloc[j]\n",
    "\n",
    "                    # Subjekt ersetzen, wenn es ein Pronomen ist (Relativsatz und Nebensätze)\n",
    "                    subj, case = substitute_pronoun(subj)\n",
    "\n",
    "                    # Wenn das Pronomen auf einem Satz in der Aktivform sich bezieht\n",
    "                    if case == 1:\n",
    "                        # Auf Basis des Subjektes wird versucht, das Noun Chunk und Objekt-Typ zu holen\n",
    "                        try:\n",
    "                            subj_chunk = df_subjs['subj_chunk'][df_subjs['subj'] == subj].values[0]\n",
    "                            subj_type = df_subjs['subj_type'][df_subjs['subj'] == subj].values[0]\n",
    "                        # Falls die Aktiveform nicht erkannt wird, soll das Noun Chunk und Objekt-Typ auf Basis der Passivform geholt werden\n",
    "                        except:\n",
    "                            case = 2\n",
    "                            subj_chunk = df_objs['obj_chunk'][df_objs['obj'] == subj].values[0]\n",
    "                            subj_type = df_objs['obj_chunk'][df_objs['obj'] == subj].values[0]\n",
    "\n",
    "                    # Wenn das Pronomen aus einem Satz in der Passivform sich bezieht\n",
    "                    else:\n",
    "                        # Auf Basis des Subjektes wird versucht, das Noun Chunk und Objekt-Typ zu holen\n",
    "                        try:\n",
    "                            subj_chunk = df_objs['obj_chunk'][df_objs['obj'] == subj].values[0]\n",
    "                            subj_type = df_objs['obj_chunk'][df_objs['obj'] == subj].values[0]\n",
    "                        # Falls die Passivform nicht erkannt wird, soll das Noun Chunk und Objekt-Typ auf Basis der Aktivform geholt werden\n",
    "                        except:\n",
    "                            case = 1\n",
    "                            subj_chunk = df_subjs['subj_chunk'][df_subjs['subj'] == subj].values[0]\n",
    "                            subj_type = df_subjs['subj_type'][df_subjs['subj'] == subj].values[0]\n",
    "\n",
    "                    # Methode zur Aktivierung der Passivform wird ausgeführt\n",
    "                    relation, obj, subj, obj_chunk, subj_chunk, obj_type, subj_type = activate_passive(case, relation1, obj, subj, obj_chunk, subj_chunk, obj_type, subj_type)\n",
    "\n",
    "                    # Erstellung eines Dictionarys mit den Informationen, die exportiert werden\n",
    "                    d = {'Subjects_raw':subj, \n",
    "                         'Subjects':subj_chunk,\n",
    "                         'Subject_Type':subj_type,\n",
    "                         'Relations':relation,\n",
    "                         'Objects':obj_chunk, \n",
    "                         'Objects_raw':obj,\n",
    "                         'Object_Type':obj_type}\n",
    "\n",
    "                    # achten Sie darauf, Pronomen nicht als Paare zu speichern (Pronomen sind nicht aussagekräftig)\n",
    "                    # Wenn sowohl das Objekt als auch das Subjekt kein Pronomen sind, werden die Informationen in das Dataframe \"df_info\" eingefügt\n",
    "                    if (is_question_words_without_obj(obj) or is_question_words_without_obj(subj)) and \\\n",
    "                        obj != subj and subj_chunk != obj_chunk:\n",
    "                        add_row = pd.DataFrame(d,index=[len(df_info)])\n",
    "                        df_info = pd.concat([df_info,add_row])\n",
    "                    elif obj.pos_ != 'PRON' and subj.pos_ != 'PRON' and obj != subj and subj_chunk != obj_chunk:\n",
    "                        add_row = pd.DataFrame(d,index=[len(df_info)])\n",
    "                        df_info = pd.concat([df_info,add_row])\n",
    "\n",
    "        # Falls die Bearbeitung der Relationen zwischen Subjekte und Objete fehlerhaft sind, wird sie ignoriert und das Programm läuft weiter\n",
    "        except:\n",
    "            None\n",
    "\n",
    "    # Duplikate werden entfernt\n",
    "    df_info.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Rückgabe von den Subjekten, Objekten, Relationen und die Zusammenfügung von ihnen.\n",
    "    return df_subjs, df_objs, df_relations, df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prep(text):\n",
    "    '''\n",
    "    Diese Methode wird für die Textaufbereitung erstellt. Die Form des Textes beeiflusst dierekt die Performance des\n",
    "    Algorithmus. Wenn Sonderzeichen oder mehrere Textumbruche oder Leerzeichen im Text vorkommen, kann das Algorithmus\n",
    "    schlechter bspw. die Sätze erkennen, oder den Zusammenhang der Wörter im Kontext des Satzes. Aufgrund dessen\n",
    "    wird durch diese Methode den Text vor der Bearbeitung bereinigt, um effizient bearbeitet zu werden.\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    text --> Text, der bearbeitet wird\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    text --> Aufbereiteter und bereinigter Text\n",
    "    '''\n",
    "    # Zeilenumbrüche innerhalb des Wortes werden gelöscht\n",
    "    text = re.sub(r'-\\n+', '', text)\n",
    "    # Mehrere Zeilenumbrüche, Tabs  werden zu einem Leerzeichen ersetzt\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub('\\n ','',text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    # removing new line characters\n",
    "    text = re.sub('\\n ','',text)\n",
    "    text = re.sub('\\n',' ',text)\n",
    "    # Ersetzen alle Whitespace-Zeichen zu normalem Leerzeichen\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\t+', ' ', text)\n",
    "    # Entfernen von Unterstrich gefolgt von einem Leerzeichen\n",
    "    text = re.sub(\"— \",'',text)\n",
    "    # Entfernen jeglicher Verweise auf externen Text\n",
    "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    # E-Mailadresse wird zu dem Wort E-Mail ersetzt\n",
    "    text = re.sub(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", 'E-Mail', text)\n",
    "    # Klammen werden duch Komma ersetzt\n",
    "    text = re.sub(r'([()[]{}])', ',', text)\n",
    "    # Leerzeichen werden gelöscht, aber die Interpunktion wird beibehalten\n",
    "    text = re.sub(r\"[^<>{}\\\"/|~@#$%^=&*\\\\]\\\\\\\\()\\\\[¿§«»ω⊙¤°℃℉€¥£¢¡®©0-9_+]\", '', text)\n",
    "\n",
    "    # Rückgabe des bereinigten und aufbereiteten Texts\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_extraction(text,all_info=False):\n",
    "    '''\n",
    "    Diese ist die Hauptmethode der Klasse und über diese Methode werden die andere ausgeführt und gesteuert.\n",
    "    Diese Methode soll extern ausgeführt werden, um das VictoryNLP-Verfahren zu nutzen. \n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Inputs ###\n",
    "    text --> Text, der bearbeitet wird\n",
    "    ____________________________________________________________________________________________________\n",
    "    ### Outputs ###\n",
    "    df_info_full --> Aufbereiteter und bereinigter Text\n",
    "    '''\n",
    "    # Bearbeitung des Textes, um das NLP-Verfahren mit RegEx zu erleichtern\n",
    "    text = text_prep(text)\n",
    "    # Erstellung eines Spacy-Objektes\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Erstellung eines Dataframes für die Subjekte\n",
    "    subjs = pd.DataFrame(columns=['subj', 'root'])\n",
    "\n",
    "    # Erstellung eines Dataframes für die Objekte\n",
    "    objs = pd.DataFrame(columns=['obj', 'root'])\n",
    "\n",
    "    # Erstellung eines Dataframes für die Relationen\n",
    "    relations = pd.DataFrame(columns=['relation', 'root'])\n",
    "\n",
    "    # Erstellung eines leeren Dataframes für die Zusammenfügung der Informationen\n",
    "    df_info_full = pd.DataFrame()\n",
    "\n",
    "    # Aufteilung des Textes in Sätzen in Form einer Liste mit den Sätzen im Textformat\n",
    "    sentences = [sent.string.strip() for sent in doc.sents]\n",
    "\n",
    "    # Schleife über die Sätze\n",
    "    for sent in sentences:\n",
    "\n",
    "        # Weiter Nachbereitung von dem Text, dieses Mal in der Form eines Satzes\n",
    "        sent = text_prep(sent)\n",
    "\n",
    "        # Erstellung eines Spacy-Objektes für das NLP\n",
    "        sent = nlp(sent)\n",
    "\n",
    "        # Erstellung von Placeholders für die Subjekte, Objekte und Wurzeln\n",
    "        subjs = []\n",
    "        objs  = []\n",
    "        roots = []\n",
    "\n",
    "        # Data Exploration für die Bearbeitung von Fragen\n",
    "        # Erstellung von einer Liste mit den Subjekten (Dependency = 'sb')\n",
    "        s = [word for word in sent if word.dep_ == 'sb']\n",
    "        # Erstellung von einer Liste mit den Objekten (Dependency = 'oa' Objekt Akkusativ)\n",
    "        o = [word for word in sent if word.dep_ == 'oa']\n",
    "\n",
    "        # Schleife über die Sätze\n",
    "        for token in sent:\n",
    "            # Findet die Subjekte heraus, wenn die Dependency = 'sb', Nominativ\n",
    "            if token.dep_ == 'sb':\n",
    "                # Fügt den Token in die Subjekt-Liste ein\n",
    "                subjs.append(token)\n",
    "\n",
    "                # Findet die anderen möglichen Subjekte heraus, falls vielfältige Subjekte vorhanden sind\n",
    "                subjs = get_multiple_elements(subjs)\n",
    "\n",
    "                # Speichert die Wurzeln\n",
    "                roots.append(token.head)\n",
    "                # Modalverben werden auch als Wurzel berücksichtigt\n",
    "                roots = get_modal_verb(sent, roots)\n",
    "\n",
    "            # Findet die Objekte heraus. Erlaubte Dependencies:\n",
    "            # 'oa' --> Objekt Akkusativ\n",
    "            # 'da' --> Objekt Dativ\n",
    "            # 'pd' --> Predikat\n",
    "            # 'sbp' --> Subjekt in der Passivform\n",
    "            # 'mo' --> Modifier (z.B.: Präpositionen)\n",
    "            elif token.dep_ == 'oa' or token.dep_ == 'da' or token.dep_ == 'pd' or token.dep_ == 'sbp' or token.dep_ == 'mo':\n",
    "                # Fügt den Token in die Objekt-Liste ein\n",
    "                objs.append(token)\n",
    "\n",
    "                # check clausal phrases\n",
    "                if len(get_clause(token))>0:\n",
    "                    subjs.append(token)\n",
    "\n",
    "                # Findet die anderen möglichen Subjekte heraus, falls vielfältige Objekte vorhanden sind\n",
    "                objs = get_multiple_elements(objs)\n",
    "\n",
    "            # Die Objekte überprüfen, wenn der Satz eine Frage ist\n",
    "            elif is_question(sent) and is_question_words_without_obj(token):\n",
    "                # Wenn die Frage kein Subjekt enthält\n",
    "                if len(s)==0:\n",
    "                    subjs.append(token)\n",
    "                # Wenn die Frage kein Objekt enthält\n",
    "                if len(o)==0:\n",
    "                    objs.append(token)\n",
    "            else:\n",
    "                None            \n",
    "\n",
    "        # Die Noun Chunks werden geholt\n",
    "        sub_chunks = get_chunks(subjs, sent)\n",
    "        obj_chunks = get_chunks(objs, sent)\n",
    "\n",
    "        # Nur die einzigartigen Wurzeln werden beibehalten\n",
    "        roots = list(set(roots))\n",
    "        # Die Relationen werden herausgefunden auf Basis von den Wurzeln\n",
    "        relations = get_relations(roots)\n",
    "\n",
    "        # Verbindung von den Subjekten und Objekten über ihre Relationen\n",
    "        df_subjs, df_objs, df_relations, df_info = linking_relations(subjs, objs, roots, sub_chunks, obj_chunks, relations)\n",
    "        # Der Satz wird in das Dataframe hinzugefügt \n",
    "        df_info['Sentence'] = str(sent)\n",
    "        # Update von dem bestehenden Dataframe, mit den neuen Informationen aus dem gerade analysierten Satz\n",
    "        df_info_full = pd.concat([df_info_full, df_info])\n",
    "\n",
    "    # Duplikate werden gelöscht\n",
    "    df_info_full.drop_duplicates(subset= ['Subjects', 'Subjects_raw', 'Subject_Type', 'Relations', 'Objects_raw', 'Objects', 'Object_Type', 'Sentence'],\n",
    "                    inplace=True)\n",
    "\n",
    "    # Vorbose, damit es bewusst ist, wie viele Paare aus einem Dokument extrahiert wurden\n",
    "    print('Pairs extracted: {}'.format(len(df_info_full)))\n",
    "\n",
    "    # Entwicklungsmodus\n",
    "    if all_info == True:\n",
    "        # Rückgabe von den aus dem Dokument extrahierten Informationen und einzelnen Dataframes: Subjekte, Objekte und Relationen\n",
    "        return df_info_full, df_subjs, df_objs, df_relations\n",
    "    # Produktionsmodus\n",
    "    else:\n",
    "        # Rückgabe von den aus dem Dokument extrahierten Informationen\n",
    "        return df_info_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test vom Algorithmus mit einem Text aus den Echtdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:71: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:165: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:109: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:162: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs extracted: 406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Objects</th>\n",
       "      <th>Objects_raw</th>\n",
       "      <th>Relations</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Subject_Type</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Subjects_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Stipendien</td>\n",
       "      <td>Stipendien</td>\n",
       "      <td>gewinnen</td>\n",
       "      <td>Talente gewinnen Stipendien Studium mit vertie...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Talente</td>\n",
       "      <td>Talente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Studium</td>\n",
       "      <td>Studium</td>\n",
       "      <td>gewinnen</td>\n",
       "      <td>Talente gewinnen Stipendien Studium mit vertie...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Talente</td>\n",
       "      <td>Talente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>vertiefter Praxis</td>\n",
       "      <td>Praxis</td>\n",
       "      <td>gewinnen</td>\n",
       "      <td>Talente gewinnen Stipendien Studium mit vertie...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Talente</td>\n",
       "      <td>Talente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Die Dirigierbewegung</td>\n",
       "      <td>Dirigierbewegung</td>\n",
       "      <td>erfasst</td>\n",
       "      <td>Die Dirigierbewegung wird durch Radarsensorik ...</td>\n",
       "      <td></td>\n",
       "      <td>Radarsensorik</td>\n",
       "      <td>Radarsensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>das Stück</td>\n",
       "      <td>Stück</td>\n",
       "      <td>abbrechen</td>\n",
       "      <td>Weicht das Metrum zu stark von der Vorgabe des...</td>\n",
       "      <td></td>\n",
       "      <td>das Orchester</td>\n",
       "      <td>Orchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Das Projekt</td>\n",
       "      <td>Projekt</td>\n",
       "      <td>präsentieren</td>\n",
       "      <td>Das Projekt wird von der Hochschule Heilbronn ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>der Hochschule Heilbronn</td>\n",
       "      <td>Hochschule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Hochschulen</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Universität</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik</td>\n",
       "      <td>Millimeterwellen-Sensorik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Hochschulen</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LOC</td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Universität</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>MikroSens</td>\n",
       "      <td>MikroSens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Hochschulen</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LOC</td>\n",
       "      <td>den Hochschulen Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>Pforzheim</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Universität</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ORG</td>\n",
       "      <td>der Universität Ulm</td>\n",
       "      <td>Ulm</td>\n",
       "      <td>entstehen</td>\n",
       "      <td>MikroSens Innovative Millimeterwellen-Sensorik...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>industrielle Anwendungen</td>\n",
       "      <td>Anwendungen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>der Radarsensorik</td>\n",
       "      <td>Radarsensorik</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td></td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>eine neuartige Plattform</td>\n",
       "      <td>Plattform</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Applikationsfelder</td>\n",
       "      <td>Applikationsfelder</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Bewegungsanalyse</td>\n",
       "      <td>Bewegungsanalyse</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>fließende Gewässer</td>\n",
       "      <td>Gewässer</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>Bienen</td>\n",
       "      <td>Bienen</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>die Erfassung</td>\n",
       "      <td>Erfassung</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Kochvorgängen</td>\n",
       "      <td>Kochvorgängen</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>Automatisierungstechnik</td>\n",
       "      <td>Automatisierungstechnik</td>\n",
       "      <td>erschließen</td>\n",
       "      <td>In diesem Forschungsprojekt werden der Radarse...</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>diesem Forschungsprojekt</td>\n",
       "      <td>Forschungsprojekt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>dem Gebiet</td>\n",
       "      <td>Gebiet</td>\n",
       "      <td>kommen</td>\n",
       "      <td>Zur Stärkung einer bestehenden langjährigen in...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Prof. Philip H. Gaskell</td>\n",
       "      <td>H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>der Fluiddynamik</td>\n",
       "      <td>Fluiddynamik</td>\n",
       "      <td>kommen</td>\n",
       "      <td>Zur Stärkung einer bestehenden langjährigen in...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Prof. Philip H. Gaskell</td>\n",
       "      <td>H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td>dem nordenglischen Durham</td>\n",
       "      <td>Durham</td>\n",
       "      <td>kommen</td>\n",
       "      <td>Zur Stärkung einer bestehenden langjährigen in...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Prof. Philip H. Gaskell</td>\n",
       "      <td>H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>Gastprofessor</td>\n",
       "      <td>Gastprofessor</td>\n",
       "      <td>kommen</td>\n",
       "      <td>Zur Stärkung einer bestehenden langjährigen in...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Prof. Philip H. Gaskell</td>\n",
       "      <td>H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td></td>\n",
       "      <td>die Hochschule</td>\n",
       "      <td>Hochschule</td>\n",
       "      <td>kommen</td>\n",
       "      <td>Zur Stärkung einer bestehenden langjährigen in...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Prof. Philip H. Gaskell</td>\n",
       "      <td>H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>einen Doktoranden</td>\n",
       "      <td>Doktoranden</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td></td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Herr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Studiengang MR</td>\n",
       "      <td>Studiengang</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td></td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Herr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Studiengang MR</td>\n",
       "      <td>MR</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td></td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Herr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>einen Doktoranden</td>\n",
       "      <td>Doktoranden</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Gaskell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Studiengang MR</td>\n",
       "      <td>Studiengang</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Gaskell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>Studiengang MR</td>\n",
       "      <td>MR</td>\n",
       "      <td>betreuen</td>\n",
       "      <td>Herr Gaskell betreut zudem einen Doktoranden i...</td>\n",
       "      <td>PER</td>\n",
       "      <td>Herr Gaskell</td>\n",
       "      <td>Gaskell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Die Gastprofessur</td>\n",
       "      <td>Gastprofessur</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td></td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Prof. Scholle</td>\n",
       "      <td>Prof.</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG</td>\n",
       "      <td>den DAAD</td>\n",
       "      <td>DAAD</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Prof. Scholle</td>\n",
       "      <td>Scholle</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>ca. 25.000 €</td>\n",
       "      <td>€</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>ca. 25.000 €</td>\n",
       "      <td>25.000</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>ca. 25.000 €</td>\n",
       "      <td>ca.</td>\n",
       "      <td>unterstützen</td>\n",
       "      <td>Die Gastprofessur wurde nach Antrag von Prof. ...</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>Antrag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>UK-Ranking</td>\n",
       "      <td>UK-Ranking</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Platz</td>\n",
       "      <td>Platz</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Oxford</td>\n",
       "      <td>Oxford</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Imperial College</td>\n",
       "      <td>College</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Imperial College</td>\n",
       "      <td>Imperial</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ORG</td>\n",
       "      <td>UK-Ranking</td>\n",
       "      <td>UK-Ranking</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Platz</td>\n",
       "      <td>Platz</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Oxford</td>\n",
       "      <td>Oxford</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Imperial College</td>\n",
       "      <td>College</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Imperial College</td>\n",
       "      <td>Imperial</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Durham University steht im UK-Ranking auf ...</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Die Durham University</td>\n",
       "      <td>Durham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Object_Type                    Objects              Objects_raw  \\\n",
       "0                              Stipendien               Stipendien   \n",
       "1                                 Studium                  Studium   \n",
       "2                       vertiefter Praxis                   Praxis   \n",
       "0                    Die Dirigierbewegung         Dirigierbewegung   \n",
       "0                               das Stück                    Stück   \n",
       "0                             Das Projekt                  Projekt   \n",
       "0                     den Hochschulen Ulm              Hochschulen   \n",
       "1          LOC        den Hochschulen Ulm                      Ulm   \n",
       "2          LOC                  Pforzheim                Pforzheim   \n",
       "3          ORG        der Universität Ulm              Universität   \n",
       "4          ORG        der Universität Ulm                      Ulm   \n",
       "5                     den Hochschulen Ulm              Hochschulen   \n",
       "6          LOC        den Hochschulen Ulm                      Ulm   \n",
       "7          LOC                  Pforzheim                Pforzheim   \n",
       "8          ORG        der Universität Ulm              Universität   \n",
       "9          ORG        der Universität Ulm                      Ulm   \n",
       "15                    den Hochschulen Ulm              Hochschulen   \n",
       "16         LOC        den Hochschulen Ulm                      Ulm   \n",
       "17         LOC                  Pforzheim                Pforzheim   \n",
       "18         ORG        der Universität Ulm              Universität   \n",
       "19         ORG        der Universität Ulm                      Ulm   \n",
       "0                       der Radarsensorik            Radarsensorik   \n",
       "1                eine neuartige Plattform                Plattform   \n",
       "2                      Applikationsfelder       Applikationsfelder   \n",
       "3                        Bewegungsanalyse         Bewegungsanalyse   \n",
       "4                      fließende Gewässer                 Gewässer   \n",
       "5                                  Bienen                   Bienen   \n",
       "6                           die Erfassung                Erfassung   \n",
       "7          LOC              Kochvorgängen            Kochvorgängen   \n",
       "8                 Automatisierungstechnik  Automatisierungstechnik   \n",
       "..         ...                        ...                      ...   \n",
       "30                             dem Gebiet                   Gebiet   \n",
       "31                       der Fluiddynamik             Fluiddynamik   \n",
       "32              dem nordenglischen Durham                   Durham   \n",
       "33                          Gastprofessor            Gastprofessor   \n",
       "34                         die Hochschule               Hochschule   \n",
       "0                       einen Doktoranden              Doktoranden   \n",
       "1                          Studiengang MR              Studiengang   \n",
       "2                          Studiengang MR                       MR   \n",
       "3                       einen Doktoranden              Doktoranden   \n",
       "4                          Studiengang MR              Studiengang   \n",
       "5                          Studiengang MR                       MR   \n",
       "0                       Die Gastprofessur            Gastprofessur   \n",
       "1         MISC              Prof. Scholle                    Prof.   \n",
       "2          ORG                   den DAAD                     DAAD   \n",
       "3         MISC              Prof. Scholle                  Scholle   \n",
       "4                            ca. 25.000 €                        €   \n",
       "5                            ca. 25.000 €                   25.000   \n",
       "6                            ca. 25.000 €                      ca.   \n",
       "0          ORG                 UK-Ranking               UK-Ranking   \n",
       "1                                   Platz                    Platz   \n",
       "2          LOC                     Oxford                   Oxford   \n",
       "3          ORG                  Cambridge                Cambridge   \n",
       "4          ORG           Imperial College                  College   \n",
       "5          ORG           Imperial College                 Imperial   \n",
       "6          ORG                 UK-Ranking               UK-Ranking   \n",
       "7                                   Platz                    Platz   \n",
       "8          LOC                     Oxford                   Oxford   \n",
       "9          ORG                  Cambridge                Cambridge   \n",
       "10         ORG           Imperial College                  College   \n",
       "11         ORG           Imperial College                 Imperial   \n",
       "\n",
       "       Relations                                           Sentence  \\\n",
       "0       gewinnen  Talente gewinnen Stipendien Studium mit vertie...   \n",
       "1       gewinnen  Talente gewinnen Stipendien Studium mit vertie...   \n",
       "2       gewinnen  Talente gewinnen Stipendien Studium mit vertie...   \n",
       "0        erfasst  Die Dirigierbewegung wird durch Radarsensorik ...   \n",
       "0      abbrechen  Weicht das Metrum zu stark von der Vorgabe des...   \n",
       "0   präsentieren  Das Projekt wird von der Hochschule Heilbronn ...   \n",
       "0      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "1      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "2      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "3      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "4      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "5      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "6      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "7      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "8      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "9      entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "15     entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "16     entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "17     entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "18     entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "19     entstehen  MikroSens Innovative Millimeterwellen-Sensorik...   \n",
       "0    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "1    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "2    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "3    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "4    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "5    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "6    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "7    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "8    erschließen  In diesem Forschungsprojekt werden der Radarse...   \n",
       "..           ...                                                ...   \n",
       "30        kommen  Zur Stärkung einer bestehenden langjährigen in...   \n",
       "31        kommen  Zur Stärkung einer bestehenden langjährigen in...   \n",
       "32        kommen  Zur Stärkung einer bestehenden langjährigen in...   \n",
       "33        kommen  Zur Stärkung einer bestehenden langjährigen in...   \n",
       "34        kommen  Zur Stärkung einer bestehenden langjährigen in...   \n",
       "0       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "1       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "2       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "3       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "4       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "5       betreuen  Herr Gaskell betreut zudem einen Doktoranden i...   \n",
       "0   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "1   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "2   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "3   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "4   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "5   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "6   unterstützen  Die Gastprofessur wurde nach Antrag von Prof. ...   \n",
       "0         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "1         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "2         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "3         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "4         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "5         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "6         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "7         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "8         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "9         stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "10        stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "11        stehen  Die Durham University steht im UK-Ranking auf ...   \n",
       "\n",
       "                Subject_Type                                        Subjects  \\\n",
       "0                        PER                                         Talente   \n",
       "1                        PER                                         Talente   \n",
       "2                        PER                                         Talente   \n",
       "0                                                              Radarsensorik   \n",
       "0                                                              das Orchester   \n",
       "0                        ORG                        der Hochschule Heilbronn   \n",
       "0                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "1                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "2                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "3                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "4                        ORG  MikroSens Innovative Millimeterwellen-Sensorik   \n",
       "5                        ORG                                       MikroSens   \n",
       "6                        ORG                                       MikroSens   \n",
       "7                        ORG                                       MikroSens   \n",
       "8                        ORG                                       MikroSens   \n",
       "9                        ORG                                       MikroSens   \n",
       "15                       ORG                        industrielle Anwendungen   \n",
       "16                       ORG                        industrielle Anwendungen   \n",
       "17                       ORG                        industrielle Anwendungen   \n",
       "18                       ORG                        industrielle Anwendungen   \n",
       "19                       ORG                        industrielle Anwendungen   \n",
       "0                                                   diesem Forschungsprojekt   \n",
       "1   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "2   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "3   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "4   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "5   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "6   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "7   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "8   diesem Forschungsprojekt                        diesem Forschungsprojekt   \n",
       "..                       ...                                             ...   \n",
       "30                       PER                    Herr Prof. Philip H. Gaskell   \n",
       "31                       PER                    Herr Prof. Philip H. Gaskell   \n",
       "32                       PER                    Herr Prof. Philip H. Gaskell   \n",
       "33                       PER                    Herr Prof. Philip H. Gaskell   \n",
       "34                       PER                    Herr Prof. Philip H. Gaskell   \n",
       "0                                                               Herr Gaskell   \n",
       "1                                                               Herr Gaskell   \n",
       "2                                                               Herr Gaskell   \n",
       "3                        PER                                    Herr Gaskell   \n",
       "4                        PER                                    Herr Gaskell   \n",
       "5                        PER                                    Herr Gaskell   \n",
       "0                                                                     Antrag   \n",
       "1                     Antrag                                          Antrag   \n",
       "2                     Antrag                                          Antrag   \n",
       "3                     Antrag                                          Antrag   \n",
       "4                     Antrag                                          Antrag   \n",
       "5                     Antrag                                          Antrag   \n",
       "6                     Antrag                                          Antrag   \n",
       "0                        ORG                           Die Durham University   \n",
       "1                        ORG                           Die Durham University   \n",
       "2                        ORG                           Die Durham University   \n",
       "3                        ORG                           Die Durham University   \n",
       "4                        ORG                           Die Durham University   \n",
       "5                        ORG                           Die Durham University   \n",
       "6                        ORG                           Die Durham University   \n",
       "7                        ORG                           Die Durham University   \n",
       "8                        ORG                           Die Durham University   \n",
       "9                        ORG                           Die Durham University   \n",
       "10                       ORG                           Die Durham University   \n",
       "11                       ORG                           Die Durham University   \n",
       "\n",
       "                 Subjects_raw  \n",
       "0                     Talente  \n",
       "1                     Talente  \n",
       "2                     Talente  \n",
       "0               Radarsensorik  \n",
       "0                   Orchester  \n",
       "0                  Hochschule  \n",
       "0   Millimeterwellen-Sensorik  \n",
       "1   Millimeterwellen-Sensorik  \n",
       "2   Millimeterwellen-Sensorik  \n",
       "3   Millimeterwellen-Sensorik  \n",
       "4   Millimeterwellen-Sensorik  \n",
       "5                   MikroSens  \n",
       "6                   MikroSens  \n",
       "7                   MikroSens  \n",
       "8                   MikroSens  \n",
       "9                   MikroSens  \n",
       "15                Anwendungen  \n",
       "16                Anwendungen  \n",
       "17                Anwendungen  \n",
       "18                Anwendungen  \n",
       "19                Anwendungen  \n",
       "0           Forschungsprojekt  \n",
       "1           Forschungsprojekt  \n",
       "2           Forschungsprojekt  \n",
       "3           Forschungsprojekt  \n",
       "4           Forschungsprojekt  \n",
       "5           Forschungsprojekt  \n",
       "6           Forschungsprojekt  \n",
       "7           Forschungsprojekt  \n",
       "8           Forschungsprojekt  \n",
       "..                        ...  \n",
       "30                         H.  \n",
       "31                         H.  \n",
       "32                         H.  \n",
       "33                         H.  \n",
       "34                         H.  \n",
       "0                        Herr  \n",
       "1                        Herr  \n",
       "2                        Herr  \n",
       "3                     Gaskell  \n",
       "4                     Gaskell  \n",
       "5                     Gaskell  \n",
       "0                      Antrag  \n",
       "1                      Antrag  \n",
       "2                      Antrag  \n",
       "3                      Antrag  \n",
       "4                      Antrag  \n",
       "5                      Antrag  \n",
       "6                      Antrag  \n",
       "0                  University  \n",
       "1                  University  \n",
       "2                  University  \n",
       "3                  University  \n",
       "4                  University  \n",
       "5                  University  \n",
       "6                      Durham  \n",
       "7                      Durham  \n",
       "8                      Durham  \n",
       "9                      Durham  \n",
       "10                     Durham  \n",
       "11                     Durham  \n",
       "\n",
       "[406 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Test mit dem Text aus dem Zweiten Dokument aus den von Gruppe 1 zur Verfügung gestellten Daten\n",
    "'''\n",
    "text = df['Text'][1]\n",
    "df_info_full = information_extraction(text)\n",
    "df_info_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entwicklungsmodus: Test mit einem selbsterstellten Satz\n",
    "##### Für das Testen vom Algorithmus, kann ein Text im nächsten Block eingefügt werden, sodass die Variable \"text\" gleich dem eingegebenen Text  ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs extracted: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:71: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:165: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"das interessante Buch wird von Victor nicht heute am schönen Strand gelesen, sondern fährt er das schnelle Auto\"\n",
    "df_info_full, df_subjs, df_objs, df_relations = information_extraction(text, all_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extrahierten Informationen in Form von Subjekten Objekten und ihren Beziehungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Objects</th>\n",
       "      <th>Objects_raw</th>\n",
       "      <th>Relations</th>\n",
       "      <th>Subject_Type</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Subjects_raw</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>das interessante Buch</td>\n",
       "      <td>Buch</td>\n",
       "      <td>lesen</td>\n",
       "      <td>PER</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>das interessante Buch wird von Victor nicht he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>schönen Strand</td>\n",
       "      <td>Strand</td>\n",
       "      <td>lesen</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>das interessante Buch wird von Victor nicht he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>das schnelle Auto</td>\n",
       "      <td>Auto</td>\n",
       "      <td>fahren</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>das interessante Buch wird von Victor nicht he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Object_Type                Objects Objects_raw Relations Subject_Type  \\\n",
       "0              das interessante Buch        Buch     lesen          PER   \n",
       "1                     schönen Strand      Strand     lesen       Victor   \n",
       "2                  das schnelle Auto        Auto    fahren       Victor   \n",
       "\n",
       "  Subjects Subjects_raw                                           Sentence  \n",
       "0   Victor       Victor  das interessante Buch wird von Victor nicht he...  \n",
       "1   Victor       Victor  das interessante Buch wird von Victor nicht he...  \n",
       "2   Victor       Victor  das interessante Buch wird von Victor nicht he...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Objekte und ihre wesentlichen Informationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj</th>\n",
       "      <th>obj_chunk</th>\n",
       "      <th>obj_type</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>PER</td>\n",
       "      <td>gelesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Strand</td>\n",
       "      <td>schönen Strand</td>\n",
       "      <td></td>\n",
       "      <td>gelesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto</td>\n",
       "      <td>das schnelle Auto</td>\n",
       "      <td></td>\n",
       "      <td>fährt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      obj          obj_chunk obj_type     root\n",
       "0  Victor             Victor      PER  gelesen\n",
       "1  Strand     schönen Strand           gelesen\n",
       "2    Auto  das schnelle Auto             fährt"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subjekte und ihre wesentlichen Informationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root</th>\n",
       "      <th>subj</th>\n",
       "      <th>subj_chunk</th>\n",
       "      <th>subj_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wird</td>\n",
       "      <td>Buch</td>\n",
       "      <td>das interessante Buch</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fährt</td>\n",
       "      <td>er</td>\n",
       "      <td>er</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    root  subj             subj_chunk subj_type\n",
       "0   wird  Buch  das interessante Buch          \n",
       "1  fährt    er                     er          "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relationen und Wurzeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fährt</td>\n",
       "      <td>fährt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wird gelesen</td>\n",
       "      <td>wird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wird gelesen</td>\n",
       "      <td>gelesen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       relation     root\n",
       "0         fährt    fährt\n",
       "1  wird gelesen     wird\n",
       "2  wird gelesen  gelesen"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generierung von den Training-Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datendistribution: Wikipedia auf Deutsch\n",
    "Das Ziel von dieser Implementierung ist die Performance vom Algorithmus im Kontext einer anderen Datendistribution zu evaluieren und diese mit der Performance auf Basis von Echtdaten der Hochschule Heilbronn zu vergleichen. Themen die berücksichtigt werden sind bspw.:\n",
    "##### **1** - Werden mehrere Paaren in der anderen Distribution erkannt?\n",
    "##### **2** - Ergeben die aus der anderen Datendistribution erkannten Paaren mehr Sinn als die aus Echtdaten?\n",
    "##### **3** - Wie können die Ergebnisse verglichen werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_scrape(topic_name, verbose=True):\n",
    "    '''\n",
    "    Diese Methode ist ein Wikipedia-Scraper, was die in Beziehung stehende Artikeln aus der Wikipedia in einem \n",
    "    Dataframe speichert zusammen mit verfügbaren Metadaten zu diesem Artikel\n",
    "    '''\n",
    "    \n",
    "    def wiki_link(link):\n",
    "        try:\n",
    "            page = wiki_api.page(link)\n",
    "            if page.exists():\n",
    "                d = {'page': link, 'text': page.text, 'link': page.fullurl,\n",
    "                     'categories': list(page.categories.keys())}\n",
    "                return d\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    wiki_api = wikipediaapi.Wikipedia(language='de',\n",
    "                extract_format=wikipediaapi.ExtractFormat.WIKI)\n",
    "    \n",
    "    page_name = wiki_api.page(topic_name)\n",
    "    \n",
    "    if not page_name.exists():\n",
    "        print('page does not exist')\n",
    "        return\n",
    "    \n",
    "    page_links = list(page_name.links.keys())\n",
    "    progress = tqdm(desc='Links Scraped', unit='', total=len(page_links)) if verbose else None\n",
    "    sources = [{'page': topic_name, 'text': page_name.text, 'link': page_name.fullurl,\n",
    "                'categories': list(page_name.categories.keys())}]\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_link = {executor.submit(wiki_link, link): link for link in page_links}\n",
    "        for future in concurrent.futures.as_completed(future_link):\n",
    "            data = future.result()\n",
    "            progress.update(1) if verbose else None\n",
    "            if data:\n",
    "                sources.append(data)\n",
    "    progress.close() if verbose else None\n",
    "    blacklist = ('Template', 'Help:', 'Category:', 'Portal:', 'Wikipedia:', 'Talk:')\n",
    "    sources = pd.DataFrame(sources)\n",
    "    sources = sources[(len(sources['text']) > 20)\n",
    "                      & ~(sources['page'].str.startswith(blacklist))]\n",
    "    sources['categories'] = sources.categories.apply(lambda x: [y[9:] for y in x])\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Links Scraped: 100%|██████████| 2068/2068 [04:36<00:00,  7.49/s]\n"
     ]
    }
   ],
   "source": [
    "df_wiki = wiki_scrape('Deutschland')\n",
    "df_wiki.to_csv(r'wiki_deutschland_datensatz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>link</th>\n",
       "      <th>page</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[:Namensgeber für ein chemisches Element, :Gru...</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Deutschland ( [ˈdɔʏtʃlant]; Vollform: Bundesre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[:Allgemeine Truppenkunde, :Militär nach Teils...</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Teilstreitkraft</td>\n",
       "      <td>Teilstreitkraft</td>\n",
       "      <td>Eine Teilstreitkraft (abgekürzt TSK; englisch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[:Wikipedia:Defekte Weblinks/Ungeprüfte Botmar...</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Verteidigungsetat</td>\n",
       "      <td>Verteidigungsetat</td>\n",
       "      <td>Der Verteidigungshaushalt, auch Verteidigungsb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[:Politik 1923, :Bayerische Geschichte (20. Ja...</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Hitlerputsch</td>\n",
       "      <td>Hitlerputsch</td>\n",
       "      <td>Der Hitlerputsch (auch Hitler-Ludendorff-Putsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[:Wikipedia:Redundanz Januar 2015, :Schulwesen...</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Gegliedertes_Sch...</td>\n",
       "      <td>Gegliedertes Schulsystem</td>\n",
       "      <td>Als gegliedertes Schulsystem werden Schulsyste...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          categories  \\\n",
       "0  [:Namensgeber für ein chemisches Element, :Gru...   \n",
       "1  [:Allgemeine Truppenkunde, :Militär nach Teils...   \n",
       "2  [:Wikipedia:Defekte Weblinks/Ungeprüfte Botmar...   \n",
       "3  [:Politik 1923, :Bayerische Geschichte (20. Ja...   \n",
       "4  [:Wikipedia:Redundanz Januar 2015, :Schulwesen...   \n",
       "\n",
       "                                                link  \\\n",
       "0          https://de.wikipedia.org/wiki/Deutschland   \n",
       "1      https://de.wikipedia.org/wiki/Teilstreitkraft   \n",
       "2    https://de.wikipedia.org/wiki/Verteidigungsetat   \n",
       "3         https://de.wikipedia.org/wiki/Hitlerputsch   \n",
       "4  https://de.wikipedia.org/wiki/Gegliedertes_Sch...   \n",
       "\n",
       "                       page                                               text  \n",
       "0               Deutschland  Deutschland ( [ˈdɔʏtʃlant]; Vollform: Bundesre...  \n",
       "1           Teilstreitkraft  Eine Teilstreitkraft (abgekürzt TSK; englisch ...  \n",
       "2         Verteidigungsetat  Der Verteidigungshaushalt, auch Verteidigungsb...  \n",
       "3              Hitlerputsch  Der Hitlerputsch (auch Hitler-Ludendorff-Putsc...  \n",
       "4  Gegliedertes Schulsystem  Als gegliedertes Schulsystem werden Schulsyste...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:541: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:576: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:670: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:829: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:667: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs extracted: 3496\n",
      "___________________________________________________\n",
      "Document: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:29: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/student/.local/lib/python3.5/site-packages/ipykernel_launcher.py:30: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs extracted: 105\n",
      "___________________________________________________\n",
      "Document: 2\n",
      "Pairs extracted: 1949\n",
      "___________________________________________________\n",
      "Document: 3\n",
      "Pairs extracted: 634\n",
      "___________________________________________________\n",
      "Document: 4\n",
      "Pairs extracted: 309\n",
      "___________________________________________________\n",
      "Document: 5\n",
      "Pairs extracted: 724\n",
      "___________________________________________________\n",
      "Document: 6\n",
      "Pairs extracted: 124\n",
      "___________________________________________________\n",
      "Document: 7\n",
      "Pairs extracted: 207\n",
      "___________________________________________________\n",
      "Document: 8\n",
      "Pairs extracted: 1977\n",
      "___________________________________________________\n",
      "Document: 9\n",
      "Pairs extracted: 322\n",
      "___________________________________________________\n",
      "Document: 10\n",
      "Pairs extracted: 1034\n",
      "___________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Features aus dem NLP-Verfahren\n",
    "kg_data_cols = ['Subjects', 'Subjects_raw', 'Subject_Type', 'Relations', 'Objects_raw', 'Objects', 'Object_Type', 'Sentence']\n",
    "\n",
    "# Zusammenfügung von allen Features\n",
    "columns = kg_data_cols\n",
    "\n",
    "# Erstellung eines leeren Dataframes\n",
    "wiki_kg_df = pd.DataFrame(columns=columns)\n",
    "wiki_kg_df_error = []\n",
    "\n",
    "# Erstellung eines Objektes aus der VictoryNLP-Klasse\n",
    "victory = VictoryNLP(\"victory\", nlp)\n",
    "\n",
    "# Schleife über den Wiki-Datensatz\n",
    "for i, doc in df_wiki.iterrows():\n",
    "    \n",
    "    # Erstellung eines Dataframes für alle Extrahierten Informationen aus einem Wikipediaartikel\n",
    "    doc = pd.DataFrame(doc).T\n",
    "    # Einstellung der Spalten\n",
    "    cache = pd.DataFrame(columns=columns)\n",
    "    \n",
    "     # Wird versucht, die Informationen aus einem Dokument zu extrahieren\n",
    "    try:\n",
    "        print('Document: {}'.format(i))\n",
    "        pairs = victory.information_extraction(doc.iloc[0]['text'])\n",
    "        cache = pd.concat([cache, pairs])\n",
    "        wiki_kg_df = pd.concat([wiki_kg_df,cache])\n",
    "        print('___________________________________________________')\n",
    "        \n",
    "    # Wird angezeigt, dass ein Fehler passiert ist\n",
    "    except:\n",
    "        wiki_kg_df_error.append(doc.iloc[0]['link'])\n",
    "        print('Error')\n",
    "        print('___________________________________________________')\n",
    "    \n",
    "    # Speichert den Datensatz während der Ausführung des NLP-Verfahren (in 100-Schritten)\n",
    "    if i%100==0:\n",
    "        wiki_kg_df.to_csv(r'pairs_wiki_deutschland_datensatz_v2.csv')\n",
    "        \n",
    "# Speichert am Ende\n",
    "wiki_kg_df.to_csv(r'pairs_wiki_deutschland_datensatz_v2.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis der Datenextrahierung aus den Wikipediaartikeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Objects</th>\n",
       "      <th>Objects_raw</th>\n",
       "      <th>Relations</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Subject_Type</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Subjects_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>die jüngste Ausprägung</td>\n",
       "      <td>Ausprägung</td>\n",
       "      <td>darstellen</td>\n",
       "      <td>Die 1949 gegründete Bundesrepublik Deutschland...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Die 1949 gegründete Bundesrepublik Deutschland</td>\n",
       "      <td>Bundesrepublik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORG</td>\n",
       "      <td>des deutschen Nationalstaates</td>\n",
       "      <td>Nationalstaates</td>\n",
       "      <td>darstellen</td>\n",
       "      <td>Die 1949 gegründete Bundesrepublik Deutschland...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Die 1949 gegründete Bundesrepublik Deutschland</td>\n",
       "      <td>Bundesrepublik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>die jüngste Ausprägung</td>\n",
       "      <td>Ausprägung</td>\n",
       "      <td>darstellen</td>\n",
       "      <td>Die 1949 gegründete Bundesrepublik Deutschland...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Die 1949 gegründete Bundesrepublik Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORG</td>\n",
       "      <td>des deutschen Nationalstaates</td>\n",
       "      <td>Nationalstaates</td>\n",
       "      <td>darstellen</td>\n",
       "      <td>Die 1949 gegründete Bundesrepublik Deutschland...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Die 1949 gegründete Bundesrepublik Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>83 Millionen Einwohner</td>\n",
       "      <td>Millionen</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschland hat 83 Millionen Einwohner und zäh...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>83 Millionen Einwohner</td>\n",
       "      <td>83</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschland hat 83 Millionen Einwohner und zäh...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>83 Millionen Einwohner</td>\n",
       "      <td>Einwohner</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschland hat 83 Millionen Einwohner und zäh...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>grenzen</td>\n",
       "      <td>An Deutschland grenzen neun Staaten, es hat An...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>neun Staaten</td>\n",
       "      <td>Staaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>grenzen</td>\n",
       "      <td>An Deutschland grenzen neun Staaten, es hat An...</td>\n",
       "      <td></td>\n",
       "      <td>neun Staaten</td>\n",
       "      <td>neun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Anteil</td>\n",
       "      <td>Anteil</td>\n",
       "      <td>haben</td>\n",
       "      <td>An Deutschland grenzen neun Staaten, es hat An...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>neun Staaten</td>\n",
       "      <td>Staaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOC</td>\n",
       "      <td>der Nord- und Ostsee</td>\n",
       "      <td>Ostsee</td>\n",
       "      <td>haben</td>\n",
       "      <td>An Deutschland grenzen neun Staaten, es hat An...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>neun Staaten</td>\n",
       "      <td>Staaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Norden</td>\n",
       "      <td>Norden</td>\n",
       "      <td>haben</td>\n",
       "      <td>An Deutschland grenzen neun Staaten, es hat An...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>neun Staaten</td>\n",
       "      <td>Staaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LOC</td>\n",
       "      <td>dem Bodensee</td>\n",
       "      <td>Bodensee</td>\n",
       "      <td>haben</td>\n",
       "      <td>An Deutschland grenzen neun Staaten, es hat An...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>neun Staaten</td>\n",
       "      <td>Staaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LOC</td>\n",
       "      <td>den Alpen</td>\n",
       "      <td>Alpen</td>\n",
       "      <td>haben</td>\n",
       "      <td>An Deutschland grenzen neun Staaten, es hat An...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>neun Staaten</td>\n",
       "      <td>Staaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Süden</td>\n",
       "      <td>Süden</td>\n",
       "      <td>haben</td>\n",
       "      <td>An Deutschland grenzen neun Staaten, es hat An...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>neun Staaten</td>\n",
       "      <td>Staaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1,57 Kindern</td>\n",
       "      <td>Kindern</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td></td>\n",
       "      <td>Deutschlands Bevölkerung</td>\n",
       "      <td>Bevölkerung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>1,57 Kindern</td>\n",
       "      <td>1,57</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td></td>\n",
       "      <td>Deutschlands Bevölkerung</td>\n",
       "      <td>Bevölkerung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Frau</td>\n",
       "      <td>Frau</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td></td>\n",
       "      <td>Deutschlands Bevölkerung</td>\n",
       "      <td>Bevölkerung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>eine vergleichsweise niedrige Geburtenrate</td>\n",
       "      <td>vergleichsweise</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td></td>\n",
       "      <td>Deutschlands Bevölkerung</td>\n",
       "      <td>Bevölkerung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>eine vergleichsweise niedrige Geburtenrate</td>\n",
       "      <td>Geburtenrate</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td></td>\n",
       "      <td>Deutschlands Bevölkerung</td>\n",
       "      <td>Bevölkerung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>1,57 Kindern</td>\n",
       "      <td>Kindern</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Deutschlands Bevölkerung</td>\n",
       "      <td>Deutschlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>1,57 Kindern</td>\n",
       "      <td>1,57</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Deutschlands Bevölkerung</td>\n",
       "      <td>Deutschlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Frau</td>\n",
       "      <td>Frau</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Deutschlands Bevölkerung</td>\n",
       "      <td>Deutschlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>eine vergleichsweise niedrige Geburtenrate</td>\n",
       "      <td>vergleichsweise</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Deutschlands Bevölkerung</td>\n",
       "      <td>Deutschlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>eine vergleichsweise niedrige Geburtenrate</td>\n",
       "      <td>Geburtenrate</td>\n",
       "      <td>haben</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Deutschlands Bevölkerung</td>\n",
       "      <td>Deutschlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>den 2010er-Jahren</td>\n",
       "      <td>2010er-Jahren</td>\n",
       "      <td>ansteigen</td>\n",
       "      <td>Deutschlands Bevölkerung hat mit 1,57 Kindern ...</td>\n",
       "      <td></td>\n",
       "      <td>eine vergleichsweise niedrige Geburtenrate</td>\n",
       "      <td>Geburtenrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>dem Gebiet</td>\n",
       "      <td>Gebiet</td>\n",
       "      <td>sein nachweisen</td>\n",
       "      <td>Auf dem Gebiet des heutigen Deutschlands ist d...</td>\n",
       "      <td></td>\n",
       "      <td>die Anwesenheit</td>\n",
       "      <td>Anwesenheit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>des heutigen Deutschlands</td>\n",
       "      <td>Deutschlands</td>\n",
       "      <td>sein nachweisen</td>\n",
       "      <td>Auf dem Gebiet des heutigen Deutschlands ist d...</td>\n",
       "      <td></td>\n",
       "      <td>die Anwesenheit</td>\n",
       "      <td>Anwesenheit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Funde</td>\n",
       "      <td>Funde</td>\n",
       "      <td>sein nachweisen</td>\n",
       "      <td>Auf dem Gebiet des heutigen Deutschlands ist d...</td>\n",
       "      <td></td>\n",
       "      <td>die Anwesenheit</td>\n",
       "      <td>Anwesenheit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>dem Gebiet</td>\n",
       "      <td>Gebiet</td>\n",
       "      <td>sein nachweisen</td>\n",
       "      <td>Auf dem Gebiet des heutigen Deutschlands ist d...</td>\n",
       "      <td></td>\n",
       "      <td>Menschen</td>\n",
       "      <td>Menschen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PER</td>\n",
       "      <td>Sally Field F.I.S.T.</td>\n",
       "      <td>Field</td>\n",
       "      <td>stehen</td>\n",
       "      <td>Die Faust im Nacken mit Marlon Brando Norma Ra...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Eine Frau</td>\n",
       "      <td>Frau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>seinen Weg</td>\n",
       "      <td>Weg</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PER</td>\n",
       "      <td>Sylvester Stallone Silkwood</td>\n",
       "      <td>Sylvester</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PER</td>\n",
       "      <td>Meryl Streep</td>\n",
       "      <td>Streep</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PER</td>\n",
       "      <td>Richard Pryor</td>\n",
       "      <td>Pryor</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>Sylvester Stallone Silkwood</td>\n",
       "      <td>Silkwood</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PER</td>\n",
       "      <td>Meryl Streep</td>\n",
       "      <td>Meryl</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PER</td>\n",
       "      <td>Cher</td>\n",
       "      <td>Cher</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PER</td>\n",
       "      <td>Richard Pryor</td>\n",
       "      <td>Richard</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PER</td>\n",
       "      <td>Sylvester Stallone Silkwood</td>\n",
       "      <td>Stallone</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PER</td>\n",
       "      <td>Harvey Keitel Jimmy Hoffa</td>\n",
       "      <td>Keitel</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PER</td>\n",
       "      <td>Kurt Russell Blue Collar</td>\n",
       "      <td>Collar</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PER</td>\n",
       "      <td>Harvey Keitel Jimmy Hoffa</td>\n",
       "      <td>Harvey</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PER</td>\n",
       "      <td>Harvey Keitel Jimmy Hoffa</td>\n",
       "      <td>Hoffa</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PER</td>\n",
       "      <td>Kurt Russell Blue Collar</td>\n",
       "      <td>Kurt</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PER</td>\n",
       "      <td>Kurt Russell Blue Collar</td>\n",
       "      <td>Russell</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PER</td>\n",
       "      <td>Kurt Russell Blue Collar</td>\n",
       "      <td>Blue</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PER</td>\n",
       "      <td>Harvey Keitel Jimmy Hoffa</td>\n",
       "      <td>Jimmy</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PER</td>\n",
       "      <td>Jack Nicholson Bread and Roses</td>\n",
       "      <td>Roses</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PER</td>\n",
       "      <td>Jack Nicholson Bread and Roses</td>\n",
       "      <td>Jack</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PER</td>\n",
       "      <td>Jack Nicholson Bread and Roses</td>\n",
       "      <td>Nicholson</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PER</td>\n",
       "      <td>Jack Nicholson Bread and Roses</td>\n",
       "      <td>Bread</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PER</td>\n",
       "      <td>Jack Nicholson Bread and Roses</td>\n",
       "      <td>and</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PER</td>\n",
       "      <td>Ken Loach</td>\n",
       "      <td>Loach</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PER</td>\n",
       "      <td>Ken Loach</td>\n",
       "      <td>Ken</td>\n",
       "      <td>gehen</td>\n",
       "      <td>Ein Mann geht seinen Weg mit Sylvester Stallon...</td>\n",
       "      <td>MISC</td>\n",
       "      <td>Ein Mann</td>\n",
       "      <td>Mann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Liste</td>\n",
       "      <td>Liste</td>\n",
       "      <td>Siehe</td>\n",
       "      <td>Siehe auch Arbeitsrecht Liste von Gewerkschaft...</td>\n",
       "      <td></td>\n",
       "      <td>auch Arbeitsrecht</td>\n",
       "      <td>Arbeitsrecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>Gewerkschaften</td>\n",
       "      <td>Gewerkschaften</td>\n",
       "      <td>Siehe</td>\n",
       "      <td>Siehe auch Arbeitsrecht Liste von Gewerkschaft...</td>\n",
       "      <td></td>\n",
       "      <td>auch Arbeitsrecht</td>\n",
       "      <td>Arbeitsrecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Europa</td>\n",
       "      <td>Siehe</td>\n",
       "      <td>Siehe auch Arbeitsrecht Liste von Gewerkschaft...</td>\n",
       "      <td></td>\n",
       "      <td>auch Arbeitsrecht</td>\n",
       "      <td>Arbeitsrecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Arbeitsentgelt Koalitionsrecht</td>\n",
       "      <td>Koalitionsrecht</td>\n",
       "      <td>Siehe</td>\n",
       "      <td>Siehe auch Arbeitsrecht Liste von Gewerkschaft...</td>\n",
       "      <td></td>\n",
       "      <td>auch Arbeitsrecht</td>\n",
       "      <td>Arbeitsrecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Arbeitsentgelt Koalitionsrecht</td>\n",
       "      <td>Arbeitsentgelt</td>\n",
       "      <td>Siehe</td>\n",
       "      <td>Siehe auch Arbeitsrecht Liste von Gewerkschaft...</td>\n",
       "      <td></td>\n",
       "      <td>auch Arbeitsrecht</td>\n",
       "      <td>Arbeitsrecht</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10881 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Object_Type                                     Objects      Objects_raw  \\\n",
       "0                                   die jüngste Ausprägung       Ausprägung   \n",
       "1          ORG               des deutschen Nationalstaates  Nationalstaates   \n",
       "2                                   die jüngste Ausprägung       Ausprägung   \n",
       "3          ORG               des deutschen Nationalstaates  Nationalstaates   \n",
       "0                                   83 Millionen Einwohner        Millionen   \n",
       "1                                   83 Millionen Einwohner               83   \n",
       "2                                   83 Millionen Einwohner        Einwohner   \n",
       "0          LOC                                 Deutschland      Deutschland   \n",
       "1          LOC                                 Deutschland      Deutschland   \n",
       "2                                                   Anteil           Anteil   \n",
       "3          LOC                        der Nord- und Ostsee           Ostsee   \n",
       "4                                                   Norden           Norden   \n",
       "5          LOC                                dem Bodensee         Bodensee   \n",
       "6          LOC                                   den Alpen            Alpen   \n",
       "7                                                    Süden            Süden   \n",
       "0                                             1,57 Kindern          Kindern   \n",
       "1                                             1,57 Kindern             1,57   \n",
       "2                                                     Frau             Frau   \n",
       "3               eine vergleichsweise niedrige Geburtenrate  vergleichsweise   \n",
       "4               eine vergleichsweise niedrige Geburtenrate     Geburtenrate   \n",
       "5                                             1,57 Kindern          Kindern   \n",
       "6                                             1,57 Kindern             1,57   \n",
       "7                                                     Frau             Frau   \n",
       "8               eine vergleichsweise niedrige Geburtenrate  vergleichsweise   \n",
       "9               eine vergleichsweise niedrige Geburtenrate     Geburtenrate   \n",
       "15                                       den 2010er-Jahren    2010er-Jahren   \n",
       "0                                               dem Gebiet           Gebiet   \n",
       "1          LOC                   des heutigen Deutschlands     Deutschlands   \n",
       "2                                                    Funde            Funde   \n",
       "3                                               dem Gebiet           Gebiet   \n",
       "..         ...                                         ...              ...   \n",
       "27         PER                        Sally Field F.I.S.T.            Field   \n",
       "0                                               seinen Weg              Weg   \n",
       "1          PER                 Sylvester Stallone Silkwood        Sylvester   \n",
       "2          PER                                Meryl Streep           Streep   \n",
       "3          PER                               Richard Pryor            Pryor   \n",
       "4          PER                 Sylvester Stallone Silkwood         Silkwood   \n",
       "5          PER                                Meryl Streep            Meryl   \n",
       "6          PER                                        Cher             Cher   \n",
       "7          PER                               Richard Pryor          Richard   \n",
       "8          PER                 Sylvester Stallone Silkwood         Stallone   \n",
       "9          PER                   Harvey Keitel Jimmy Hoffa           Keitel   \n",
       "10         PER                    Kurt Russell Blue Collar           Collar   \n",
       "11         PER                   Harvey Keitel Jimmy Hoffa           Harvey   \n",
       "12         PER                   Harvey Keitel Jimmy Hoffa            Hoffa   \n",
       "13         PER                    Kurt Russell Blue Collar             Kurt   \n",
       "14         PER                    Kurt Russell Blue Collar          Russell   \n",
       "15         PER                    Kurt Russell Blue Collar             Blue   \n",
       "16         PER                   Harvey Keitel Jimmy Hoffa            Jimmy   \n",
       "17         PER              Jack Nicholson Bread and Roses            Roses   \n",
       "18         PER              Jack Nicholson Bread and Roses             Jack   \n",
       "19         PER              Jack Nicholson Bread and Roses        Nicholson   \n",
       "20         PER              Jack Nicholson Bread and Roses            Bread   \n",
       "21         PER              Jack Nicholson Bread and Roses              and   \n",
       "22         PER                                   Ken Loach            Loach   \n",
       "23         PER                                   Ken Loach              Ken   \n",
       "0         MISC                                       Liste            Liste   \n",
       "1         MISC                              Gewerkschaften   Gewerkschaften   \n",
       "2          LOC                                      Europa           Europa   \n",
       "3                           Arbeitsentgelt Koalitionsrecht  Koalitionsrecht   \n",
       "4                           Arbeitsentgelt Koalitionsrecht   Arbeitsentgelt   \n",
       "\n",
       "          Relations                                           Sentence  \\\n",
       "0        darstellen  Die 1949 gegründete Bundesrepublik Deutschland...   \n",
       "1        darstellen  Die 1949 gegründete Bundesrepublik Deutschland...   \n",
       "2        darstellen  Die 1949 gegründete Bundesrepublik Deutschland...   \n",
       "3        darstellen  Die 1949 gegründete Bundesrepublik Deutschland...   \n",
       "0             haben  Deutschland hat 83 Millionen Einwohner und zäh...   \n",
       "1             haben  Deutschland hat 83 Millionen Einwohner und zäh...   \n",
       "2             haben  Deutschland hat 83 Millionen Einwohner und zäh...   \n",
       "0           grenzen  An Deutschland grenzen neun Staaten, es hat An...   \n",
       "1           grenzen  An Deutschland grenzen neun Staaten, es hat An...   \n",
       "2             haben  An Deutschland grenzen neun Staaten, es hat An...   \n",
       "3             haben  An Deutschland grenzen neun Staaten, es hat An...   \n",
       "4             haben  An Deutschland grenzen neun Staaten, es hat An...   \n",
       "5             haben  An Deutschland grenzen neun Staaten, es hat An...   \n",
       "6             haben  An Deutschland grenzen neun Staaten, es hat An...   \n",
       "7             haben  An Deutschland grenzen neun Staaten, es hat An...   \n",
       "0             haben  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "1             haben  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "2             haben  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "3             haben  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "4             haben  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "5             haben  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "6             haben  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "7             haben  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "8             haben  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "9             haben  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "15        ansteigen  Deutschlands Bevölkerung hat mit 1,57 Kindern ...   \n",
       "0   sein nachweisen  Auf dem Gebiet des heutigen Deutschlands ist d...   \n",
       "1   sein nachweisen  Auf dem Gebiet des heutigen Deutschlands ist d...   \n",
       "2   sein nachweisen  Auf dem Gebiet des heutigen Deutschlands ist d...   \n",
       "3   sein nachweisen  Auf dem Gebiet des heutigen Deutschlands ist d...   \n",
       "..              ...                                                ...   \n",
       "27           stehen  Die Faust im Nacken mit Marlon Brando Norma Ra...   \n",
       "0             gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "1             gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "2             gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "3             gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "4             gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "5             gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "6             gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "7             gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "8             gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "9             gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "10            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "11            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "12            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "13            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "14            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "15            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "16            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "17            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "18            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "19            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "20            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "21            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "22            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "23            gehen  Ein Mann geht seinen Weg mit Sylvester Stallon...   \n",
       "0             Siehe  Siehe auch Arbeitsrecht Liste von Gewerkschaft...   \n",
       "1             Siehe  Siehe auch Arbeitsrecht Liste von Gewerkschaft...   \n",
       "2             Siehe  Siehe auch Arbeitsrecht Liste von Gewerkschaft...   \n",
       "3             Siehe  Siehe auch Arbeitsrecht Liste von Gewerkschaft...   \n",
       "4             Siehe  Siehe auch Arbeitsrecht Liste von Gewerkschaft...   \n",
       "\n",
       "   Subject_Type                                        Subjects  \\\n",
       "0           LOC  Die 1949 gegründete Bundesrepublik Deutschland   \n",
       "1           LOC  Die 1949 gegründete Bundesrepublik Deutschland   \n",
       "2           LOC  Die 1949 gegründete Bundesrepublik Deutschland   \n",
       "3           LOC  Die 1949 gegründete Bundesrepublik Deutschland   \n",
       "0           LOC                                     Deutschland   \n",
       "1           LOC                                     Deutschland   \n",
       "2           LOC                                     Deutschland   \n",
       "0           LOC                                    neun Staaten   \n",
       "1                                                  neun Staaten   \n",
       "2           LOC                                    neun Staaten   \n",
       "3           LOC                                    neun Staaten   \n",
       "4           LOC                                    neun Staaten   \n",
       "5           LOC                                    neun Staaten   \n",
       "6           LOC                                    neun Staaten   \n",
       "7           LOC                                    neun Staaten   \n",
       "0                                      Deutschlands Bevölkerung   \n",
       "1                                      Deutschlands Bevölkerung   \n",
       "2                                      Deutschlands Bevölkerung   \n",
       "3                                      Deutschlands Bevölkerung   \n",
       "4                                      Deutschlands Bevölkerung   \n",
       "5           LOC                        Deutschlands Bevölkerung   \n",
       "6           LOC                        Deutschlands Bevölkerung   \n",
       "7           LOC                        Deutschlands Bevölkerung   \n",
       "8           LOC                        Deutschlands Bevölkerung   \n",
       "9           LOC                        Deutschlands Bevölkerung   \n",
       "15                   eine vergleichsweise niedrige Geburtenrate   \n",
       "0                                               die Anwesenheit   \n",
       "1                                               die Anwesenheit   \n",
       "2                                               die Anwesenheit   \n",
       "3                                                      Menschen   \n",
       "..          ...                                             ...   \n",
       "27         MISC                                       Eine Frau   \n",
       "0          MISC                                        Ein Mann   \n",
       "1          MISC                                        Ein Mann   \n",
       "2          MISC                                        Ein Mann   \n",
       "3          MISC                                        Ein Mann   \n",
       "4          MISC                                        Ein Mann   \n",
       "5          MISC                                        Ein Mann   \n",
       "6          MISC                                        Ein Mann   \n",
       "7          MISC                                        Ein Mann   \n",
       "8          MISC                                        Ein Mann   \n",
       "9          MISC                                        Ein Mann   \n",
       "10         MISC                                        Ein Mann   \n",
       "11         MISC                                        Ein Mann   \n",
       "12         MISC                                        Ein Mann   \n",
       "13         MISC                                        Ein Mann   \n",
       "14         MISC                                        Ein Mann   \n",
       "15         MISC                                        Ein Mann   \n",
       "16         MISC                                        Ein Mann   \n",
       "17         MISC                                        Ein Mann   \n",
       "18         MISC                                        Ein Mann   \n",
       "19         MISC                                        Ein Mann   \n",
       "20         MISC                                        Ein Mann   \n",
       "21         MISC                                        Ein Mann   \n",
       "22         MISC                                        Ein Mann   \n",
       "23         MISC                                        Ein Mann   \n",
       "0                                             auch Arbeitsrecht   \n",
       "1                                             auch Arbeitsrecht   \n",
       "2                                             auch Arbeitsrecht   \n",
       "3                                             auch Arbeitsrecht   \n",
       "4                                             auch Arbeitsrecht   \n",
       "\n",
       "      Subjects_raw  \n",
       "0   Bundesrepublik  \n",
       "1   Bundesrepublik  \n",
       "2      Deutschland  \n",
       "3      Deutschland  \n",
       "0      Deutschland  \n",
       "1      Deutschland  \n",
       "2      Deutschland  \n",
       "0          Staaten  \n",
       "1             neun  \n",
       "2          Staaten  \n",
       "3          Staaten  \n",
       "4          Staaten  \n",
       "5          Staaten  \n",
       "6          Staaten  \n",
       "7          Staaten  \n",
       "0      Bevölkerung  \n",
       "1      Bevölkerung  \n",
       "2      Bevölkerung  \n",
       "3      Bevölkerung  \n",
       "4      Bevölkerung  \n",
       "5     Deutschlands  \n",
       "6     Deutschlands  \n",
       "7     Deutschlands  \n",
       "8     Deutschlands  \n",
       "9     Deutschlands  \n",
       "15    Geburtenrate  \n",
       "0      Anwesenheit  \n",
       "1      Anwesenheit  \n",
       "2      Anwesenheit  \n",
       "3         Menschen  \n",
       "..             ...  \n",
       "27            Frau  \n",
       "0             Mann  \n",
       "1             Mann  \n",
       "2             Mann  \n",
       "3             Mann  \n",
       "4             Mann  \n",
       "5             Mann  \n",
       "6             Mann  \n",
       "7             Mann  \n",
       "8             Mann  \n",
       "9             Mann  \n",
       "10            Mann  \n",
       "11            Mann  \n",
       "12            Mann  \n",
       "13            Mann  \n",
       "14            Mann  \n",
       "15            Mann  \n",
       "16            Mann  \n",
       "17            Mann  \n",
       "18            Mann  \n",
       "19            Mann  \n",
       "20            Mann  \n",
       "21            Mann  \n",
       "22            Mann  \n",
       "23            Mann  \n",
       "0     Arbeitsrecht  \n",
       "1     Arbeitsrecht  \n",
       "2     Arbeitsrecht  \n",
       "3     Arbeitsrecht  \n",
       "4     Arbeitsrecht  \n",
       "\n",
       "[10881 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_kg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An Deutschland grenzen neun Staaten, es hat Anteil an der Nord- und Ostsee im Norden sowie dem Bodensee und den Alpen im Süden.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_kg_df.iloc[10]['Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10881 entries, 0 to 4\n",
      "Data columns (total 8 columns):\n",
      "Object_Type     10881 non-null object\n",
      "Objects         10881 non-null object\n",
      "Objects_raw     10881 non-null object\n",
      "Relations       10881 non-null object\n",
      "Sentence        10881 non-null object\n",
      "Subject_Type    10881 non-null object\n",
      "Subjects        10881 non-null object\n",
      "Subjects_raw    10881 non-null object\n",
      "dtypes: object(8)\n",
      "memory usage: 765.1+ KB\n"
     ]
    }
   ],
   "source": [
    "wiki_kg_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung der Ergebnisse\n",
    "Die Erste Ergebnisse werden angezeigt, um ein Gefühl bezüglich der Aussicht eines Knowledge-Graphs erhalten wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_kg(pairs):\n",
    "    '''\n",
    "    Bei dieser Methode wird die Basis für die vereinfachten Darstellung eines\n",
    "    Knowledge-Graphs geschaffen.\n",
    "    '''\n",
    "    k_graph = nx.from_pandas_edgelist(pairs, 'Subjects', 'Objects',\n",
    "            create_using=nx.MultiDiGraph())\n",
    "    node_deg = nx.degree(k_graph)\n",
    "    layout = nx.spring_layout(k_graph, k=0.15, iterations=20)\n",
    "    plt.figure(num=None, figsize=(15, 10), dpi=80)\n",
    "    nx.draw_networkx(\n",
    "        k_graph,\n",
    "        node_size=[int(deg[1]) * 500 for deg in node_deg],\n",
    "        arrowsize=20,\n",
    "        linewidths=1.5,\n",
    "        pos=layout,\n",
    "        edge_color='red',\n",
    "        edgecolors='black',\n",
    "        node_color='white',\n",
    "        )\n",
    "    labels = dict(zip(list(zip(pairs.Subjects, pairs.Objects)),\n",
    "                  pairs['Relations'].tolist()))\n",
    "    nx.draw_networkx_edge_labels(k_graph, pos=layout, edge_labels=labels,\n",
    "                                 font_color='red')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_graph(pairs, node):\n",
    "    '''\n",
    "    Bei dieser Methode, wird die Information anhand der Subjekte gefiltert, sodass\n",
    "    nicht alle Informationen gleichzeitig dargestellt wird, sonder nur was eine\n",
    "    Verbindung zu dem Eingegebenen Subjekt enthält.\n",
    "    '''\n",
    "    k_graph = nx.from_pandas_edgelist(pairs, 'Subjects', 'Objects',\n",
    "            create_using=nx.MultiDiGraph())\n",
    "    edges = nx.dfs_successors(k_graph, node)\n",
    "    nodes = []\n",
    "    for k, v in edges.items():\n",
    "        nodes.extend([k])\n",
    "        nodes.extend(v)\n",
    "    subgraph = k_graph.subgraph(nodes)\n",
    "    layout = nx.spring_layout(k_graph, k=0.15, iterations=20)\n",
    "    nx.draw_networkx(\n",
    "        subgraph,\n",
    "        node_size=1000,\n",
    "        arrowsize=20,\n",
    "        linewidths=1.5,\n",
    "        pos=layout,\n",
    "        edge_color='red',\n",
    "        edgecolors='black',\n",
    "        node_color='white'\n",
    "        )\n",
    "    labels = dict(zip((list(zip(pairs.Subjects, pairs.Objects))),\n",
    "                    pairs['Relations'].tolist()))\n",
    "    edges= tuple(subgraph.out_edges(data=False))\n",
    "    sublabels ={k: labels[k] for k in edges}\n",
    "#     print(k_graph.out_edges(data=False))\n",
    "    nx.draw_networkx_edge_labels(subgraph, pos=layout, edge_labels=sublabels,\n",
    "                                font_color='red')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    plt.figure(num=None, figsize=(15, 10), dpi=80)\n",
    "    filter_graph(kg_df[kg_data_cols], 'die Studierenden')\n",
    "except:\n",
    "    print('Subjekt nicht gefunden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
